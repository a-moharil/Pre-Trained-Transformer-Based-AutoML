Processing Df..

Done Processing Df..

0it [00:00, ?it/s]
  0%|          | 0/100 [00:00<?, ?it/s][A/home/TUE/20210962/miniconda3/envs/ambarish_base/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2357: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(
/home/TUE/20210962/miniconda3/envs/ambarish_base/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(

  1%|          | 1/100 [00:02<04:05,  2.48s/it][A
  2%|â–         | 2/100 [00:04<03:12,  1.97s/it][A
  3%|â–         | 3/100 [00:05<02:59,  1.85s/it][A
  4%|â–         | 4/100 [00:07<03:07,  1.95s/it][A
  5%|â–Œ         | 5/100 [00:59<31:20, 19.80s/it][A
  6%|â–Œ         | 6/100 [01:38<41:17, 26.36s/it][A
  7%|â–‹         | 7/100 [02:27<52:15, 33.71s/it][A
  8%|â–Š         | 8/100 [02:46<44:50, 29.25s/it][A
  9%|â–‰         | 9/100 [02:49<31:46, 20.95s/it][A
 10%|â–ˆ         | 10/100 [02:54<23:46, 15.85s/it][A
 11%|â–ˆ         | 11/100 [02:55<17:04, 11.51s/it][A
 12%|â–ˆâ–        | 12/100 [02:57<12:24,  8.46s/it][A
 13%|â–ˆâ–        | 13/100 [02:58<09:04,  6.26s/it][A
 14%|â–ˆâ–        | 14/100 [03:04<08:42,  6.07s/it][A
 15%|â–ˆâ–Œ        | 15/100 [03:54<27:30, 19.42s/it][A
 16%|â–ˆâ–Œ        | 16/100 [04:46<40:47, 29.13s/it][A
 17%|â–ˆâ–‹        | 17/100 [05:28<45:35, 32.96s/it][A
 18%|â–ˆâ–Š        | 18/100 [05:47<39:24, 28.83s/it][A
 19%|â–ˆâ–‰        | 19/100 [05:48<27:49, 20.61s/it][A
 20%|â–ˆâ–ˆ        | 20/100 [05:49<19:33, 14.67s/it][A
 21%|â–ˆâ–ˆ        | 21/100 [05:50<13:56, 10.59s/it][A
 22%|â–ˆâ–ˆâ–       | 22/100 [05:51<09:59,  7.69s/it][A
 23%|â–ˆâ–ˆâ–       | 23/100 [05:52<07:15,  5.65s/it][A
 24%|â–ˆâ–ˆâ–       | 24/100 [05:57<07:02,  5.55s/it][A
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [06:47<23:26, 18.76s/it][A
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [07:39<35:21, 28.67s/it][A
 27%|â–ˆâ–ˆâ–‹       | 27/100 [08:20<39:30, 32.48s/it][A
 28%|â–ˆâ–ˆâ–Š       | 28/100 [09:03<42:43, 35.60s/it][A
 29%|â–ˆâ–ˆâ–‰       | 29/100 [09:11<32:18, 27.30s/it][A
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [09:15<23:42, 20.32s/it][A
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [09:21<18:21, 15.97s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [09:23<13:26, 11.86s/it][A
 33%|â–ˆâ–ˆâ–ˆâ–      | 33/100 [09:26<10:20,  9.27s/it][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [09:28<07:44,  7.04s/it][A
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [09:30<06:03,  5.59s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [09:33<04:59,  4.68s/it][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [09:34<03:43,  3.54s/it][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [09:35<02:52,  2.78s/it][A
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [09:36<02:15,  2.21s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [09:36<01:47,  1.79s/it][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [09:38<01:36,  1.64s/it][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [09:39<01:22,  1.42s/it][A
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/100 [09:40<01:14,  1.31s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [09:41<01:11,  1.27s/it][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [09:42<01:07,  1.24s/it][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [09:43<01:03,  1.17s/it][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [09:44<00:59,  1.13s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [09:55<03:26,  3.96s/it][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [10:36<12:51, 15.13s/it][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [10:47<11:36, 13.93s/it][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [10:50<08:50, 10.84s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [11:12<11:09, 13.95s/it][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/100 [11:13<07:56, 10.14s/it][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [11:45<12:48, 16.70s/it][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [12:36<20:16, 27.04s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [13:27<25:10, 34.34s/it][A
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [13:57<23:32, 32.85s/it][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [14:04<17:42, 25.29s/it][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [14:10<13:11, 19.30s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [14:11<09:10, 13.77s/it][A
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [14:12<06:27,  9.93s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [14:40<09:43, 15.36s/it][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 63/100 [15:15<13:08, 21.32s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [15:20<09:52, 16.47s/it][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [16:02<14:00, 24.02s/it][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [16:42<16:18, 28.77s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [17:18<17:04, 31.05s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [17:50<16:41, 31.28s/it][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [18:04<13:34, 26.29s/it][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [18:05<09:20, 18.68s/it][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [18:06<06:26, 13.34s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [18:07<04:27,  9.57s/it][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 73/100 [18:08<03:08,  6.96s/it][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [18:09<02:13,  5.15s/it][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [18:11<01:45,  4.20s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [18:42<04:53, 12.23s/it][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [19:11<06:36, 17.24s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [19:12<04:32, 12.40s/it][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [19:13<03:07,  8.95s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [19:26<03:25, 10.26s/it][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [19:29<02:33,  8.08s/it][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [20:20<06:18, 21.01s/it][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 83/100 [21:16<08:53, 31.38s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [22:10<10:12, 38.29s/it][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [22:57<10:12, 40.83s/it][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [23:39<09:35, 41.14s/it][A
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [24:22<09:01, 41.64s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [24:59<08:03, 40.31s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [25:36<07:11, 39.25s/it][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [26:01<05:52, 35.21s/it][A
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [26:03<03:45, 25.07s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [26:04<02:24, 18.07s/it][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 93/100 [26:05<01:30, 12.96s/it][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [26:08<00:58,  9.68s/it][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [26:09<00:35,  7.18s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [26:11<00:22,  5.58s/it][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [26:13<00:13,  4.53s/it][A
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [26:14<00:07,  3.67s/it][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [26:16<00:02,  2.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [26:16<00:00,  2.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [26:16<00:00, 15.77s/it]
1it [26:21, 1581.06s/it]1it [26:21, 1581.50s/it]
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ /home/TUE/20210962/flava_mod3_pf.py:97 in <module>                           â”‚
â”‚                                                                              â”‚
â”‚    94                                                                        â”‚
â”‚    95 # Getting tabular + text embeddings                                    â”‚
â”‚    96 text_img_embeddings = []                                               â”‚
â”‚ â±  97 for idx, batch in tqdm(enumerate(train_loader)):                       â”‚
â”‚    98 â”‚   img, text = batch                                                  â”‚
â”‚    99 â”‚   converted_tensors = [torchvision.transforms.functional.to_pil_imag â”‚
â”‚   100 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚    img]                                          â”‚
â”‚                                                                              â”‚
â”‚ /home/TUE/20210962/miniconda3/envs/ambarish_base/lib/python3.8/site-packages â”‚
â”‚ /tqdm/std.py:1195 in __iter__                                                â”‚
â”‚                                                                              â”‚
â”‚   1192 â”‚   â”‚   time = self._time                                             â”‚
â”‚   1193 â”‚   â”‚                                                                 â”‚
â”‚   1194 â”‚   â”‚   try:                                                          â”‚
â”‚ â± 1195 â”‚   â”‚   â”‚   for obj in iterable:                                      â”‚
â”‚   1196 â”‚   â”‚   â”‚   â”‚   yield obj                                             â”‚
â”‚   1197 â”‚   â”‚   â”‚   â”‚   # Update and possibly print the progressbar.          â”‚
â”‚   1198 â”‚   â”‚   â”‚   â”‚   # Note: does not call self.update(1) for speed optimi â”‚
â”‚                                                                              â”‚
â”‚ /home/TUE/20210962/miniconda3/envs/ambarish_base/lib/python3.8/site-packages â”‚
â”‚ /torch/utils/data/dataloader.py:681 in __next__                              â”‚
â”‚                                                                              â”‚
â”‚    678 â”‚   â”‚   â”‚   if self._sampler_iter is None:                            â”‚
â”‚    679 â”‚   â”‚   â”‚   â”‚   # TODO(https://github.com/pytorch/pytorch/issues/7675 â”‚
â”‚    680 â”‚   â”‚   â”‚   â”‚   self._reset()  # type: ignore[call-arg]               â”‚
â”‚ â±  681 â”‚   â”‚   â”‚   data = self._next_data()                                  â”‚
â”‚    682 â”‚   â”‚   â”‚   self._num_yielded += 1                                    â”‚
â”‚    683 â”‚   â”‚   â”‚   if self._dataset_kind == _DatasetKind.Iterable and \      â”‚
â”‚    684 â”‚   â”‚   â”‚   â”‚   â”‚   self._IterableDataset_len_called is not None and  â”‚
â”‚                                                                              â”‚
â”‚ /home/TUE/20210962/miniconda3/envs/ambarish_base/lib/python3.8/site-packages â”‚
â”‚ /torch/utils/data/dataloader.py:721 in _next_data                            â”‚
â”‚                                                                              â”‚
â”‚    718 â”‚                                                                     â”‚
â”‚    719 â”‚   def _next_data(self):                                             â”‚
â”‚    720 â”‚   â”‚   index = self._next_index()  # may raise StopIteration         â”‚
â”‚ â±  721 â”‚   â”‚   data = self._dataset_fetcher.fetch(index)  # may raise StopIt â”‚
â”‚    722 â”‚   â”‚   if self._pin_memory:                                          â”‚
â”‚    723 â”‚   â”‚   â”‚   data = _utils.pin_memory.pin_memory(data, self._pin_memor â”‚
â”‚    724 â”‚   â”‚   return data                                                   â”‚
â”‚                                                                              â”‚
â”‚ /home/TUE/20210962/miniconda3/envs/ambarish_base/lib/python3.8/site-packages â”‚
â”‚ /torch/utils/data/_utils/fetch.py:52 in fetch                                â”‚
â”‚                                                                              â”‚
â”‚   49 â”‚   â”‚   â”‚   data = [self.dataset[idx] for idx in possibly_batched_index â”‚
â”‚   50 â”‚   â”‚   else:                                                           â”‚
â”‚   51 â”‚   â”‚   â”‚   data = self.dataset[possibly_batched_index]                 â”‚
â”‚ â± 52 â”‚   â”‚   return self.collate_fn(data)                                    â”‚
â”‚   53                                                                         â”‚
â”‚                                                                              â”‚
â”‚ /home/TUE/20210962/flava_mod3_pf.py:84 in collate_fn                         â”‚
â”‚                                                                              â”‚
â”‚    81 # defining a custom collate function                                   â”‚
â”‚    82 def collate_fn(batch):                                                 â”‚
â”‚    83 â”‚   batch = list(filter(lambda x: x is not None, batch))               â”‚
â”‚ â±  84 â”‚   return torch.utils.data.dataloader.default_collate(batch)          â”‚
â”‚    85                                                                        â”‚
â”‚    86                                                                        â”‚
â”‚    87 batch_size = 100                                                       â”‚
â”‚                                                                              â”‚
â”‚ /home/TUE/20210962/miniconda3/envs/ambarish_base/lib/python3.8/site-packages â”‚
â”‚ /torch/utils/data/_utils/collate.py:175 in default_collate                   â”‚
â”‚                                                                              â”‚
â”‚   172 â”‚   â”‚   transposed = list(zip(*batch))  # It may be accessed twice, so â”‚
â”‚   173 â”‚   â”‚                                                                  â”‚
â”‚   174 â”‚   â”‚   if isinstance(elem, tuple):                                    â”‚
â”‚ â± 175 â”‚   â”‚   â”‚   return [default_collate(samples) for samples in transposed â”‚
â”‚   176 â”‚   â”‚   else:                                                          â”‚
â”‚   177 â”‚   â”‚   â”‚   try:                                                       â”‚
â”‚   178 â”‚   â”‚   â”‚   â”‚   return elem_type([default_collate(samples) for samples â”‚
â”‚                                                                              â”‚
â”‚ /home/TUE/20210962/miniconda3/envs/ambarish_base/lib/python3.8/site-packages â”‚
â”‚ /torch/utils/data/_utils/collate.py:175 in <listcomp>                        â”‚
â”‚                                                                              â”‚
â”‚   172 â”‚   â”‚   transposed = list(zip(*batch))  # It may be accessed twice, so â”‚
â”‚   173 â”‚   â”‚                                                                  â”‚
â”‚   174 â”‚   â”‚   if isinstance(elem, tuple):                                    â”‚
â”‚ â± 175 â”‚   â”‚   â”‚   return [default_collate(samples) for samples in transposed â”‚
â”‚   176 â”‚   â”‚   else:                                                          â”‚
â”‚   177 â”‚   â”‚   â”‚   try:                                                       â”‚
â”‚   178 â”‚   â”‚   â”‚   â”‚   return elem_type([default_collate(samples) for samples â”‚
â”‚                                                                              â”‚
â”‚ /home/TUE/20210962/miniconda3/envs/ambarish_base/lib/python3.8/site-packages â”‚
â”‚ /torch/utils/data/_utils/collate.py:153 in default_collate                   â”‚
â”‚                                                                              â”‚
â”‚   150 â”‚   â”‚   elif elem.shape == ():  # scalars                              â”‚
â”‚   151 â”‚   â”‚   â”‚   return torch.as_tensor(batch)                              â”‚
â”‚   152 â”‚   elif isinstance(elem, float):                                      â”‚
â”‚ â± 153 â”‚   â”‚   return torch.tensor(batch, dtype=torch.float64)                â”‚
â”‚   154 â”‚   elif isinstance(elem, int):                                        â”‚
â”‚   155 â”‚   â”‚   return torch.tensor(batch)                                     â”‚
â”‚   156 â”‚   elif isinstance(elem, string_classes):                             â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
TypeError: must be real number, not str
/var/spool/slurm/d/job118567/slurm_script: line 6: deactivate: No such file or directory
