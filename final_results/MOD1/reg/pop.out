Token is valid (permission: read).
[1m[31mCannot authenticate through git-credential as no helper is defined on your machine.
You might have to re-authenticate when pushing to the Hugging Face Hub.
Run the following command in your terminal in case you want to set the 'store' credential helper as default.

git config --global credential.helper store

Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.[0m
Token has not been saved to git credential helper.
Your token has been saved to /home/TUE/20210962/.cache/huggingface/token
Login successful
We will add these 36 downstream models into our config space
                                                       0
0      Any.DO Moment Pushes You to Actually Tackle Yo...
1                     iPad Activations on AT&T Jump 200%
2      This Simple Action Will Dramatically Grow Your...
3      Twitter CEO Finally Gets a Verified Account on...
4             Slingbox Can Now Stream TV on Roku Players
...                                                  ...
24002  Michael Brown's family leaves empty seat at di...
24003                   14 Quotes That Haunt New Yorkers
24004  4 changes that will make your resume a breath ...
24005  Top Moments From Sochi: Olympic Fog, Injuries ...
24006  Report: Google in Talks to Buy Streaming Servi...

[24007 rows x 1 columns]
The shape of the text data is (24007, 1)
The shape of the tabular data is (24007, 4)
Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.
Token is valid (permission: read).
Your token has been saved to /home/TUE/20210962/.cache/huggingface/token
Login successful
The selected modality is tabular_text 

Starting NAS for the Tabular Modality 

No path specified. Models will be saved in: "AutogluonModels/ag-20230719_201923/"
AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).
	Label info (max, min, mean, stddev): (12.646908114973671, 4.174387269895637, 7.46828, 0.93474)
	If 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])
[rank: 0] Global seed set to 0
AutoMM starts to create your model. âœ¨

- AutoGluon version is 0.8.2.

- Pytorch version is 1.12.1+cu116.

- Model will be saved to "/mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923".

- Validation metric is "rmse".

- To track the learning progress, you can open a terminal and launch Tensorboard:
    ```shell
    # Assume you have installed tensorboard
    tensorboard --logdir /mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923
    ```

Enjoy your coffee, and let AutoMM do the job â˜•â˜•â˜• Learn more at https://auto.gluon.ai

1 GPUs are detected, and 1 GPUs will be used.
   - GPU 0 name: GeForce GTX 1080 Ti
   - GPU 0 memory: 11.58GB/11.72GB (Free/Total)
CUDA version is 11.6.

/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python SMAC_REG_MOD1.py ...
  rank_zero_warn(
Using 16bit None Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python SMAC_REG_MOD1.py ...
  rank_zero_warn(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name              | Type                | Params
----------------------------------------------------------
0 | model             | MultimodalFusionMLP | 109 M 
1 | validation_metric | MeanSquaredError    | 0     
2 | loss_func         | MSELoss             | 0     
----------------------------------------------------------
109 M     Trainable params
0         Non-trainable params
109 M     Total params
219.565   Total estimated model params size (MB)
Sanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.32it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.48it/s]                                                                           Training: 0it [00:00, ?it/s]Training:   0%|          | 0/76 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/76 [00:00<?, ?it/s] Epoch 0:   1%|â–         | 1/76 [00:00<00:23,  3.21it/s]Epoch 0:   1%|â–         | 1/76 [00:00<00:23,  3.20it/s, loss=2.34, v_num=]Epoch 0:   3%|â–Ž         | 2/76 [00:00<00:14,  5.00it/s, loss=2.34, v_num=]Epoch 0:   3%|â–Ž         | 2/76 [00:00<00:14,  5.00it/s, loss=2.1, v_num=] Epoch 0:   4%|â–         | 3/76 [00:00<00:11,  6.46it/s, loss=2.1, v_num=]Epoch 0:   4%|â–         | 3/76 [00:00<00:11,  6.45it/s, loss=1.73, v_num=]Epoch 0:   5%|â–Œ         | 4/76 [00:00<00:09,  7.51it/s, loss=1.73, v_num=]Epoch 0:   5%|â–Œ         | 4/76 [00:00<00:09,  7.50it/s, loss=1.6, v_num=] Epoch 0:   7%|â–‹         | 5/76 [00:00<00:08,  8.03it/s, loss=1.6, v_num=]Epoch 0:   7%|â–‹         | 5/76 [00:00<00:08,  8.02it/s, loss=1.9, v_num=]Epoch 0:   8%|â–Š         | 6/76 [00:00<00:08,  8.38it/s, loss=1.9, v_num=]Epoch 0:   8%|â–Š         | 6/76 [00:00<00:08,  8.37it/s, loss=2.12, v_num=]Epoch 0:   9%|â–‰         | 7/76 [00:00<00:07,  8.79it/s, loss=2.12, v_num=]Epoch 0:   9%|â–‰         | 7/76 [00:00<00:07,  8.78it/s, loss=2.27, v_num=]Epoch 0:  11%|â–ˆ         | 8/76 [00:00<00:07,  9.20it/s, loss=2.27, v_num=]Epoch 0:  11%|â–ˆ         | 8/76 [00:00<00:07,  9.20it/s, loss=2.27, v_num=]Epoch 0:  12%|â–ˆâ–        | 9/76 [00:00<00:07,  9.53it/s, loss=2.27, v_num=]Epoch 0:  12%|â–ˆâ–        | 9/76 [00:00<00:07,  9.52it/s, loss=2.23, v_num=]Epoch 0:  13%|â–ˆâ–Ž        | 10/76 [00:01<00:06,  9.63it/s, loss=2.23, v_num=]Epoch 0:  13%|â–ˆâ–Ž        | 10/76 [00:01<00:06,  9.63it/s, loss=2.53, v_num=]Epoch 0:  14%|â–ˆâ–        | 11/76 [00:01<00:06,  9.91it/s, loss=2.53, v_num=]Epoch 0:  14%|â–ˆâ–        | 11/76 [00:01<00:06,  9.90it/s, loss=2.46, v_num=]Epoch 0:  16%|â–ˆâ–Œ        | 12/76 [00:01<00:06, 10.12it/s, loss=2.46, v_num=]Epoch 0:  16%|â–ˆâ–Œ        | 12/76 [00:01<00:06, 10.11it/s, loss=2.39, v_num=]Epoch 0:  17%|â–ˆâ–‹        | 13/76 [00:01<00:06, 10.28it/s, loss=2.39, v_num=]Epoch 0:  17%|â–ˆâ–‹        | 13/76 [00:01<00:06, 10.28it/s, loss=2.39, v_num=]Epoch 0:  18%|â–ˆâ–Š        | 14/76 [00:01<00:05, 10.40it/s, loss=2.39, v_num=]Epoch 0:  18%|â–ˆâ–Š        | 14/76 [00:01<00:05, 10.39it/s, loss=2.45, v_num=]Epoch 0:  20%|â–ˆâ–‰        | 15/76 [00:01<00:05, 10.55it/s, loss=2.45, v_num=]Epoch 0:  20%|â–ˆâ–‰        | 15/76 [00:01<00:05, 10.54it/s, loss=2.37, v_num=]Epoch 0:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:05, 10.53it/s, loss=2.37, v_num=]Epoch 0:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:05, 10.52it/s, loss=2.46, v_num=]Epoch 0:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:05, 10.59it/s, loss=2.46, v_num=]Epoch 0:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:05, 10.58it/s, loss=2.35, v_num=]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:05, 10.74it/s, loss=2.35, v_num=]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:05, 10.73it/s, loss=2.34, v_num=]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:05, 10.81it/s, loss=2.34, v_num=]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:05, 10.81it/s, loss=2.29, v_num=]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:01<00:05, 10.92it/s, loss=2.29, v_num=]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:01<00:05, 10.92it/s, loss=2.28, v_num=]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:01<00:05, 10.95it/s, loss=2.28, v_num=]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:01<00:05, 10.55it/s, loss=2.25, v_num=]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:02<00:05, 10.68it/s, loss=2.25, v_num=]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:02<00:05, 10.68it/s, loss=2.22, v_num=]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:02<00:04, 10.70it/s, loss=2.22, v_num=]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:02<00:04, 10.70it/s, loss=2.29, v_num=]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:02<00:04, 10.81it/s, loss=2.29, v_num=]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:02<00:04, 10.81it/s, loss=2.3, v_num=] Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:02<00:04, 10.85it/s, loss=2.3, v_num=]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:02<00:04, 10.85it/s, loss=2.27, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 23.49it/s][AEpoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 26/76 [00:02<00:04, 10.89it/s, loss=2.27, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 25.56it/s][AEpoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/76 [00:02<00:04, 11.14it/s, loss=2.27, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 25.13it/s][AEpoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/76 [00:02<00:04, 11.36it/s, loss=2.27, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 25.81it/s][AEpoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 29/76 [00:02<00:04, 11.60it/s, loss=2.27, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 24.75it/s][AEpoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 30/76 [00:02<00:03, 11.78it/s, loss=2.27, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 24.32it/s][AEpoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 31/76 [00:02<00:03, 11.96it/s, loss=2.27, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 24.89it/s][AEpoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/76 [00:02<00:03, 12.18it/s, loss=2.27, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 25.49it/s][AEpoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 33/76 [00:02<00:03, 12.41it/s, loss=2.27, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 26.77it/s][AEpoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/76 [00:02<00:03, 12.68it/s, loss=2.27, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 26.39it/s][AEpoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 35/76 [00:02<00:03, 12.85it/s, loss=2.27, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 25.66it/s][AEpoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 36/76 [00:02<00:03, 12.98it/s, loss=2.27, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 25.69it/s][AEpoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 37/76 [00:02<00:02, 13.15it/s, loss=2.27, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.87it/s][AEpoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:02<00:02, 13.34it/s, loss=2.27, v_num=]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:03<00:03, 10.01it/s, loss=2.27, v_num=]
                                                                        [AEpoch 0, global step 1: 'val_rmse' reached 1.17664 (best 1.17664), saving model to '/mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923/epoch=0-step=1.ckpt' as top 3
Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:25<00:24,  1.51it/s, loss=2.27, v_num=]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:26<00:24,  1.50it/s, loss=2.22, v_num=]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:26<00:23,  1.53it/s, loss=2.22, v_num=]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:26<00:23,  1.53it/s, loss=2.2, v_num=] Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:26<00:22,  1.56it/s, loss=2.2, v_num=]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:26<00:22,  1.56it/s, loss=2.24, v_num=]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:26<00:21,  1.60it/s, loss=2.24, v_num=]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:26<00:21,  1.60it/s, loss=2.23, v_num=]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:26<00:20,  1.63it/s, loss=2.23, v_num=]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:26<00:20,  1.63it/s, loss=2.08, v_num=]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:26<00:19,  1.66it/s, loss=2.08, v_num=]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:26<00:19,  1.66it/s, loss=2.04, v_num=]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:26<00:18,  1.69it/s, loss=2.04, v_num=]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:26<00:18,  1.69it/s, loss=2.04, v_num=]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:26<00:17,  1.72it/s, loss=2.04, v_num=]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:26<00:17,  1.72it/s, loss=2.1, v_num=] Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [00:26<00:16,  1.75it/s, loss=2.1, v_num=]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [00:26<00:16,  1.75it/s, loss=1.97, v_num=]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [00:26<00:15,  1.78it/s, loss=1.97, v_num=]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [00:26<00:15,  1.78it/s, loss=2, v_num=]   Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [00:27<00:14,  1.81it/s, loss=2, v_num=]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [00:27<00:14,  1.81it/s, loss=2.02, v_num=]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [00:27<00:14,  1.84it/s, loss=2.02, v_num=]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [00:27<00:14,  1.84it/s, loss=2.07, v_num=]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [00:27<00:13,  1.87it/s, loss=2.07, v_num=]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [00:27<00:13,  1.87it/s, loss=2.02, v_num=]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [00:27<00:12,  1.90it/s, loss=2.02, v_num=]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [00:27<00:12,  1.90it/s, loss=2.04, v_num=]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [00:27<00:11,  1.93it/s, loss=2.04, v_num=]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [00:27<00:11,  1.93it/s, loss=2.19, v_num=]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [00:27<00:11,  1.96it/s, loss=2.19, v_num=]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [00:27<00:11,  1.96it/s, loss=2.19, v_num=]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [00:27<00:10,  1.99it/s, loss=2.19, v_num=]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [00:27<00:10,  1.99it/s, loss=2.39, v_num=]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [00:27<00:09,  2.02it/s, loss=2.39, v_num=]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [00:27<00:09,  2.02it/s, loss=2.58, v_num=]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [00:27<00:09,  2.05it/s, loss=2.58, v_num=]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [00:27<00:09,  2.05it/s, loss=2.62, v_num=]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [00:27<00:08,  2.08it/s, loss=2.62, v_num=]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [00:27<00:08,  2.08it/s, loss=2.7, v_num=] Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [00:28<00:08,  2.11it/s, loss=2.7, v_num=]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [00:28<00:08,  2.11it/s, loss=2.67, v_num=]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [00:28<00:07,  2.14it/s, loss=2.67, v_num=]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [00:28<00:07,  2.14it/s, loss=2.66, v_num=]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [00:28<00:06,  2.16it/s, loss=2.66, v_num=]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [00:28<00:06,  2.16it/s, loss=2.82, v_num=]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [00:28<00:06,  2.19it/s, loss=2.82, v_num=]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [00:28<00:06,  2.19it/s, loss=2.8, v_num=] Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [00:28<00:05,  2.21it/s, loss=2.8, v_num=]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [00:28<00:05,  2.21it/s, loss=2.78, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 31.72it/s][AEpoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 64/76 [00:28<00:05,  2.24it/s, loss=2.78, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 23.48it/s][AEpoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 65/76 [00:28<00:04,  2.27it/s, loss=2.78, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 22.66it/s][AEpoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 66/76 [00:28<00:04,  2.31it/s, loss=2.78, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 23.30it/s][AEpoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 67/76 [00:28<00:03,  2.34it/s, loss=2.78, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 24.05it/s][AEpoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 68/76 [00:28<00:03,  2.37it/s, loss=2.78, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 25.54it/s][AEpoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 69/76 [00:28<00:02,  2.40it/s, loss=2.78, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 25.30it/s][AEpoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/76 [00:28<00:02,  2.43it/s, loss=2.78, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 26.35it/s][AEpoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 71/76 [00:28<00:02,  2.47it/s, loss=2.78, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 25.60it/s][AEpoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72/76 [00:28<00:01,  2.50it/s, loss=2.78, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 25.43it/s][AEpoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 73/76 [00:28<00:01,  2.53it/s, loss=2.78, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 25.59it/s][AEpoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 74/76 [00:28<00:00,  2.56it/s, loss=2.78, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 25.14it/s][AEpoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 75/76 [00:28<00:00,  2.59it/s, loss=2.78, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 25.10it/s][AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:29<00:00,  2.62it/s, loss=2.78, v_num=]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:31<00:00,  2.38it/s, loss=2.78, v_num=]
                                                                        [AEpoch 0, global step 4: 'val_rmse' reached 1.06247 (best 1.06247), saving model to '/mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923/epoch=0-step=4.ckpt' as top 3
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:13<00:00,  1.03it/s, loss=2.78, v_num=]Epoch 0:   0%|          | 0/76 [00:00<?, ?it/s, loss=2.78, v_num=]         Epoch 1:   0%|          | 0/76 [00:00<?, ?it/s, loss=2.78, v_num=]Epoch 1:   1%|â–         | 1/76 [00:00<00:10,  7.34it/s, loss=2.78, v_num=]Epoch 1:   1%|â–         | 1/76 [00:00<00:10,  7.29it/s, loss=2.78, v_num=]Epoch 1:   3%|â–Ž         | 2/76 [00:00<00:08,  8.50it/s, loss=2.78, v_num=]Epoch 1:   3%|â–Ž         | 2/76 [00:00<00:08,  8.47it/s, loss=2.74, v_num=]Epoch 1:   4%|â–         | 3/76 [00:00<00:08,  8.82it/s, loss=2.74, v_num=]Epoch 1:   4%|â–         | 3/76 [00:00<00:08,  8.79it/s, loss=2.7, v_num=] Epoch 1:   5%|â–Œ         | 4/76 [00:00<00:07,  9.00it/s, loss=2.7, v_num=]Epoch 1:   5%|â–Œ         | 4/76 [00:00<00:08,  8.98it/s, loss=2.75, v_num=]Epoch 1:   7%|â–‹         | 5/76 [00:00<00:07,  9.00it/s, loss=2.75, v_num=]Epoch 1:   7%|â–‹         | 5/76 [00:00<00:07,  8.98it/s, loss=2.78, v_num=]Epoch 1:   8%|â–Š         | 6/76 [00:00<00:07,  9.09it/s, loss=2.78, v_num=]Epoch 1:   8%|â–Š         | 6/76 [00:00<00:07,  9.08it/s, loss=2.74, v_num=]Epoch 1:   9%|â–‰         | 7/76 [00:00<00:07,  9.18it/s, loss=2.74, v_num=]Epoch 1:   9%|â–‰         | 7/76 [00:00<00:07,  9.18it/s, loss=2.68, v_num=]Epoch 1:  11%|â–ˆ         | 8/76 [00:00<00:07,  9.28it/s, loss=2.68, v_num=]Epoch 1:  11%|â–ˆ         | 8/76 [00:00<00:07,  9.27it/s, loss=2.86, v_num=]Epoch 1:  12%|â–ˆâ–        | 9/76 [00:00<00:07,  9.35it/s, loss=2.86, v_num=]Epoch 1:  12%|â–ˆâ–        | 9/76 [00:00<00:07,  9.35it/s, loss=2.88, v_num=]Epoch 1:  13%|â–ˆâ–Ž        | 10/76 [00:01<00:06,  9.50it/s, loss=2.88, v_num=]Epoch 1:  13%|â–ˆâ–Ž        | 10/76 [00:01<00:06,  9.49it/s, loss=2.75, v_num=]Epoch 1:  14%|â–ˆâ–        | 11/76 [00:01<00:06,  9.52it/s, loss=2.75, v_num=]Epoch 1:  14%|â–ˆâ–        | 11/76 [00:01<00:06,  9.51it/s, loss=2.71, v_num=]Epoch 1:  16%|â–ˆâ–Œ        | 12/76 [00:01<00:06,  9.54it/s, loss=2.71, v_num=]Epoch 1:  16%|â–ˆâ–Œ        | 12/76 [00:01<00:06,  9.54it/s, loss=2.51, v_num=]Epoch 1:  17%|â–ˆâ–‹        | 13/76 [00:01<00:06,  9.54it/s, loss=2.51, v_num=]Epoch 1:  17%|â–ˆâ–‹        | 13/76 [00:01<00:06,  9.54it/s, loss=2.33, v_num=]Epoch 1:  18%|â–ˆâ–Š        | 14/76 [00:01<00:06,  9.65it/s, loss=2.33, v_num=]Epoch 1:  18%|â–ˆâ–Š        | 14/76 [00:01<00:06,  9.64it/s, loss=2.32, v_num=]Epoch 1:  20%|â–ˆâ–‰        | 15/76 [00:01<00:06,  9.79it/s, loss=2.32, v_num=]Epoch 1:  20%|â–ˆâ–‰        | 15/76 [00:01<00:06,  9.79it/s, loss=2.29, v_num=]Epoch 1:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:06,  9.50it/s, loss=2.29, v_num=]Epoch 1:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:06,  9.50it/s, loss=2.35, v_num=]Epoch 1:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:06,  9.58it/s, loss=2.35, v_num=]Epoch 1:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:06,  9.58it/s, loss=2.3, v_num=] Epoch 1:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:06,  9.62it/s, loss=2.3, v_num=]Epoch 1:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:06,  9.62it/s, loss=2.05, v_num=]Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:05,  9.73it/s, loss=2.05, v_num=]Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:05,  9.73it/s, loss=2.15, v_num=]Epoch 1:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:02<00:05,  9.79it/s, loss=2.15, v_num=]Epoch 1:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:02<00:05,  9.78it/s, loss=2.36, v_num=]Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:02<00:05,  9.86it/s, loss=2.36, v_num=]Epoch 1:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:02<00:05,  9.85it/s, loss=2.35, v_num=]Epoch 1:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:02<00:05,  9.92it/s, loss=2.35, v_num=]Epoch 1:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:02<00:05,  9.92it/s, loss=2.4, v_num=] Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:02<00:05, 10.03it/s, loss=2.4, v_num=]Epoch 1:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:02<00:05, 10.03it/s, loss=2.41, v_num=]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:02<00:05, 10.08it/s, loss=2.41, v_num=]Epoch 1:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:02<00:05, 10.08it/s, loss=2.54, v_num=]Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:02<00:05, 10.16it/s, loss=2.54, v_num=]Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:02<00:05, 10.16it/s, loss=2.55, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 27.54it/s][AEpoch 1:  34%|â–ˆâ–ˆâ–ˆâ–      | 26/76 [00:02<00:04, 10.24it/s, loss=2.55, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 29.25it/s][AEpoch 1:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/76 [00:02<00:04, 10.51it/s, loss=2.55, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 28.59it/s][AEpoch 1:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/76 [00:02<00:04, 10.74it/s, loss=2.55, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 30.01it/s][AEpoch 1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 29/76 [00:02<00:04, 11.01it/s, loss=2.55, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 30.20it/s][AEpoch 1:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 30/76 [00:02<00:04, 11.25it/s, loss=2.55, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 30.27it/s][AEpoch 1:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 31/76 [00:02<00:03, 11.48it/s, loss=2.55, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 30.42it/s][AEpoch 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/76 [00:02<00:03, 11.71it/s, loss=2.55, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 30.52it/s][AEpoch 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 33/76 [00:02<00:03, 11.94it/s, loss=2.55, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 30.63it/s][AEpoch 1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/76 [00:02<00:03, 12.16it/s, loss=2.55, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 30.70it/s][AEpoch 1:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 35/76 [00:02<00:03, 12.38it/s, loss=2.55, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 30.76it/s][AEpoch 1:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 36/76 [00:02<00:03, 12.59it/s, loss=2.55, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 30.81it/s][AEpoch 1:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 37/76 [00:02<00:03, 12.80it/s, loss=2.55, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 30.85it/s][AEpoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:02<00:02, 13.00it/s, loss=2.55, v_num=]Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:03<00:03,  9.98it/s, loss=2.55, v_num=]
                                                                        [AEpoch 1, global step 5: 'val_rmse' reached 1.59560 (best 1.06247), saving model to '/mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923/epoch=1-step=5.ckpt' as top 3
Epoch 1:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:45<00:42,  1.16s/it, loss=2.55, v_num=]Epoch 1:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:45<00:42,  1.16s/it, loss=2.48, v_num=]Epoch 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:45<00:40,  1.13s/it, loss=2.48, v_num=]Epoch 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:45<00:40,  1.13s/it, loss=2.52, v_num=]Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:45<00:38,  1.11s/it, loss=2.52, v_num=]Epoch 1:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:45<00:38,  1.11s/it, loss=2.41, v_num=]Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:45<00:36,  1.08s/it, loss=2.41, v_num=]Epoch 1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:45<00:36,  1.08s/it, loss=2.51, v_num=]Epoch 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:45<00:34,  1.06s/it, loss=2.51, v_num=]Epoch 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:45<00:34,  1.06s/it, loss=2.61, v_num=]Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:45<00:33,  1.04s/it, loss=2.61, v_num=]Epoch 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:45<00:33,  1.04s/it, loss=2.6, v_num=] Epoch 1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:45<00:31,  1.02s/it, loss=2.6, v_num=]Epoch 1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:45<00:31,  1.02s/it, loss=2.66, v_num=]Epoch 1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:45<00:29,  1.00it/s, loss=2.66, v_num=]Epoch 1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:45<00:29,  1.00it/s, loss=2.58, v_num=]Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [00:46<00:28,  1.02it/s, loss=2.58, v_num=]Epoch 1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [00:46<00:28,  1.02it/s, loss=2.52, v_num=]Epoch 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [00:46<00:26,  1.04it/s, loss=2.52, v_num=]Epoch 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [00:46<00:26,  1.04it/s, loss=2.39, v_num=]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [00:46<00:25,  1.06it/s, loss=2.39, v_num=]Epoch 1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [00:46<00:25,  1.06it/s, loss=2.34, v_num=]Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [00:46<00:24,  1.08it/s, loss=2.34, v_num=]Epoch 1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [00:46<00:24,  1.08it/s, loss=2.31, v_num=]Epoch 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [00:46<00:22,  1.10it/s, loss=2.31, v_num=]Epoch 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [00:46<00:22,  1.10it/s, loss=2.28, v_num=]Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [00:46<00:21,  1.12it/s, loss=2.28, v_num=]Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [00:46<00:21,  1.12it/s, loss=2.16, v_num=]Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [00:46<00:20,  1.14it/s, loss=2.16, v_num=]Epoch 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [00:46<00:20,  1.14it/s, loss=1.93, v_num=]Epoch 1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [00:46<00:19,  1.16it/s, loss=1.93, v_num=]Epoch 1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [00:46<00:19,  1.16it/s, loss=1.96, v_num=]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [00:46<00:17,  1.18it/s, loss=1.96, v_num=]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [00:46<00:17,  1.18it/s, loss=1.92, v_num=]Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [00:46<00:16,  1.20it/s, loss=1.92, v_num=]Epoch 1:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [00:46<00:16,  1.20it/s, loss=1.89, v_num=]Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [00:46<00:15,  1.22it/s, loss=1.89, v_num=]Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [00:46<00:15,  1.22it/s, loss=1.83, v_num=]Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [00:46<00:14,  1.23it/s, loss=1.83, v_num=]Epoch 1:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [00:46<00:14,  1.23it/s, loss=1.74, v_num=]Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [00:47<00:13,  1.25it/s, loss=1.74, v_num=]Epoch 1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [00:47<00:13,  1.25it/s, loss=1.75, v_num=]Epoch 1:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [00:47<00:12,  1.27it/s, loss=1.75, v_num=]Epoch 1:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [00:47<00:12,  1.27it/s, loss=1.73, v_num=]Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [00:47<00:11,  1.29it/s, loss=1.73, v_num=]Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [00:47<00:11,  1.29it/s, loss=1.63, v_num=]Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [00:47<00:10,  1.31it/s, loss=1.63, v_num=]Epoch 1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [00:47<00:10,  1.31it/s, loss=1.65, v_num=]Epoch 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [00:47<00:09,  1.32it/s, loss=1.65, v_num=]Epoch 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [00:47<00:09,  1.32it/s, loss=1.49, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 44.18it/s][AEpoch 1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 64/76 [00:47<00:08,  1.34it/s, loss=1.49, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 44.90it/s][AEpoch 1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 65/76 [00:47<00:08,  1.36it/s, loss=1.49, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 42.97it/s][AEpoch 1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 66/76 [00:47<00:07,  1.39it/s, loss=1.49, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 42.15it/s][AEpoch 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 67/76 [00:47<00:06,  1.41it/s, loss=1.49, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 41.65it/s][AEpoch 1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 68/76 [00:47<00:05,  1.43it/s, loss=1.49, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 41.30it/s][AEpoch 1:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 69/76 [00:47<00:04,  1.45it/s, loss=1.49, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 41.05it/s][AEpoch 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/76 [00:47<00:04,  1.47it/s, loss=1.49, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 40.89it/s][AEpoch 1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 71/76 [00:47<00:03,  1.49it/s, loss=1.49, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 40.75it/s][AEpoch 1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72/76 [00:47<00:02,  1.51it/s, loss=1.49, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 40.69it/s][AEpoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 73/76 [00:47<00:01,  1.53it/s, loss=1.49, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 40.62it/s][AEpoch 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 74/76 [00:47<00:01,  1.55it/s, loss=1.49, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 40.59it/s][AEpoch 1:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 75/76 [00:47<00:00,  1.57it/s, loss=1.49, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 40.55it/s][AEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:47<00:00,  1.59it/s, loss=1.49, v_num=]Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:48<00:00,  1.56it/s, loss=1.49, v_num=]
                                                                        [AEpoch 1, global step 8: 'val_rmse' reached 1.01569 (best 1.01569), saving model to '/mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923/epoch=1-step=8.ckpt' as top 3
Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:39<00:00,  1.31s/it, loss=1.49, v_num=]Epoch 1:   0%|          | 0/76 [00:00<?, ?it/s, loss=1.49, v_num=]         Epoch 2:   0%|          | 0/76 [00:00<?, ?it/s, loss=1.49, v_num=]Epoch 2:   1%|â–         | 1/76 [00:00<00:09,  8.22it/s, loss=1.49, v_num=]Epoch 2:   1%|â–         | 1/76 [00:00<00:09,  8.16it/s, loss=1.51, v_num=]Epoch 2:   3%|â–Ž         | 2/76 [00:00<00:07,  9.28it/s, loss=1.51, v_num=]Epoch 2:   3%|â–Ž         | 2/76 [00:00<00:08,  9.23it/s, loss=1.48, v_num=]Epoch 2:   4%|â–         | 3/76 [00:00<00:08,  9.11it/s, loss=1.48, v_num=]Epoch 2:   4%|â–         | 3/76 [00:00<00:08,  9.08it/s, loss=1.49, v_num=]Epoch 2:   5%|â–Œ         | 4/76 [00:00<00:07,  9.75it/s, loss=1.49, v_num=]Epoch 2:   5%|â–Œ         | 4/76 [00:00<00:07,  9.73it/s, loss=1.5, v_num=] Epoch 2:   7%|â–‹         | 5/76 [00:00<00:07,  9.87it/s, loss=1.5, v_num=]Epoch 2:   7%|â–‹         | 5/76 [00:00<00:07,  9.85it/s, loss=1.53, v_num=]Epoch 2:   8%|â–Š         | 6/76 [00:00<00:06, 10.10it/s, loss=1.53, v_num=]Epoch 2:   8%|â–Š         | 6/76 [00:00<00:06, 10.09it/s, loss=1.55, v_num=]Epoch 2:   9%|â–‰         | 7/76 [00:00<00:06, 10.24it/s, loss=1.55, v_num=]Epoch 2:   9%|â–‰         | 7/76 [00:00<00:06, 10.23it/s, loss=1.53, v_num=]Epoch 2:  11%|â–ˆ         | 8/76 [00:00<00:06, 10.49it/s, loss=1.53, v_num=]Epoch 2:  11%|â–ˆ         | 8/76 [00:00<00:06, 10.49it/s, loss=1.55, v_num=]Epoch 2:  12%|â–ˆâ–        | 9/76 [00:00<00:06, 10.60it/s, loss=1.55, v_num=]Epoch 2:  12%|â–ˆâ–        | 9/76 [00:00<00:06, 10.59it/s, loss=1.57, v_num=]Epoch 2:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:06, 10.63it/s, loss=1.57, v_num=]Epoch 2:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:06, 10.62it/s, loss=1.56, v_num=]Epoch 2:  14%|â–ˆâ–        | 11/76 [00:01<00:06, 10.66it/s, loss=1.56, v_num=]Epoch 2:  14%|â–ˆâ–        | 11/76 [00:01<00:06, 10.65it/s, loss=1.51, v_num=]Epoch 2:  16%|â–ˆâ–Œ        | 12/76 [00:01<00:05, 10.68it/s, loss=1.51, v_num=]Epoch 2:  16%|â–ˆâ–Œ        | 12/76 [00:01<00:05, 10.67it/s, loss=1.53, v_num=]Epoch 2:  17%|â–ˆâ–‹        | 13/76 [00:01<00:05, 10.67it/s, loss=1.53, v_num=]Epoch 2:  17%|â–ˆâ–‹        | 13/76 [00:01<00:05, 10.66it/s, loss=1.47, v_num=]Epoch 2:  18%|â–ˆâ–Š        | 14/76 [00:01<00:05, 10.83it/s, loss=1.47, v_num=]Epoch 2:  18%|â–ˆâ–Š        | 14/76 [00:01<00:05, 10.82it/s, loss=1.38, v_num=]Epoch 2:  20%|â–ˆâ–‰        | 15/76 [00:01<00:05, 10.82it/s, loss=1.38, v_num=]Epoch 2:  20%|â–ˆâ–‰        | 15/76 [00:01<00:05, 10.81it/s, loss=1.43, v_num=]Epoch 2:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:05, 10.62it/s, loss=1.43, v_num=]Epoch 2:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:05, 10.62it/s, loss=1.4, v_num=] Epoch 2:  22%|â–ˆâ–ˆâ–       | 17/76 [00:03<00:12,  4.84it/s, loss=1.4, v_num=]Epoch 2:  22%|â–ˆâ–ˆâ–       | 17/76 [00:03<00:12,  4.84it/s, loss=1.39, v_num=]Epoch 2:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:04<00:14,  4.11it/s, loss=1.39, v_num=]Epoch 2:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:04<00:14,  4.11it/s, loss=1.42, v_num=]Epoch 2:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:05<00:15,  3.63it/s, loss=1.42, v_num=]Epoch 2:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:05<00:15,  3.63it/s, loss=1.23, v_num=]Epoch 2:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:06<00:17,  3.28it/s, loss=1.23, v_num=]Epoch 2:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:06<00:17,  3.28it/s, loss=1.22, v_num=]Epoch 2:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:06<00:17,  3.06it/s, loss=1.22, v_num=]Epoch 2:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:06<00:17,  3.06it/s, loss=1.2, v_num=] Epoch 2:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:07<00:18,  2.94it/s, loss=1.2, v_num=]Epoch 2:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:07<00:18,  2.94it/s, loss=1.13, v_num=]Epoch 2:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:13<00:30,  1.76it/s, loss=1.13, v_num=]Epoch 2:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:13<00:30,  1.75it/s, loss=1.12, v_num=]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:21<00:47,  1.10it/s, loss=1.12, v_num=]Epoch 2:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:21<00:47,  1.10it/s, loss=1.21, v_num=]Epoch 2:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:22<00:46,  1.11it/s, loss=1.21, v_num=]Epoch 2:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:22<00:46,  1.11it/s, loss=1.18, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 42.41it/s][AEpoch 2:  34%|â–ˆâ–ˆâ–ˆâ–      | 26/76 [00:22<00:43,  1.15it/s, loss=1.18, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 40.73it/s][AEpoch 2:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/76 [00:22<00:41,  1.19it/s, loss=1.18, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 35.17it/s][AEpoch 2:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/76 [00:22<00:38,  1.23it/s, loss=1.18, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 36.45it/s][AEpoch 2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 29/76 [00:22<00:36,  1.28it/s, loss=1.18, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 36.57it/s][AEpoch 2:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 30/76 [00:22<00:34,  1.32it/s, loss=1.18, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 36.43it/s][AEpoch 2:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 31/76 [00:22<00:33,  1.36it/s, loss=1.18, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 36.31it/s][AEpoch 2:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/76 [00:22<00:31,  1.40it/s, loss=1.18, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 36.35it/s][AEpoch 2:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 33/76 [00:22<00:29,  1.44it/s, loss=1.18, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 34.65it/s][AEpoch 2:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/76 [00:22<00:28,  1.49it/s, loss=1.18, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 32.67it/s][AEpoch 2:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 35/76 [00:22<00:26,  1.53it/s, loss=1.18, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 31.26it/s][AEpoch 2:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 36/76 [00:22<00:25,  1.57it/s, loss=1.18, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 31.51it/s][AEpoch 2:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 37/76 [00:23<00:24,  1.61it/s, loss=1.18, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 31.87it/s][AEpoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:23<00:23,  1.65it/s, loss=1.18, v_num=]Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:23<00:23,  1.64it/s, loss=1.18, v_num=]
                                                                        [AEpoch 2, global step 9: 'val_rmse' reached 1.00427 (best 1.00427), saving model to '/mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923/epoch=2-step=9.ckpt' as top 3
Epoch 2:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [01:18<01:14,  2.00s/it, loss=1.18, v_num=]Epoch 2:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [01:18<01:14,  2.00s/it, loss=1.31, v_num=]Epoch 2:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [01:19<01:11,  1.98s/it, loss=1.31, v_num=]Epoch 2:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [01:19<01:11,  1.98s/it, loss=1.44, v_num=]Epoch 2:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [01:19<01:08,  1.95s/it, loss=1.44, v_num=]Epoch 2:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [01:19<01:08,  1.95s/it, loss=1.43, v_num=]Epoch 2:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [01:20<01:05,  1.92s/it, loss=1.43, v_num=]Epoch 2:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [01:20<01:05,  1.92s/it, loss=1.4, v_num=] Epoch 2:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [01:21<01:02,  1.89s/it, loss=1.4, v_num=]Epoch 2:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [01:21<01:02,  1.89s/it, loss=1.42, v_num=]Epoch 2:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [01:22<00:59,  1.87s/it, loss=1.42, v_num=]Epoch 2:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [01:22<00:59,  1.87s/it, loss=1.41, v_num=]Epoch 2:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [01:23<00:57,  1.85s/it, loss=1.41, v_num=]Epoch 2:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [01:23<00:57,  1.85s/it, loss=1.65, v_num=]Epoch 2:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [01:23<00:54,  1.82s/it, loss=1.65, v_num=]Epoch 2:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [01:23<00:54,  1.82s/it, loss=1.69, v_num=]Epoch 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [01:23<00:51,  1.78s/it, loss=1.69, v_num=]Epoch 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [01:23<00:51,  1.78s/it, loss=1.69, v_num=]Epoch 2:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [01:23<00:48,  1.75s/it, loss=1.69, v_num=]Epoch 2:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [01:23<00:48,  1.75s/it, loss=1.71, v_num=]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [01:23<00:46,  1.71s/it, loss=1.71, v_num=]Epoch 2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [01:23<00:46,  1.71s/it, loss=1.71, v_num=]Epoch 2:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [01:23<00:43,  1.68s/it, loss=1.71, v_num=]Epoch 2:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [01:23<00:43,  1.68s/it, loss=1.73, v_num=]Epoch 2:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [01:24<00:41,  1.65s/it, loss=1.73, v_num=]Epoch 2:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [01:24<00:41,  1.65s/it, loss=1.75, v_num=]Epoch 2:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [01:24<00:38,  1.62s/it, loss=1.75, v_num=]Epoch 2:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [01:24<00:38,  1.62s/it, loss=1.77, v_num=]Epoch 2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [01:24<00:36,  1.59s/it, loss=1.77, v_num=]Epoch 2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [01:24<00:36,  1.59s/it, loss=1.76, v_num=]Epoch 2:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [01:24<00:34,  1.56s/it, loss=1.76, v_num=]Epoch 2:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [01:24<00:34,  1.56s/it, loss=1.78, v_num=]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [01:24<00:32,  1.53s/it, loss=1.78, v_num=]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [01:24<00:32,  1.53s/it, loss=1.89, v_num=]Epoch 2:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [01:24<00:30,  1.51s/it, loss=1.89, v_num=]Epoch 2:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [01:24<00:30,  1.51s/it, loss=1.92, v_num=]Epoch 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [01:24<00:28,  1.48s/it, loss=1.92, v_num=]Epoch 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [01:24<00:28,  1.48s/it, loss=1.87, v_num=]Epoch 2:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [01:24<00:26,  1.46s/it, loss=1.87, v_num=]Epoch 2:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [01:24<00:26,  1.46s/it, loss=1.89, v_num=]Epoch 2:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [01:24<00:24,  1.44s/it, loss=1.89, v_num=]Epoch 2:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [01:24<00:24,  1.44s/it, loss=1.7, v_num=] Epoch 2:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [01:24<00:22,  1.41s/it, loss=1.7, v_num=]Epoch 2:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [01:24<00:22,  1.41s/it, loss=1.57, v_num=]Epoch 2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [01:24<00:20,  1.39s/it, loss=1.57, v_num=]Epoch 2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [01:24<00:20,  1.39s/it, loss=1.67, v_num=]Epoch 2:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [01:24<00:19,  1.37s/it, loss=1.67, v_num=]Epoch 2:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [01:24<00:19,  1.37s/it, loss=1.72, v_num=]Epoch 2:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [01:25<00:17,  1.35s/it, loss=1.72, v_num=]Epoch 2:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [01:25<00:17,  1.35s/it, loss=1.68, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 42.25it/s][AEpoch 2:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 64/76 [01:25<00:15,  1.33s/it, loss=1.68, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 42.24it/s][AEpoch 2:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 65/76 [01:25<00:14,  1.31s/it, loss=1.68, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 40.25it/s][AEpoch 2:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 66/76 [01:25<00:12,  1.29s/it, loss=1.68, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 35.65it/s][AEpoch 2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 67/76 [01:25<00:11,  1.27s/it, loss=1.68, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 34.41it/s][AEpoch 2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 68/76 [01:25<00:10,  1.25s/it, loss=1.68, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 34.38it/s][AEpoch 2:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 69/76 [01:25<00:08,  1.24s/it, loss=1.68, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 34.61it/s][AEpoch 2:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/76 [01:25<00:07,  1.22s/it, loss=1.68, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 34.86it/s][AEpoch 2:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 71/76 [01:25<00:06,  1.20s/it, loss=1.68, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 35.11it/s][AEpoch 2:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72/76 [01:25<00:04,  1.18s/it, loss=1.68, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 35.31it/s][AEpoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 73/76 [01:25<00:03,  1.17s/it, loss=1.68, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 35.47it/s][AEpoch 2:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 74/76 [01:25<00:02,  1.15s/it, loss=1.68, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 35.69it/s][AEpoch 2:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 75/76 [01:25<00:01,  1.14s/it, loss=1.68, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 35.90it/s][AEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:25<00:00,  1.12s/it, loss=1.68, v_num=]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:26<00:00,  1.13s/it, loss=1.68, v_num=]
                                                                        [AEpoch 2, global step 12: 'val_rmse' was not in top 3
Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:50<00:00,  1.46s/it, loss=1.68, v_num=]Epoch 2:   0%|          | 0/76 [00:00<?, ?it/s, loss=1.68, v_num=]         Epoch 3:   0%|          | 0/76 [00:00<?, ?it/s, loss=1.68, v_num=]Epoch 3:   1%|â–         | 1/76 [00:00<00:06, 10.77it/s, loss=1.68, v_num=]Epoch 3:   1%|â–         | 1/76 [00:00<00:07, 10.68it/s, loss=1.69, v_num=]Epoch 3:   3%|â–Ž         | 2/76 [00:00<00:06, 12.07it/s, loss=1.69, v_num=]Epoch 3:   3%|â–Ž         | 2/76 [00:00<00:06, 12.02it/s, loss=1.44, v_num=]Epoch 3:   4%|â–         | 3/76 [00:00<00:06, 11.94it/s, loss=1.44, v_num=]Epoch 3:   4%|â–         | 3/76 [00:00<00:06, 11.90it/s, loss=1.48, v_num=]Epoch 3:   5%|â–Œ         | 4/76 [00:00<00:05, 12.18it/s, loss=1.48, v_num=]Epoch 3:   5%|â–Œ         | 4/76 [00:00<00:05, 12.16it/s, loss=1.45, v_num=]Epoch 3:   7%|â–‹         | 5/76 [00:00<00:05, 12.48it/s, loss=1.45, v_num=]Epoch 3:   7%|â–‹         | 5/76 [00:00<00:05, 12.46it/s, loss=1.37, v_num=]Epoch 3:   8%|â–Š         | 6/76 [00:00<00:05, 12.36it/s, loss=1.37, v_num=]Epoch 3:   8%|â–Š         | 6/76 [00:00<00:05, 12.34it/s, loss=1.34, v_num=]Epoch 3:   9%|â–‰         | 7/76 [00:00<00:05, 12.14it/s, loss=1.34, v_num=]Epoch 3:   9%|â–‰         | 7/76 [00:00<00:05, 12.13it/s, loss=1.35, v_num=]Epoch 3:  11%|â–ˆ         | 8/76 [00:00<00:05, 12.30it/s, loss=1.35, v_num=]Epoch 3:  11%|â–ˆ         | 8/76 [00:00<00:05, 12.29it/s, loss=1.32, v_num=]Epoch 3:  12%|â–ˆâ–        | 9/76 [00:00<00:05, 12.52it/s, loss=1.32, v_num=]Epoch 3:  12%|â–ˆâ–        | 9/76 [00:00<00:05, 12.51it/s, loss=1.33, v_num=]Epoch 3:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:05, 12.75it/s, loss=1.33, v_num=]Epoch 3:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:05, 12.74it/s, loss=1.38, v_num=]Epoch 3:  14%|â–ˆâ–        | 11/76 [00:00<00:05, 12.74it/s, loss=1.38, v_num=]Epoch 3:  14%|â–ˆâ–        | 11/76 [00:00<00:05, 12.73it/s, loss=1.38, v_num=]Epoch 3:  16%|â–ˆâ–Œ        | 12/76 [00:00<00:05, 12.72it/s, loss=1.38, v_num=]Epoch 3:  16%|â–ˆâ–Œ        | 12/76 [00:00<00:05, 12.71it/s, loss=1.33, v_num=]Epoch 3:  17%|â–ˆâ–‹        | 13/76 [00:01<00:05, 12.57it/s, loss=1.33, v_num=]Epoch 3:  17%|â–ˆâ–‹        | 13/76 [00:01<00:05, 12.56it/s, loss=1.35, v_num=]Epoch 3:  18%|â–ˆâ–Š        | 14/76 [00:01<00:05, 12.37it/s, loss=1.35, v_num=]Epoch 3:  18%|â–ˆâ–Š        | 14/76 [00:01<00:05, 12.36it/s, loss=1.36, v_num=]Epoch 3:  20%|â–ˆâ–‰        | 15/76 [00:01<00:04, 12.28it/s, loss=1.36, v_num=]Epoch 3:  20%|â–ˆâ–‰        | 15/76 [00:01<00:04, 12.27it/s, loss=1.4, v_num=] Epoch 3:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:05, 11.63it/s, loss=1.4, v_num=]Epoch 3:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:05, 11.62it/s, loss=1.46, v_num=]Epoch 3:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:05, 11.65it/s, loss=1.46, v_num=]Epoch 3:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:05, 11.65it/s, loss=1.45, v_num=]Epoch 3:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:04, 11.65it/s, loss=1.45, v_num=]Epoch 3:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:04, 11.64it/s, loss=1.35, v_num=]Epoch 3:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:04, 11.62it/s, loss=1.35, v_num=]Epoch 3:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:04, 11.61it/s, loss=1.5, v_num=] Epoch 3:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:01<00:04, 11.60it/s, loss=1.5, v_num=]Epoch 3:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:01<00:04, 11.59it/s, loss=1.47, v_num=]Epoch 3:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:01<00:04, 11.54it/s, loss=1.47, v_num=]Epoch 3:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:01<00:04, 11.54it/s, loss=1.49, v_num=]Epoch 3:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:01<00:04, 11.51it/s, loss=1.49, v_num=]Epoch 3:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:01<00:04, 11.50it/s, loss=1.46, v_num=]Epoch 3:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:01<00:04, 11.51it/s, loss=1.46, v_num=]Epoch 3:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:01<00:04, 11.51it/s, loss=1.44, v_num=]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:02<00:04, 11.49it/s, loss=1.44, v_num=]Epoch 3:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:02<00:04, 11.49it/s, loss=1.51, v_num=]Epoch 3:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:02<00:04, 11.49it/s, loss=1.51, v_num=]Epoch 3:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:02<00:04, 11.48it/s, loss=1.56, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 35.75it/s][AEpoch 3:  34%|â–ˆâ–ˆâ–ˆâ–      | 26/76 [00:02<00:04, 11.61it/s, loss=1.56, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 37.62it/s][AEpoch 3:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/76 [00:02<00:04, 11.93it/s, loss=1.56, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 35.87it/s][AEpoch 3:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/76 [00:02<00:03, 12.20it/s, loss=1.56, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 37.82it/s][AEpoch 3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 29/76 [00:02<00:03, 12.52it/s, loss=1.56, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 37.99it/s][AEpoch 3:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 30/76 [00:02<00:03, 12.81it/s, loss=1.56, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 38.06it/s][AEpoch 3:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 31/76 [00:02<00:03, 13.09it/s, loss=1.56, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 38.05it/s][AEpoch 3:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/76 [00:02<00:03, 13.36it/s, loss=1.56, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 37.96it/s][AEpoch 3:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 33/76 [00:02<00:03, 13.63it/s, loss=1.56, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 37.97it/s][AEpoch 3:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/76 [00:02<00:03, 13.89it/s, loss=1.56, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 38.11it/s][AEpoch 3:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 35/76 [00:02<00:02, 14.15it/s, loss=1.56, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 38.30it/s][AEpoch 3:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 36/76 [00:02<00:02, 14.41it/s, loss=1.56, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 38.49it/s][AEpoch 3:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 37/76 [00:02<00:02, 14.67it/s, loss=1.56, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 38.65it/s][AEpoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:02<00:02, 14.92it/s, loss=1.56, v_num=]Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:03<00:03, 11.43it/s, loss=1.56, v_num=]
                                                                        [AEpoch 3, global step 13: 'val_rmse' reached 1.02476 (best 1.00427), saving model to '/mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923/epoch=3-step=13.ckpt' as top 3
Epoch 3:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:55<00:52,  1.41s/it, loss=1.56, v_num=]Epoch 3:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:55<00:52,  1.41s/it, loss=1.56, v_num=]Epoch 3:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:55<00:49,  1.38s/it, loss=1.56, v_num=]Epoch 3:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:55<00:49,  1.38s/it, loss=1.53, v_num=]Epoch 3:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:55<00:47,  1.35s/it, loss=1.53, v_num=]Epoch 3:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:55<00:47,  1.35s/it, loss=1.75, v_num=]Epoch 3:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:55<00:44,  1.32s/it, loss=1.75, v_num=]Epoch 3:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:55<00:44,  1.32s/it, loss=1.68, v_num=]Epoch 3:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:55<00:42,  1.29s/it, loss=1.68, v_num=]Epoch 3:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:55<00:42,  1.29s/it, loss=1.63, v_num=]Epoch 3:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:55<00:40,  1.26s/it, loss=1.63, v_num=]Epoch 3:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:55<00:40,  1.26s/it, loss=1.6, v_num=] Epoch 3:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:55<00:38,  1.23s/it, loss=1.6, v_num=]Epoch 3:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:55<00:38,  1.23s/it, loss=1.53, v_num=]Epoch 3:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:55<00:36,  1.21s/it, loss=1.53, v_num=]Epoch 3:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:55<00:36,  1.21s/it, loss=1.51, v_num=]Epoch 3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [00:55<00:34,  1.18s/it, loss=1.51, v_num=]Epoch 3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [00:55<00:34,  1.18s/it, loss=1.48, v_num=]Epoch 3:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [00:55<00:32,  1.16s/it, loss=1.48, v_num=]Epoch 3:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [00:55<00:32,  1.16s/it, loss=1.4, v_num=] Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [00:55<00:30,  1.14s/it, loss=1.4, v_num=]Epoch 3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [00:55<00:30,  1.14s/it, loss=1.32, v_num=]Epoch 3:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [00:55<00:29,  1.12s/it, loss=1.32, v_num=]Epoch 3:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [00:55<00:29,  1.12s/it, loss=1.34, v_num=]Epoch 3:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [00:55<00:27,  1.10s/it, loss=1.34, v_num=]Epoch 3:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [00:55<00:27,  1.10s/it, loss=1.32, v_num=]Epoch 3:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [00:56<00:25,  1.08s/it, loss=1.32, v_num=]Epoch 3:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [00:56<00:25,  1.08s/it, loss=1.12, v_num=]Epoch 3:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [00:56<00:24,  1.06s/it, loss=1.12, v_num=]Epoch 3:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [00:56<00:24,  1.06s/it, loss=1.12, v_num=]Epoch 3:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [00:56<00:22,  1.04s/it, loss=1.12, v_num=]Epoch 3:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [00:56<00:22,  1.04s/it, loss=1.28, v_num=]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [00:56<00:21,  1.02s/it, loss=1.28, v_num=]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [00:56<00:21,  1.02s/it, loss=1.33, v_num=]Epoch 3:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [00:56<00:20,  1.01s/it, loss=1.33, v_num=]Epoch 3:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [00:56<00:20,  1.01s/it, loss=1.26, v_num=]Epoch 3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [00:56<00:18,  1.01it/s, loss=1.26, v_num=]Epoch 3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [00:56<00:18,  1.01it/s, loss=1.21, v_num=]Epoch 3:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [00:56<00:17,  1.03it/s, loss=1.21, v_num=]Epoch 3:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [00:56<00:17,  1.03it/s, loss=1.16, v_num=]Epoch 3:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [00:56<00:16,  1.04it/s, loss=1.16, v_num=]Epoch 3:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [00:56<00:16,  1.04it/s, loss=1.19, v_num=]Epoch 3:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [00:56<00:15,  1.06it/s, loss=1.19, v_num=]Epoch 3:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [00:56<00:15,  1.06it/s, loss=1.22, v_num=]Epoch 3:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [00:56<00:13,  1.08it/s, loss=1.22, v_num=]Epoch 3:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [00:56<00:13,  1.08it/s, loss=0.993, v_num=]Epoch 3:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [00:56<00:12,  1.09it/s, loss=0.993, v_num=]Epoch 3:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [00:56<00:12,  1.09it/s, loss=1.09, v_num=] Epoch 3:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [00:56<00:11,  1.11it/s, loss=1.09, v_num=]Epoch 3:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [00:56<00:11,  1.11it/s, loss=1.08, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 50.89it/s][AEpoch 3:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 64/76 [00:56<00:10,  1.12it/s, loss=1.08, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 50.13it/s][AEpoch 3:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 65/76 [00:56<00:09,  1.14it/s, loss=1.08, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 47.64it/s][AEpoch 3:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 66/76 [00:56<00:08,  1.16it/s, loss=1.08, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 46.60it/s][AEpoch 3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 67/76 [00:56<00:07,  1.18it/s, loss=1.08, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 46.02it/s][AEpoch 3:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 68/76 [00:57<00:06,  1.19it/s, loss=1.08, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 45.52it/s][AEpoch 3:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 69/76 [00:57<00:05,  1.21it/s, loss=1.08, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 45.32it/s][AEpoch 3:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/76 [00:57<00:04,  1.23it/s, loss=1.08, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 45.14it/s][AEpoch 3:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 71/76 [00:57<00:04,  1.24it/s, loss=1.08, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 44.96it/s][AEpoch 3:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72/76 [00:57<00:03,  1.26it/s, loss=1.08, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 44.80it/s][AEpoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 73/76 [00:57<00:02,  1.28it/s, loss=1.08, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 44.67it/s][AEpoch 3:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 74/76 [00:57<00:01,  1.29it/s, loss=1.08, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 44.53it/s][AEpoch 3:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 75/76 [00:57<00:00,  1.31it/s, loss=1.08, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 44.43it/s][AEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:57<00:00,  1.33it/s, loss=1.08, v_num=]Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:57<00:00,  1.33it/s, loss=1.08, v_num=]
                                                                        [AEpoch 3, global step 16: 'val_rmse' was not in top 3
Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:23<00:00,  1.10s/it, loss=1.08, v_num=]Epoch 3:   0%|          | 0/76 [00:00<?, ?it/s, loss=1.08, v_num=]         Epoch 4:   0%|          | 0/76 [00:00<?, ?it/s, loss=1.08, v_num=]Epoch 4:   1%|â–         | 1/76 [00:00<00:05, 12.79it/s, loss=1.08, v_num=]Epoch 4:   1%|â–         | 1/76 [00:00<00:05, 12.70it/s, loss=1.1, v_num=] Epoch 4:   3%|â–Ž         | 2/76 [00:00<00:04, 14.90it/s, loss=1.1, v_num=]Epoch 4:   3%|â–Ž         | 2/76 [00:00<00:04, 14.85it/s, loss=1.12, v_num=]Epoch 4:   4%|â–         | 3/76 [00:00<00:04, 15.55it/s, loss=1.12, v_num=]Epoch 4:   4%|â–         | 3/76 [00:00<00:04, 15.52it/s, loss=1.05, v_num=]Epoch 4:   5%|â–Œ         | 4/76 [00:00<00:04, 16.07it/s, loss=1.05, v_num=]Epoch 4:   5%|â–Œ         | 4/76 [00:00<00:04, 16.04it/s, loss=1.06, v_num=]Epoch 4:   7%|â–‹         | 5/76 [00:00<00:04, 16.13it/s, loss=1.06, v_num=]Epoch 4:   7%|â–‹         | 5/76 [00:00<00:04, 16.11it/s, loss=1.1, v_num=] Epoch 4:   8%|â–Š         | 6/76 [00:00<00:04, 16.48it/s, loss=1.1, v_num=]Epoch 4:   8%|â–Š         | 6/76 [00:00<00:04, 16.46it/s, loss=1.11, v_num=]Epoch 4:   9%|â–‰         | 7/76 [00:00<00:04, 16.20it/s, loss=1.11, v_num=]Epoch 4:   9%|â–‰         | 7/76 [00:00<00:04, 16.18it/s, loss=1.17, v_num=]Epoch 4:  11%|â–ˆ         | 8/76 [00:00<00:04, 16.13it/s, loss=1.17, v_num=]Epoch 4:  11%|â–ˆ         | 8/76 [00:00<00:04, 16.11it/s, loss=1.24, v_num=]Epoch 4:  12%|â–ˆâ–        | 9/76 [00:00<00:04, 16.12it/s, loss=1.24, v_num=]Epoch 4:  12%|â–ˆâ–        | 9/76 [00:00<00:04, 16.10it/s, loss=1.29, v_num=]Epoch 4:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:04, 15.95it/s, loss=1.29, v_num=]Epoch 4:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:04, 15.94it/s, loss=1.36, v_num=]Epoch 4:  14%|â–ˆâ–        | 11/76 [00:00<00:04, 15.96it/s, loss=1.36, v_num=]Epoch 4:  14%|â–ˆâ–        | 11/76 [00:00<00:04, 15.94it/s, loss=1.2, v_num=] Epoch 4:  16%|â–ˆâ–Œ        | 12/76 [00:00<00:04, 15.80it/s, loss=1.2, v_num=]Epoch 4:  16%|â–ˆâ–Œ        | 12/76 [00:00<00:04, 15.79it/s, loss=1.2, v_num=]Epoch 4:  17%|â–ˆâ–‹        | 13/76 [00:00<00:04, 15.73it/s, loss=1.2, v_num=]Epoch 4:  17%|â–ˆâ–‹        | 13/76 [00:00<00:04, 15.72it/s, loss=1.19, v_num=]Epoch 4:  18%|â–ˆâ–Š        | 14/76 [00:00<00:03, 15.62it/s, loss=1.19, v_num=]Epoch 4:  18%|â–ˆâ–Š        | 14/76 [00:00<00:03, 15.61it/s, loss=1.22, v_num=]Epoch 4:  20%|â–ˆâ–‰        | 15/76 [00:00<00:03, 15.63it/s, loss=1.22, v_num=]Epoch 4:  20%|â–ˆâ–‰        | 15/76 [00:00<00:03, 15.62it/s, loss=1.2, v_num=] Epoch 4:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:04, 14.91it/s, loss=1.2, v_num=]Epoch 4:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:04, 14.90it/s, loss=1.15, v_num=]Epoch 4:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:03, 14.87it/s, loss=1.15, v_num=]Epoch 4:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:03, 14.86it/s, loss=1.15, v_num=]Epoch 4:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:03, 14.95it/s, loss=1.15, v_num=]Epoch 4:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:03, 14.95it/s, loss=1.21, v_num=]Epoch 4:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:03, 14.99it/s, loss=1.21, v_num=]Epoch 4:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:03, 14.98it/s, loss=1.13, v_num=]Epoch 4:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:01<00:03, 15.00it/s, loss=1.13, v_num=]Epoch 4:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:01<00:03, 14.99it/s, loss=1.15, v_num=]Epoch 4:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:01<00:03, 15.01it/s, loss=1.15, v_num=]Epoch 4:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:01<00:03, 15.00it/s, loss=1.2, v_num=] Epoch 4:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:01<00:03, 15.09it/s, loss=1.2, v_num=]Epoch 4:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:01<00:03, 15.09it/s, loss=1.2, v_num=]Epoch 4:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:01<00:03, 15.15it/s, loss=1.2, v_num=]Epoch 4:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:01<00:03, 15.15it/s, loss=1.26, v_num=]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:01<00:03, 15.20it/s, loss=1.26, v_num=]Epoch 4:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:01<00:03, 15.19it/s, loss=1.28, v_num=]Epoch 4:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:01<00:03, 15.26it/s, loss=1.28, v_num=]Epoch 4:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:01<00:03, 15.25it/s, loss=1.28, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 45.85it/s][AEpoch 4:  34%|â–ˆâ–ˆâ–ˆâ–      | 26/76 [00:01<00:03, 15.44it/s, loss=1.28, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 42.38it/s][AEpoch 4:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/76 [00:01<00:03, 15.80it/s, loss=1.28, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 37.50it/s][AEpoch 4:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/76 [00:01<00:02, 16.08it/s, loss=1.28, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 39.90it/s][AEpoch 4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 29/76 [00:01<00:02, 16.46it/s, loss=1.28, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 39.87it/s][AEpoch 4:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 30/76 [00:01<00:02, 16.79it/s, loss=1.28, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 39.56it/s][AEpoch 4:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 31/76 [00:01<00:02, 17.09it/s, loss=1.28, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 39.60it/s][AEpoch 4:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/76 [00:01<00:02, 17.41it/s, loss=1.28, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 39.41it/s][AEpoch 4:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 33/76 [00:01<00:02, 17.70it/s, loss=1.28, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 39.37it/s][AEpoch 4:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/76 [00:01<00:02, 17.99it/s, loss=1.28, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 39.31it/s][AEpoch 4:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 35/76 [00:01<00:02, 18.27it/s, loss=1.28, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 39.12it/s][AEpoch 4:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 36/76 [00:01<00:02, 18.53it/s, loss=1.28, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 39.15it/s][AEpoch 4:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 37/76 [00:01<00:02, 18.80it/s, loss=1.28, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 39.18it/s][AEpoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:01<00:01, 19.06it/s, loss=1.28, v_num=]Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:02<00:02, 17.81it/s, loss=1.28, v_num=]
                                                                        [AEpoch 4, global step 17: 'val_rmse' reached 1.01783 (best 1.00427), saving model to '/mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923/epoch=4-step=17.ckpt' as top 3
Epoch 4:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:56<00:54,  1.46s/it, loss=1.28, v_num=]Epoch 4:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:59<00:56,  1.53s/it, loss=1.44, v_num=]Epoch 4:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:59<00:53,  1.49s/it, loss=1.44, v_num=]Epoch 4:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:59<00:53,  1.49s/it, loss=1.38, v_num=]Epoch 4:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:59<00:50,  1.45s/it, loss=1.38, v_num=]Epoch 4:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:59<00:50,  1.45s/it, loss=1.36, v_num=]Epoch 4:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:59<00:48,  1.42s/it, loss=1.36, v_num=]Epoch 4:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:59<00:48,  1.42s/it, loss=1.32, v_num=]Epoch 4:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:59<00:45,  1.39s/it, loss=1.32, v_num=]Epoch 4:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:59<00:45,  1.39s/it, loss=1.34, v_num=]Epoch 4:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:59<00:43,  1.36s/it, loss=1.34, v_num=]Epoch 4:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:59<00:43,  1.36s/it, loss=1.32, v_num=]Epoch 4:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:59<00:41,  1.33s/it, loss=1.32, v_num=]Epoch 4:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:59<00:41,  1.33s/it, loss=1.33, v_num=]Epoch 4:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:59<00:39,  1.30s/it, loss=1.33, v_num=]Epoch 4:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:59<00:39,  1.30s/it, loss=1.35, v_num=]Epoch 4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [01:00<00:37,  1.28s/it, loss=1.35, v_num=]Epoch 4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [01:00<00:37,  1.28s/it, loss=1.36, v_num=]Epoch 4:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [01:00<00:35,  1.25s/it, loss=1.36, v_num=]Epoch 4:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [01:00<00:35,  1.25s/it, loss=1.41, v_num=]Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [01:00<00:33,  1.23s/it, loss=1.41, v_num=]Epoch 4:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [01:00<00:33,  1.23s/it, loss=1.41, v_num=]Epoch 4:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [01:00<00:31,  1.20s/it, loss=1.41, v_num=]Epoch 4:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [01:00<00:31,  1.20s/it, loss=1.39, v_num=]Epoch 4:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [01:00<00:29,  1.18s/it, loss=1.39, v_num=]Epoch 4:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [01:00<00:29,  1.18s/it, loss=1.57, v_num=]Epoch 4:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [01:00<00:27,  1.16s/it, loss=1.57, v_num=]Epoch 4:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [01:00<00:27,  1.16s/it, loss=1.63, v_num=]Epoch 4:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [01:00<00:26,  1.14s/it, loss=1.63, v_num=]Epoch 4:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [01:00<00:26,  1.14s/it, loss=1.62, v_num=]Epoch 4:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [01:00<00:24,  1.12s/it, loss=1.62, v_num=]Epoch 4:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [01:00<00:24,  1.12s/it, loss=1.53, v_num=]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [01:00<00:23,  1.10s/it, loss=1.53, v_num=]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [01:00<00:23,  1.10s/it, loss=1.59, v_num=]Epoch 4:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [01:00<00:21,  1.08s/it, loss=1.59, v_num=]Epoch 4:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [01:00<00:21,  1.08s/it, loss=1.69, v_num=]Epoch 4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [01:00<00:20,  1.06s/it, loss=1.69, v_num=]Epoch 4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [01:00<00:20,  1.06s/it, loss=1.65, v_num=]Epoch 4:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [01:00<00:18,  1.05s/it, loss=1.65, v_num=]Epoch 4:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [01:00<00:18,  1.05s/it, loss=1.6, v_num=] Epoch 4:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [01:00<00:17,  1.03s/it, loss=1.6, v_num=]Epoch 4:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [01:00<00:17,  1.03s/it, loss=1.44, v_num=]Epoch 4:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [01:00<00:16,  1.01s/it, loss=1.44, v_num=]Epoch 4:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [01:00<00:16,  1.01s/it, loss=1.45, v_num=]Epoch 4:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [01:00<00:14,  1.00it/s, loss=1.45, v_num=]Epoch 4:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [01:00<00:14,  1.00it/s, loss=1.4, v_num=] Epoch 4:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [01:01<00:13,  1.01it/s, loss=1.4, v_num=]Epoch 4:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [01:01<00:13,  1.01it/s, loss=1.39, v_num=]Epoch 4:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [01:02<00:12,  1.01it/s, loss=1.39, v_num=]Epoch 4:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [01:02<00:12,  1.01it/s, loss=1.33, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 45.80it/s][AEpoch 4:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 64/76 [01:02<00:11,  1.02it/s, loss=1.33, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 43.83it/s][AEpoch 4:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 65/76 [01:02<00:10,  1.04it/s, loss=1.33, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 38.01it/s][AEpoch 4:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 66/76 [01:02<00:09,  1.05it/s, loss=1.33, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 39.76it/s][AEpoch 4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 67/76 [01:02<00:08,  1.07it/s, loss=1.33, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 40.20it/s][AEpoch 4:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 68/76 [01:02<00:07,  1.08it/s, loss=1.33, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 39.82it/s][AEpoch 4:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 69/76 [01:02<00:06,  1.10it/s, loss=1.33, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 38.18it/s][AEpoch 4:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/76 [01:02<00:05,  1.11it/s, loss=1.33, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 37.88it/s][AEpoch 4:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 71/76 [01:02<00:04,  1.13it/s, loss=1.33, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 37.96it/s][AEpoch 4:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72/76 [01:02<00:03,  1.14it/s, loss=1.33, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 38.07it/s][AEpoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 73/76 [01:02<00:02,  1.16it/s, loss=1.33, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 37.95it/s][AEpoch 4:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 74/76 [01:03<00:01,  1.17it/s, loss=1.33, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 37.89it/s][AEpoch 4:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 75/76 [01:03<00:00,  1.19it/s, loss=1.33, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 37.97it/s][AEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:03<00:00,  1.21it/s, loss=1.33, v_num=]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:03<00:00,  1.20it/s, loss=1.33, v_num=]
                                                                        [AEpoch 4, global step 20: 'val_rmse' was not in top 3
Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:20<00:00,  1.06s/it, loss=1.33, v_num=]Epoch 4:   0%|          | 0/76 [00:00<?, ?it/s, loss=1.33, v_num=]         Epoch 5:   0%|          | 0/76 [00:00<?, ?it/s, loss=1.33, v_num=]Epoch 5:   1%|â–         | 1/76 [00:00<00:05, 13.48it/s, loss=1.33, v_num=]Epoch 5:   1%|â–         | 1/76 [00:00<00:05, 13.35it/s, loss=1.34, v_num=]Epoch 5:   3%|â–Ž         | 2/76 [00:00<00:05, 14.67it/s, loss=1.34, v_num=]Epoch 5:   3%|â–Ž         | 2/76 [00:00<00:05, 14.61it/s, loss=1.38, v_num=]Epoch 5:   4%|â–         | 3/76 [00:00<00:04, 15.12it/s, loss=1.38, v_num=]Epoch 5:   4%|â–         | 3/76 [00:00<00:04, 15.07it/s, loss=1.62, v_num=]Epoch 5:   5%|â–Œ         | 4/76 [00:00<00:04, 15.63it/s, loss=1.62, v_num=]Epoch 5:   5%|â–Œ         | 4/76 [00:00<00:04, 15.58it/s, loss=1.6, v_num=] Epoch 5:   7%|â–‹         | 5/76 [00:00<00:04, 15.66it/s, loss=1.6, v_num=]Epoch 5:   7%|â–‹         | 5/76 [00:00<00:04, 15.63it/s, loss=1.56, v_num=]Epoch 5:   8%|â–Š         | 6/76 [00:00<00:04, 15.71it/s, loss=1.56, v_num=]Epoch 5:   8%|â–Š         | 6/76 [00:00<00:04, 15.68it/s, loss=1.67, v_num=]Epoch 5:   9%|â–‰         | 7/76 [00:00<00:04, 15.68it/s, loss=1.67, v_num=]Epoch 5:   9%|â–‰         | 7/76 [00:00<00:04, 15.66it/s, loss=1.67, v_num=]Epoch 5:  11%|â–ˆ         | 8/76 [00:00<00:04, 15.34it/s, loss=1.67, v_num=]Epoch 5:  11%|â–ˆ         | 8/76 [00:00<00:04, 15.32it/s, loss=1.66, v_num=]Epoch 5:  12%|â–ˆâ–        | 9/76 [00:00<00:04, 15.35it/s, loss=1.66, v_num=]Epoch 5:  12%|â–ˆâ–        | 9/76 [00:00<00:04, 15.33it/s, loss=1.58, v_num=]Epoch 5:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:04, 15.30it/s, loss=1.58, v_num=]Epoch 5:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:04, 15.28it/s, loss=1.58, v_num=]Epoch 5:  14%|â–ˆâ–        | 11/76 [00:00<00:04, 15.25it/s, loss=1.58, v_num=]Epoch 5:  14%|â–ˆâ–        | 11/76 [00:00<00:04, 15.24it/s, loss=1.61, v_num=]Epoch 5:  16%|â–ˆâ–Œ        | 12/76 [00:00<00:04, 15.29it/s, loss=1.61, v_num=]Epoch 5:  16%|â–ˆâ–Œ        | 12/76 [00:00<00:04, 15.28it/s, loss=1.6, v_num=] Epoch 5:  17%|â–ˆâ–‹        | 13/76 [00:00<00:04, 15.15it/s, loss=1.6, v_num=]Epoch 5:  17%|â–ˆâ–‹        | 13/76 [00:00<00:04, 15.14it/s, loss=1.47, v_num=]Epoch 5:  18%|â–ˆâ–Š        | 14/76 [00:00<00:04, 15.09it/s, loss=1.47, v_num=]Epoch 5:  18%|â–ˆâ–Š        | 14/76 [00:00<00:04, 15.08it/s, loss=1.46, v_num=]Epoch 5:  20%|â–ˆâ–‰        | 15/76 [00:00<00:04, 15.20it/s, loss=1.46, v_num=]Epoch 5:  20%|â–ˆâ–‰        | 15/76 [00:00<00:04, 15.19it/s, loss=1.5, v_num=] Epoch 5:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:04, 14.40it/s, loss=1.5, v_num=]Epoch 5:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:04, 14.39it/s, loss=1.53, v_num=]Epoch 5:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:04, 14.44it/s, loss=1.53, v_num=]Epoch 5:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:04, 14.43it/s, loss=1.54, v_num=]Epoch 5:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:03, 14.51it/s, loss=1.54, v_num=]Epoch 5:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:03, 14.51it/s, loss=1.54, v_num=]Epoch 5:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:03, 14.60it/s, loss=1.54, v_num=]Epoch 5:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:03, 14.59it/s, loss=1.55, v_num=]Epoch 5:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:01<00:03, 14.64it/s, loss=1.55, v_num=]Epoch 5:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:01<00:03, 14.64it/s, loss=1.52, v_num=]Epoch 5:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:01<00:03, 14.72it/s, loss=1.52, v_num=]Epoch 5:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:01<00:03, 14.71it/s, loss=1.54, v_num=]Epoch 5:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:01<00:03, 14.76it/s, loss=1.54, v_num=]Epoch 5:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:01<00:03, 14.76it/s, loss=1.48, v_num=]Epoch 5:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:01<00:03, 14.85it/s, loss=1.48, v_num=]Epoch 5:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:01<00:03, 14.85it/s, loss=1.24, v_num=]Epoch 5:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:01<00:03, 14.97it/s, loss=1.24, v_num=]Epoch 5:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:01<00:03, 14.97it/s, loss=1.31, v_num=]Epoch 5:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:01<00:03, 14.96it/s, loss=1.31, v_num=]Epoch 5:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:01<00:03, 14.96it/s, loss=1.33, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 45.30it/s][AEpoch 5:  34%|â–ˆâ–ˆâ–ˆâ–      | 26/76 [00:01<00:03, 15.17it/s, loss=1.33, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 42.05it/s][AEpoch 5:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/76 [00:01<00:03, 15.52it/s, loss=1.33, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 39.32it/s][AEpoch 5:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/76 [00:01<00:03, 15.83it/s, loss=1.33, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 39.93it/s][AEpoch 5:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 29/76 [00:01<00:02, 16.18it/s, loss=1.33, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 39.68it/s][AEpoch 5:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 30/76 [00:01<00:02, 16.50it/s, loss=1.33, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 39.62it/s][AEpoch 5:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 31/76 [00:01<00:02, 16.82it/s, loss=1.33, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 39.64it/s][AEpoch 5:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/76 [00:01<00:02, 17.12it/s, loss=1.33, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 39.59it/s][AEpoch 5:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 33/76 [00:01<00:02, 17.42it/s, loss=1.33, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 39.51it/s][AEpoch 5:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/76 [00:01<00:02, 17.71it/s, loss=1.33, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 39.56it/s][AEpoch 5:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 35/76 [00:01<00:02, 18.00it/s, loss=1.33, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 39.52it/s][AEpoch 5:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 36/76 [00:01<00:02, 18.27it/s, loss=1.33, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 39.57it/s][AEpoch 5:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 37/76 [00:01<00:02, 18.54it/s, loss=1.33, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 39.52it/s][AEpoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:02<00:02, 18.80it/s, loss=1.33, v_num=]Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:02<00:02, 13.66it/s, loss=1.33, v_num=]
                                                                        [AEpoch 5, global step 21: 'val_rmse' was not in top 3
Epoch 5:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:21<00:20,  1.79it/s, loss=1.33, v_num=]Epoch 5:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:22<00:20,  1.77it/s, loss=1.27, v_num=]Epoch 5:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:22<00:19,  1.81it/s, loss=1.27, v_num=]Epoch 5:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:22<00:19,  1.81it/s, loss=1.31, v_num=]Epoch 5:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:22<00:18,  1.85it/s, loss=1.31, v_num=]Epoch 5:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:22<00:18,  1.85it/s, loss=1.08, v_num=]Epoch 5:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:22<00:17,  1.89it/s, loss=1.08, v_num=]Epoch 5:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:22<00:17,  1.89it/s, loss=1.11, v_num=]Epoch 5:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:22<00:17,  1.93it/s, loss=1.11, v_num=]Epoch 5:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:22<00:17,  1.93it/s, loss=1.24, v_num=]Epoch 5:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:22<00:16,  1.97it/s, loss=1.24, v_num=]Epoch 5:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:22<00:16,  1.97it/s, loss=1.25, v_num=]Epoch 5:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:22<00:15,  2.00it/s, loss=1.25, v_num=]Epoch 5:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:22<00:15,  2.00it/s, loss=1.2, v_num=] Epoch 5:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:22<00:14,  2.04it/s, loss=1.2, v_num=]Epoch 5:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:22<00:14,  2.04it/s, loss=1.16, v_num=]Epoch 5:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [00:22<00:13,  2.08it/s, loss=1.16, v_num=]Epoch 5:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [00:22<00:13,  2.08it/s, loss=1.2, v_num=] Epoch 5:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [00:22<00:13,  2.12it/s, loss=1.2, v_num=]Epoch 5:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [00:22<00:13,  2.12it/s, loss=1.18, v_num=]Epoch 5:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [00:22<00:12,  2.15it/s, loss=1.18, v_num=]Epoch 5:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [00:22<00:12,  2.15it/s, loss=1.15, v_num=]Epoch 5:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [00:22<00:11,  2.19it/s, loss=1.15, v_num=]Epoch 5:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [00:22<00:11,  2.19it/s, loss=1.12, v_num=]Epoch 5:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [00:22<00:11,  2.23it/s, loss=1.12, v_num=]Epoch 5:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [00:22<00:11,  2.23it/s, loss=1.13, v_num=]Epoch 5:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [00:22<00:10,  2.27it/s, loss=1.13, v_num=]Epoch 5:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [00:22<00:10,  2.27it/s, loss=1.12, v_num=]Epoch 5:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [00:23<00:09,  2.30it/s, loss=1.12, v_num=]Epoch 5:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [00:23<00:09,  2.30it/s, loss=1.19, v_num=]Epoch 5:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [00:23<00:09,  2.34it/s, loss=1.19, v_num=]Epoch 5:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [00:23<00:09,  2.34it/s, loss=1.22, v_num=]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [00:23<00:08,  2.38it/s, loss=1.22, v_num=]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [00:23<00:08,  2.38it/s, loss=1.19, v_num=]Epoch 5:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [00:23<00:08,  2.41it/s, loss=1.19, v_num=]Epoch 5:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [00:23<00:08,  2.41it/s, loss=1.19, v_num=]Epoch 5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [00:23<00:07,  2.45it/s, loss=1.19, v_num=]Epoch 5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [00:23<00:07,  2.45it/s, loss=1.22, v_num=]Epoch 5:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [00:23<00:07,  2.49it/s, loss=1.22, v_num=]Epoch 5:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [00:23<00:07,  2.49it/s, loss=1.18, v_num=]Epoch 5:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [00:23<00:06,  2.52it/s, loss=1.18, v_num=]Epoch 5:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [00:23<00:06,  2.52it/s, loss=1.14, v_num=]Epoch 5:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [00:23<00:06,  2.56it/s, loss=1.14, v_num=]Epoch 5:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [00:23<00:06,  2.56it/s, loss=1.1, v_num=] Epoch 5:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [00:23<00:05,  2.59it/s, loss=1.1, v_num=]Epoch 5:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [00:23<00:05,  2.59it/s, loss=1.12, v_num=]Epoch 5:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [00:23<00:05,  2.62it/s, loss=1.12, v_num=]Epoch 5:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [00:23<00:05,  2.62it/s, loss=1.09, v_num=]Epoch 5:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [00:23<00:04,  2.65it/s, loss=1.09, v_num=]Epoch 5:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [00:23<00:04,  2.65it/s, loss=0.99, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 40.88it/s][AEpoch 5:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 64/76 [00:23<00:04,  2.69it/s, loss=0.99, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 36.53it/s][AEpoch 5:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 65/76 [00:23<00:04,  2.73it/s, loss=0.99, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 33.52it/s][AEpoch 5:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 66/76 [00:23<00:03,  2.77it/s, loss=0.99, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 34.62it/s][AEpoch 5:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 67/76 [00:23<00:03,  2.80it/s, loss=0.99, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 34.96it/s][AEpoch 5:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 68/76 [00:23<00:02,  2.84it/s, loss=0.99, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 35.17it/s][AEpoch 5:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 69/76 [00:23<00:02,  2.88it/s, loss=0.99, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 35.19it/s][AEpoch 5:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/76 [00:23<00:02,  2.92it/s, loss=0.99, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 35.46it/s][AEpoch 5:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 71/76 [00:24<00:01,  2.96it/s, loss=0.99, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 35.74it/s][AEpoch 5:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72/76 [00:24<00:01,  3.00it/s, loss=0.99, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 36.02it/s][AEpoch 5:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 73/76 [00:24<00:00,  3.03it/s, loss=0.99, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 36.28it/s][AEpoch 5:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 74/76 [00:24<00:00,  3.07it/s, loss=0.99, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 36.41it/s][AEpoch 5:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 75/76 [00:24<00:00,  3.11it/s, loss=0.99, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 36.53it/s][AEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:24<00:00,  3.15it/s, loss=0.99, v_num=]Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:24<00:00,  3.06it/s, loss=0.99, v_num=]
                                                                        [AEpoch 5, global step 24: 'val_rmse' was not in top 3
Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:46<00:00,  1.63it/s, loss=0.99, v_num=]Epoch 5:   0%|          | 0/76 [00:00<?, ?it/s, loss=0.99, v_num=]         Epoch 6:   0%|          | 0/76 [00:00<?, ?it/s, loss=0.99, v_num=]Epoch 6:   1%|â–         | 1/76 [00:00<00:06, 11.07it/s, loss=0.99, v_num=]Epoch 6:   1%|â–         | 1/76 [00:00<00:06, 10.98it/s, loss=1.01, v_num=]Epoch 6:   3%|â–Ž         | 2/76 [00:00<00:05, 12.69it/s, loss=1.01, v_num=]Epoch 6:   3%|â–Ž         | 2/76 [00:00<00:05, 12.64it/s, loss=1, v_num=]   Epoch 6:   4%|â–         | 3/76 [00:00<00:05, 12.42it/s, loss=1, v_num=]Epoch 6:   4%|â–         | 3/76 [00:00<00:05, 12.38it/s, loss=1.02, v_num=]Epoch 6:   5%|â–Œ         | 4/76 [00:00<00:06, 11.98it/s, loss=1.02, v_num=]Epoch 6:   5%|â–Œ         | 4/76 [00:00<00:06, 11.96it/s, loss=1.05, v_num=]Epoch 6:   7%|â–‹         | 5/76 [00:00<00:05, 12.09it/s, loss=1.05, v_num=]Epoch 6:   7%|â–‹         | 5/76 [00:00<00:05, 12.07it/s, loss=1.05, v_num=]Epoch 6:   8%|â–Š         | 6/76 [00:00<00:05, 11.83it/s, loss=1.05, v_num=]Epoch 6:   8%|â–Š         | 6/76 [00:00<00:05, 11.81it/s, loss=1.06, v_num=]Epoch 6:   9%|â–‰         | 7/76 [00:00<00:05, 11.76it/s, loss=1.06, v_num=]Epoch 6:   9%|â–‰         | 7/76 [00:00<00:05, 11.75it/s, loss=1.06, v_num=]Epoch 6:  11%|â–ˆ         | 8/76 [00:00<00:05, 12.14it/s, loss=1.06, v_num=]Epoch 6:  11%|â–ˆ         | 8/76 [00:00<00:05, 12.12it/s, loss=1.07, v_num=]Epoch 6:  12%|â–ˆâ–        | 9/76 [00:00<00:05, 12.21it/s, loss=1.07, v_num=]Epoch 6:  12%|â–ˆâ–        | 9/76 [00:00<00:05, 12.20it/s, loss=1.1, v_num=] Epoch 6:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:05, 12.33it/s, loss=1.1, v_num=]Epoch 6:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:05, 12.32it/s, loss=1.1, v_num=]Epoch 6:  14%|â–ˆâ–        | 11/76 [00:00<00:05, 12.37it/s, loss=1.1, v_num=]Epoch 6:  14%|â–ˆâ–        | 11/76 [00:00<00:05, 12.36it/s, loss=1.03, v_num=]Epoch 6:  16%|â–ˆâ–Œ        | 12/76 [00:00<00:05, 12.51it/s, loss=1.03, v_num=]Epoch 6:  16%|â–ˆâ–Œ        | 12/76 [00:00<00:05, 12.50it/s, loss=1.1, v_num=] Epoch 6:  17%|â–ˆâ–‹        | 13/76 [00:01<00:05, 12.32it/s, loss=1.1, v_num=]Epoch 6:  17%|â–ˆâ–‹        | 13/76 [00:01<00:05, 12.31it/s, loss=1.06, v_num=]Epoch 6:  18%|â–ˆâ–Š        | 14/76 [00:01<00:04, 12.45it/s, loss=1.06, v_num=]Epoch 6:  18%|â–ˆâ–Š        | 14/76 [00:01<00:04, 12.44it/s, loss=0.97, v_num=]Epoch 6:  20%|â–ˆâ–‰        | 15/76 [00:01<00:04, 12.40it/s, loss=0.97, v_num=]Epoch 6:  20%|â–ˆâ–‰        | 15/76 [00:01<00:04, 12.39it/s, loss=0.986, v_num=]Epoch 6:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:05, 11.90it/s, loss=0.986, v_num=]Epoch 6:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:05, 11.89it/s, loss=0.978, v_num=]Epoch 6:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:04, 11.86it/s, loss=0.978, v_num=]Epoch 6:  22%|â–ˆâ–ˆâ–       | 17/76 [00:01<00:04, 11.85it/s, loss=0.976, v_num=]Epoch 6:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:04, 11.76it/s, loss=0.976, v_num=]Epoch 6:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:01<00:04, 11.76it/s, loss=0.974, v_num=]Epoch 6:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:04, 11.81it/s, loss=0.974, v_num=]Epoch 6:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:01<00:04, 11.80it/s, loss=0.981, v_num=]Epoch 6:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:01<00:04, 11.81it/s, loss=0.981, v_num=]Epoch 6:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:01<00:04, 11.80it/s, loss=1.02, v_num=] Epoch 6:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:01<00:04, 11.77it/s, loss=1.02, v_num=]Epoch 6:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:01<00:04, 11.77it/s, loss=0.993, v_num=]Epoch 6:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:01<00:04, 11.75it/s, loss=0.993, v_num=]Epoch 6:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:01<00:04, 11.74it/s, loss=1.01, v_num=] Epoch 6:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:01<00:04, 11.74it/s, loss=1.01, v_num=]Epoch 6:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:01<00:04, 11.73it/s, loss=1.05, v_num=]Epoch 6:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:02<00:04, 11.69it/s, loss=1.05, v_num=]Epoch 6:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:02<00:04, 11.69it/s, loss=0.978, v_num=]Epoch 6:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:02<00:04, 11.77it/s, loss=0.978, v_num=]Epoch 6:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:02<00:04, 11.76it/s, loss=1.06, v_num=] 
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 39.03it/s][AEpoch 6:  34%|â–ˆâ–ˆâ–ˆâ–      | 26/76 [00:02<00:04, 11.92it/s, loss=1.06, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 39.75it/s][AEpoch 6:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/76 [00:02<00:04, 12.23it/s, loss=1.06, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 37.45it/s][AEpoch 6:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/76 [00:02<00:03, 12.52it/s, loss=1.06, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 36.91it/s][AEpoch 6:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 29/76 [00:02<00:03, 12.80it/s, loss=1.06, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 35.70it/s][AEpoch 6:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 30/76 [00:02<00:03, 13.06it/s, loss=1.06, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 35.76it/s][AEpoch 6:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 31/76 [00:02<00:03, 13.34it/s, loss=1.06, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 35.94it/s][AEpoch 6:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/76 [00:02<00:03, 13.61it/s, loss=1.06, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 36.07it/s][AEpoch 6:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 33/76 [00:02<00:03, 13.88it/s, loss=1.06, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 35.84it/s][AEpoch 6:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/76 [00:02<00:02, 14.12it/s, loss=1.06, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 35.93it/s][AEpoch 6:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 35/76 [00:02<00:02, 14.37it/s, loss=1.06, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 35.99it/s][AEpoch 6:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 36/76 [00:02<00:02, 14.62it/s, loss=1.06, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 36.04it/s][AEpoch 6:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 37/76 [00:02<00:02, 14.86it/s, loss=1.06, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 35.56it/s][AEpoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:02<00:02, 15.07it/s, loss=1.06, v_num=]Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:02<00:02, 14.68it/s, loss=1.06, v_num=]
                                                                        [AEpoch 6, global step 25: 'val_rmse' was not in top 3
Epoch 6:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:25<00:23,  1.55it/s, loss=1.06, v_num=]Epoch 6:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/76 [00:25<00:24,  1.54it/s, loss=1.04, v_num=]Epoch 6:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:25<00:22,  1.57it/s, loss=1.04, v_num=]Epoch 6:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/76 [00:25<00:22,  1.57it/s, loss=1.05, v_num=]Epoch 6:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:25<00:21,  1.61it/s, loss=1.05, v_num=]Epoch 6:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/76 [00:25<00:21,  1.61it/s, loss=1.03, v_num=]Epoch 6:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:25<00:20,  1.64it/s, loss=1.03, v_num=]Epoch 6:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/76 [00:25<00:20,  1.64it/s, loss=1.04, v_num=]Epoch 6:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:25<00:19,  1.67it/s, loss=1.04, v_num=]Epoch 6:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/76 [00:25<00:19,  1.67it/s, loss=1.02, v_num=]Epoch 6:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:25<00:18,  1.71it/s, loss=1.02, v_num=]Epoch 6:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/76 [00:25<00:18,  1.71it/s, loss=1.03, v_num=]Epoch 6:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:25<00:17,  1.74it/s, loss=1.03, v_num=]Epoch 6:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 45/76 [00:25<00:17,  1.74it/s, loss=0.963, v_num=]Epoch 6:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:25<00:16,  1.77it/s, loss=0.963, v_num=]Epoch 6:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 46/76 [00:25<00:16,  1.77it/s, loss=1.03, v_num=] Epoch 6:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [00:26<00:16,  1.80it/s, loss=1.03, v_num=]Epoch 6:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/76 [00:26<00:16,  1.80it/s, loss=1.21, v_num=]Epoch 6:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [00:26<00:15,  1.84it/s, loss=1.21, v_num=]Epoch 6:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 48/76 [00:26<00:15,  1.84it/s, loss=1.21, v_num=]Epoch 6:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [00:26<00:14,  1.87it/s, loss=1.21, v_num=]Epoch 6:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/76 [00:26<00:14,  1.87it/s, loss=1.24, v_num=]Epoch 6:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [00:26<00:13,  1.90it/s, loss=1.24, v_num=]Epoch 6:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 50/76 [00:26<00:13,  1.90it/s, loss=1.33, v_num=]Epoch 6:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [00:26<00:12,  1.93it/s, loss=1.33, v_num=]Epoch 6:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 51/76 [00:26<00:12,  1.93it/s, loss=1.31, v_num=]Epoch 6:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [00:26<00:12,  1.97it/s, loss=1.31, v_num=]Epoch 6:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 52/76 [00:26<00:12,  1.97it/s, loss=1.31, v_num=]Epoch 6:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [00:26<00:11,  2.00it/s, loss=1.31, v_num=]Epoch 6:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 53/76 [00:26<00:11,  2.00it/s, loss=1.24, v_num=]Epoch 6:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [00:26<00:10,  2.03it/s, loss=1.24, v_num=]Epoch 6:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 54/76 [00:26<00:10,  2.03it/s, loss=1.3, v_num=] Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [00:26<00:10,  2.06it/s, loss=1.3, v_num=]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 55/76 [00:26<00:10,  2.06it/s, loss=1.47, v_num=]Epoch 6:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [00:26<00:09,  2.09it/s, loss=1.47, v_num=]Epoch 6:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 56/76 [00:26<00:09,  2.09it/s, loss=1.46, v_num=]Epoch 6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [00:26<00:08,  2.13it/s, loss=1.46, v_num=]Epoch 6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/76 [00:26<00:08,  2.13it/s, loss=1.53, v_num=]Epoch 6:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [00:26<00:08,  2.16it/s, loss=1.53, v_num=]Epoch 6:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/76 [00:26<00:08,  2.16it/s, loss=1.44, v_num=]Epoch 6:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [00:26<00:07,  2.19it/s, loss=1.44, v_num=]Epoch 6:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/76 [00:26<00:07,  2.19it/s, loss=1.44, v_num=]Epoch 6:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [00:26<00:07,  2.22it/s, loss=1.44, v_num=]Epoch 6:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 60/76 [00:26<00:07,  2.22it/s, loss=1.54, v_num=]Epoch 6:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [00:27<00:06,  2.25it/s, loss=1.54, v_num=]Epoch 6:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 61/76 [00:27<00:06,  2.25it/s, loss=1.55, v_num=]Epoch 6:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [00:27<00:06,  2.28it/s, loss=1.55, v_num=]Epoch 6:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/76 [00:27<00:06,  2.28it/s, loss=1.55, v_num=]Epoch 6:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [00:27<00:05,  2.31it/s, loss=1.55, v_num=]Epoch 6:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 63/76 [00:27<00:05,  2.31it/s, loss=1.53, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 38.76it/s][AEpoch 6:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 64/76 [00:27<00:05,  2.34it/s, loss=1.53, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 39.44it/s][AEpoch 6:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 65/76 [00:27<00:04,  2.38it/s, loss=1.53, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 35.45it/s][AEpoch 6:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 66/76 [00:27<00:04,  2.41it/s, loss=1.53, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 35.57it/s][AEpoch 6:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 67/76 [00:27<00:03,  2.44it/s, loss=1.53, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 35.76it/s][AEpoch 6:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 68/76 [00:27<00:03,  2.48it/s, loss=1.53, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 35.82it/s][AEpoch 6:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 69/76 [00:27<00:02,  2.51it/s, loss=1.53, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 35.88it/s][AEpoch 6:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 70/76 [00:27<00:02,  2.55it/s, loss=1.53, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 35.93it/s][AEpoch 6:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 71/76 [00:27<00:01,  2.58it/s, loss=1.53, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 35.98it/s][AEpoch 6:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72/76 [00:27<00:01,  2.61it/s, loss=1.53, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 36.00it/s][AEpoch 6:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 73/76 [00:27<00:01,  2.65it/s, loss=1.53, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 35.92it/s][AEpoch 6:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 74/76 [00:27<00:00,  2.68it/s, loss=1.53, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 35.97it/s][AEpoch 6:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 75/76 [00:27<00:00,  2.71it/s, loss=1.53, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 35.99it/s][AEpoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:27<00:00,  2.75it/s, loss=1.53, v_num=]Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:31<00:00,  2.43it/s, loss=1.53, v_num=]
                                                                        [AEpoch 6, global step 28: 'val_rmse' was not in top 3
Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:55<00:00,  1.37it/s, loss=1.53, v_num=]Epoch 6:   0%|          | 0/76 [00:00<?, ?it/s, loss=1.53, v_num=]         Epoch 7:   0%|          | 0/76 [00:00<?, ?it/s, loss=1.53, v_num=]Epoch 7:   1%|â–         | 1/76 [00:00<00:08,  9.03it/s, loss=1.53, v_num=]Epoch 7:   1%|â–         | 1/76 [00:00<00:08,  8.97it/s, loss=1.65, v_num=]Epoch 7:   3%|â–Ž         | 2/76 [00:00<00:06, 10.61it/s, loss=1.65, v_num=]Epoch 7:   3%|â–Ž         | 2/76 [00:00<00:06, 10.57it/s, loss=1.64, v_num=]Epoch 7:   4%|â–         | 3/76 [00:00<00:06, 11.28it/s, loss=1.64, v_num=]Epoch 7:   4%|â–         | 3/76 [00:00<00:06, 11.25it/s, loss=1.62, v_num=]Epoch 7:   5%|â–Œ         | 4/76 [00:00<00:06, 11.79it/s, loss=1.62, v_num=]Epoch 7:   5%|â–Œ         | 4/76 [00:00<00:06, 11.77it/s, loss=1.4, v_num=] Epoch 7:   7%|â–‹         | 5/76 [00:00<00:06, 11.72it/s, loss=1.4, v_num=]Epoch 7:   7%|â–‹         | 5/76 [00:00<00:06, 11.70it/s, loss=1.39, v_num=]Epoch 7:   8%|â–Š         | 6/76 [00:00<00:05, 12.10it/s, loss=1.39, v_num=]Epoch 7:   8%|â–Š         | 6/76 [00:00<00:05, 12.08it/s, loss=1.49, v_num=]Epoch 7:   9%|â–‰         | 7/76 [00:00<00:05, 12.19it/s, loss=1.49, v_num=]Epoch 7:   9%|â–‰         | 7/76 [00:00<00:05, 12.18it/s, loss=1.41, v_num=]Epoch 7:  11%|â–ˆ         | 8/76 [00:00<00:05, 12.20it/s, loss=1.41, v_num=]Epoch 7:  11%|â–ˆ         | 8/76 [00:00<00:05, 12.19it/s, loss=1.45, v_num=]Epoch 7:  12%|â–ˆâ–        | 9/76 [00:00<00:05, 12.21it/s, loss=1.45, v_num=]Epoch 7:  12%|â–ˆâ–        | 9/76 [00:00<00:05, 12.19it/s, loss=1.51, v_num=]Epoch 7:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:05, 12.26it/s, loss=1.51, v_num=]Epoch 7:  13%|â–ˆâ–Ž        | 10/76 [00:00<00:05, 12.25it/s, loss=1.54, v_num=]Epoch 7:  14%|â–ˆâ–        | 11/76 [00:00<00:05, 12.01it/s, loss=1.54, v_num=]Epoch 7:  14%|â–ˆâ–        | 11/76 [00:00<00:05, 12.00it/s, loss=1.47, v_num=]Epoch 7:  16%|â–ˆâ–Œ        | 12/76 [00:01<00:05, 11.89it/s, loss=1.47, v_num=]Epoch 7:  16%|â–ˆâ–Œ        | 12/76 [00:01<00:05, 11.88it/s, loss=1.36, v_num=]Epoch 7:  17%|â–ˆâ–‹        | 13/76 [00:01<00:05, 11.82it/s, loss=1.36, v_num=]Epoch 7:  17%|â–ˆâ–‹        | 13/76 [00:01<00:05, 11.81it/s, loss=1.43, v_num=]Epoch 7:  18%|â–ˆâ–Š        | 14/76 [00:01<00:05, 11.70it/s, loss=1.43, v_num=]Epoch 7:  18%|â–ˆâ–Š        | 14/76 [00:01<00:05, 11.70it/s, loss=1.36, v_num=]Epoch 7:  20%|â–ˆâ–‰        | 15/76 [00:01<00:05, 11.68it/s, loss=1.36, v_num=]Epoch 7:  20%|â–ˆâ–‰        | 15/76 [00:01<00:05, 11.67it/s, loss=1.35, v_num=]Epoch 7:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:05, 11.15it/s, loss=1.35, v_num=]Epoch 7:  21%|â–ˆâ–ˆ        | 16/76 [00:01<00:05, 11.14it/s, loss=1.43, v_num=]Epoch 7:  22%|â–ˆâ–ˆâ–       | 17/76 [00:04<00:15,  3.73it/s, loss=1.43, v_num=]Epoch 7:  22%|â–ˆâ–ˆâ–       | 17/76 [00:04<00:15,  3.73it/s, loss=1.36, v_num=]Epoch 7:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:04<00:15,  3.64it/s, loss=1.36, v_num=]Epoch 7:  24%|â–ˆâ–ˆâ–Ž       | 18/76 [00:04<00:15,  3.64it/s, loss=1.37, v_num=]Epoch 7:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:05<00:16,  3.54it/s, loss=1.37, v_num=]Epoch 7:  25%|â–ˆâ–ˆâ–Œ       | 19/76 [00:05<00:16,  3.54it/s, loss=1.36, v_num=]Epoch 7:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:05<00:16,  3.43it/s, loss=1.36, v_num=]Epoch 7:  26%|â–ˆâ–ˆâ–‹       | 20/76 [00:05<00:16,  3.43it/s, loss=1.4, v_num=] Epoch 7:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:06<00:16,  3.32it/s, loss=1.4, v_num=]Epoch 7:  28%|â–ˆâ–ˆâ–Š       | 21/76 [00:06<00:16,  3.32it/s, loss=1.29, v_num=]Epoch 7:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:06<00:16,  3.33it/s, loss=1.29, v_num=]Epoch 7:  29%|â–ˆâ–ˆâ–‰       | 22/76 [00:06<00:16,  3.33it/s, loss=1.37, v_num=]Epoch 7:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:07<00:16,  3.24it/s, loss=1.37, v_num=]Epoch 7:  30%|â–ˆâ–ˆâ–ˆ       | 23/76 [00:07<00:16,  3.23it/s, loss=1.35, v_num=]Epoch 7:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:07<00:16,  3.18it/s, loss=1.35, v_num=]Epoch 7:  32%|â–ˆâ–ˆâ–ˆâ–      | 24/76 [00:07<00:16,  3.18it/s, loss=1.4, v_num=] Epoch 7:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:08<00:16,  3.11it/s, loss=1.4, v_num=]Epoch 7:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/76 [00:08<00:16,  3.11it/s, loss=1.47, v_num=]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s][A
Validation DataLoader 0:   8%|â–Š         | 1/13 [00:00<00:00, 29.05it/s][AEpoch 7:  34%|â–ˆâ–ˆâ–ˆâ–      | 26/76 [00:08<00:15,  3.21it/s, loss=1.47, v_num=]
Validation DataLoader 0:  15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 30.38it/s][AEpoch 7:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/76 [00:08<00:14,  3.32it/s, loss=1.47, v_num=]
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 25.25it/s][AEpoch 7:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/76 [00:08<00:14,  3.42it/s, loss=1.47, v_num=]
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 26.82it/s][AEpoch 7:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 29/76 [00:08<00:13,  3.53it/s, loss=1.47, v_num=]
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 25.34it/s][AEpoch 7:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 30/76 [00:08<00:12,  3.63it/s, loss=1.47, v_num=]
Validation DataLoader 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 25.53it/s][AEpoch 7:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 31/76 [00:08<00:12,  3.73it/s, loss=1.47, v_num=]
Validation DataLoader 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 26.37it/s][AEpoch 7:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/76 [00:08<00:11,  3.84it/s, loss=1.47, v_num=]
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 27.28it/s][AEpoch 7:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 33/76 [00:08<00:10,  3.94it/s, loss=1.47, v_num=]
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 28.07it/s][AEpoch 7:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/76 [00:08<00:10,  4.05it/s, loss=1.47, v_num=]
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 28.80it/s][AEpoch 7:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 35/76 [00:08<00:09,  4.16it/s, loss=1.47, v_num=]
Validation DataLoader 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 29.07it/s][AEpoch 7:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 36/76 [00:08<00:09,  4.26it/s, loss=1.47, v_num=]
Validation DataLoader 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 29.60it/s][AEpoch 7:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 37/76 [00:08<00:08,  4.36it/s, loss=1.47, v_num=]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 30.04it/s][AEpoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:08<00:08,  4.47it/s, loss=1.47, v_num=]Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:08<00:08,  4.44it/s, loss=1.47, v_num=]
                                                                        [AEpoch 7, global step 29: 'val_rmse' was not in top 3
Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:34<00:34,  1.11it/s, loss=1.47, v_num=]Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/76 [00:34<00:34,  1.11it/s, loss=1.47, v_num=]Start to fuse 3 checkpoints via the greedy soup algorithm.
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python SMAC_REG_MOD1.py ...
  rank_zero_warn(
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python SMAC_REG_MOD1.py ...
  rank_zero_warn(

Predicting: 0it [00:00, ?it/s]Predicting:   0%|          | 0/4 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Predicting DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00, 26.11it/s]Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 31.08it/s]Predicting DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 33.58it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 34.71it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.97it/s]/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python SMAC_REG_MOD1.py ...
  rank_zero_warn(
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python SMAC_REG_MOD1.py ...
  rank_zero_warn(

Predicting: 0it [00:00, ?it/s]Predicting:   0%|          | 0/4 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Predicting DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00, 31.00it/s]Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 31.29it/s]Predicting DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 34.92it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 35.91it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.14it/s]/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python SMAC_REG_MOD1.py ...
  rank_zero_warn(
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python SMAC_REG_MOD1.py ...
  rank_zero_warn(

Predicting: 0it [00:00, ?it/s]Predicting:   0%|          | 0/4 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Predicting DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00, 24.90it/s]Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 27.74it/s]Predicting DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 32.06it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 34.08it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.19it/s]AutoMM has created your model ðŸŽ‰ðŸŽ‰ðŸŽ‰

- To load the model, use the code below:
    ```python
    from autogluon.multimodal import MultiModalPredictor
    predictor = MultiModalPredictor.load("/mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923")
    ```

- You can open a terminal and launch Tensorboard to visualize the training log:
    ```shell
    # Assume you have installed tensorboard
    tensorboard --logdir /mnt/server-home/TUE/20210962/optimisation/AutogluonModels/ag-20230719_201923
    ```

- If you are not satisfied with the model, try to increase the training time, 
adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),
or post issues on GitHub: https://github.com/autogluon/autogluon


/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python SMAC_REG_MOD1.py ...
  rank_zero_warn(
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python SMAC_REG_MOD1.py ...
  rank_zero_warn(

Predicting: 0it [00:00, ?it/s]Predicting:   0%|          | 0/16 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]Predicting DataLoader 0:   6%|â–‹         | 1/16 [00:00<00:00, 28.84it/s]Predicting DataLoader 0:  12%|â–ˆâ–Ž        | 2/16 [00:00<00:00, 30.62it/s]Predicting DataLoader 0:  19%|â–ˆâ–‰        | 3/16 [00:00<00:00, 34.89it/s]Predicting DataLoader 0:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:00<00:00, 27.16it/s]Predicting DataLoader 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:00<00:00, 29.78it/s]Predicting DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:00<00:00, 31.24it/s]Predicting DataLoader 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:00<00:00, 32.43it/s]Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:00<00:00, 33.41it/s]Predicting DataLoader 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:00<00:00, 34.12it/s]Predicting DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:00<00:00, 34.81it/s]Predicting DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:00<00:00, 35.41it/s]Predicting DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:00<00:00, 35.91it/s]Predicting DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:00<00:00, 36.35it/s]Predicting DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:00<00:00, 36.75it/s]Predicting DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:00<00:00, 37.10it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 37.37it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 25.16it/s]
0.8
0.256069262627141
0.257076860741332
0.258894300171868
0.258934367481467
0.260124400267344
0.26151509988243
0.26151509988243
0.279298030428895
0.281009117077736
0.286118880974898
0.431285903667698
0.42295309639543
0.421501167855565
0.421501167855565
0.41708225490815
0.360078277886497
0.286118880974898
0.431285903667698
0.42295309639543
0.421501167855565
0.421501167855565
0.41708225490815
0.360078277886497
0.966758349705304
0.966758349705304
0.964400785854617
0.964400785854617
0.9637721021611
0.962907662082515
0.96188605108055
0.957721021611002
0.95992141453831
0.958271119842829
0.958271119842829
350.327571893471
353.089333711762
359.595743835874
359.702073091062
364.732346194502
400.978039066042
403.194506208498
403.194506208498
0.680377332316016
0.680377332316016
0.442466969039637
0.440889370932755
0.439410372707553
0.439410372707553
0.92684934652245
0.927199394715527
0.927536987867204
0.92753838147008
0.931597807400951
0.927552965346058
0.927824685361449
0.927945473494686
0.928332948343208
0.928363615932888
0.928447884613105
0.928632074592587
0.936149753315216
0.937683921171037
0.92684934652245
0.927199394715527
0.927536987867204
0.92753838147008
0.931597807400951
0.927552965346058
0.927824685361449
0.927945473494686
0.928332948343208
0.928363615932888
0.928447884613105
0.928632074592587
0.936149753315216
0.937683921171037
0.587449330147522
0.587449330147522
0.621566957632531
0.599691292314243
0.594581647860336
0.577443048754524
0.0119642712630258
0.0119727897939835
0.0128363349569484
0.0131213860342688
0.0136461851553516
0.0139811049279282
0.0153266343331459
2.12259648124658
2.12970452417856
2.13279592687851
2.14216034282393
2.15905443195887
2.1823810941456
2.2230946030351
0.952577669902913
0.945101941747573
0.943228155339806
0.942145631067961
0.941912621359223
0.939009708737864
0.926936893203884
0.926936893203884
0.804708737864078
0.765781553398058
0.634
0.626922330097087
0.621101941747573
0.952577669902913
0.952577669902913
0.945101941747573
0.943228155339806
0.942145631067961
0.941912621359223
0.939223300970874
0.939009708737864
0.926936893203884
0.926936893203884
0.804708737864078
0.765781553398058
0.634
0.626922330097087
0.621101941747573
TrialKey(config_id=1, instance=54, seed=55726, budget=120.0)
TrialKey(config_id=2, instance=57, seed=55726, budget=120.0)
TrialKey(config_id=3, instance=74, seed=55726, budget=120.0)
TrialKey(config_id=4, instance=77, seed=55726, budget=120.0)
TrialKey(config_id=5, instance=77, seed=55726, budget=120.0)
TrialKey(config_id=6, instance=19, seed=55726, budget=120.0)
TrialKey(config_id=7, instance=93, seed=55726, budget=120.0)
TrialKey(config_id=8, instance=31, seed=55726, budget=120.0)
TrialKey(config_id=9, instance=46, seed=55726, budget=120.0)
TrialKey(config_id=10, instance=97, seed=55726, budget=120.0)
TrialKey(config_id=11, instance=80, seed=55726, budget=120.0)
TrialKey(config_id=12, instance=98, seed=55726, budget=120.0)
TrialKey(config_id=13, instance=98, seed=55726, budget=120.0)
TrialKey(config_id=14, instance=22, seed=55726, budget=120.0)
TrialKey(config_id=14, instance=68, seed=55726, budget=120.0)
TrialKey(config_id=15, instance=75, seed=55726, budget=120.0)
TrialKey(config_id=16, instance=49, seed=55726, budget=120.0)
TrialKey(config_id=17, instance=56, seed=55726, budget=120.0)
TrialKey(config_id=18, instance=98, seed=55726, budget=120.0)
TrialKey(config_id=19, instance=91, seed=55726, budget=120.0)
TrialKey(config_id=19, instance=47, seed=55726, budget=120.0)
TrialKey(config_id=20, instance=35, seed=55726, budget=120.0)
TrialKey(config_id=19, instance=87, seed=55726, budget=120.0)
TrialKey(config_id=15, instance=82, seed=55726, budget=120.0)
TrialKey(config_id=21, instance=19, seed=55726, budget=120.0)
TrialKey(config_id=22, instance=30, seed=55726, budget=120.0)
TrialKey(config_id=23, instance=90, seed=55726, budget=120.0)
TrialKey(config_id=14, instance=79, seed=55726, budget=120.0)
TrialKey(config_id=24, instance=89, seed=55726, budget=120.0)
TrialKey(config_id=25, instance=57, seed=55726, budget=120.0)
TrialKey(config_id=26, instance=74, seed=55726, budget=120.0)
TrialKey(config_id=27, instance=92, seed=55726, budget=120.0)
TrialKey(config_id=28, instance=98, seed=55726, budget=120.0)
TrialKey(config_id=29, instance=59, seed=55726, budget=120.0)
TrialKey(config_id=30, instance=39, seed=55726, budget=120.0)
TrialKey(config_id=31, instance=29, seed=55726, budget=120.0)
TrialKey(config_id=32, instance=29, seed=55726, budget=120.0)
TrialKey(config_id=33, instance=24, seed=55726, budget=120.0)
TrialKey(config_id=34, instance=49, seed=55726, budget=120.0)
TrialKey(config_id=33, instance=42, seed=55726, budget=120.0)
TrialKey(config_id=35, instance=75, seed=55726, budget=120.0)
TrialKey(config_id=34, instance=19, seed=55726, budget=120.0)
TrialKey(config_id=36, instance=67, seed=55726, budget=120.0)
TrialKey(config_id=37, instance=42, seed=55726, budget=120.0)
TrialKey(config_id=37, instance=41, seed=55726, budget=120.0)
TrialKey(config_id=38, instance=84, seed=55726, budget=120.0)
TrialKey(config_id=37, instance=33, seed=55726, budget=120.0)
TrialKey(config_id=39, instance=45, seed=55726, budget=120.0)
TrialKey(config_id=40, instance=85, seed=55726, budget=120.0)
TrialKey(config_id=41, instance=65, seed=55726, budget=120.0)
TrialKey(config_id=42, instance=38, seed=55726, budget=120.0)
TrialKey(config_id=43, instance=44, seed=55726, budget=120.0)
TrialKey(config_id=44, instance=10, seed=55726, budget=120.0)
TrialKey(config_id=45, instance=10, seed=55726, budget=120.0)
TrialKey(config_id=46, instance=46, seed=55726, budget=120.0)
TrialKey(config_id=47, instance=63, seed=55726, budget=120.0)
TrialKey(config_id=48, instance=15, seed=55726, budget=120.0)
TrialKey(config_id=48, instance=48, seed=55726, budget=120.0)
TrialKey(config_id=49, instance=27, seed=55726, budget=120.0)
TrialKey(config_id=50, instance=89, seed=55726, budget=120.0)
TrialKey(config_id=51, instance=14, seed=55726, budget=120.0)
TrialKey(config_id=52, instance=52, seed=55726, budget=120.0)
TrialKey(config_id=53, instance=68, seed=55726, budget=120.0)
TrialKey(config_id=54, instance=41, seed=55726, budget=120.0)
TrialKey(config_id=55, instance=11, seed=55726, budget=120.0)
TrialKey(config_id=56, instance=75, seed=55726, budget=120.0)
TrialKey(config_id=57, instance=51, seed=55726, budget=120.0)
TrialKey(config_id=58, instance=67, seed=55726, budget=120.0)
TrialKey(config_id=59, instance=45, seed=55726, budget=120.0)
TrialKey(config_id=60, instance=21, seed=55726, budget=120.0)
TrialKey(config_id=61, instance=56, seed=55726, budget=120.0)
TrialKey(config_id=61, instance=92, seed=55726, budget=120.0)
TrialKey(config_id=62, instance=10, seed=55726, budget=120.0)
TrialKey(config_id=63, instance=24, seed=55726, budget=120.0)
TrialKey(config_id=64, instance=63, seed=55726, budget=120.0)
TrialKey(config_id=65, instance=22, seed=55726, budget=120.0)
TrialKey(config_id=66, instance=52, seed=55726, budget=120.0)
TrialKey(config_id=66, instance=94, seed=55726, budget=120.0)
TrialKey(config_id=67, instance=85, seed=55726, budget=120.0)
TrialKey(config_id=68, instance=78, seed=55726, budget=120.0)
TrialKey(config_id=69, instance=16, seed=55726, budget=120.0)
TrialKey(config_id=70, instance=78, seed=55726, budget=120.0)
TrialKey(config_id=71, instance=57, seed=55726, budget=120.0)
TrialKey(config_id=72, instance=13, seed=55726, budget=120.0)
TrialKey(config_id=73, instance=86, seed=55726, budget=120.0)
TrialKey(config_id=74, instance=62, seed=55726, budget=120.0)
TrialKey(config_id=75, instance=88, seed=55726, budget=120.0)
TrialKey(config_id=76, instance=25, seed=55726, budget=120.0)
TrialKey(config_id=77, instance=30, seed=55726, budget=120.0)
TrialKey(config_id=78, instance=68, seed=55726, budget=120.0)
TrialKey(config_id=79, instance=33, seed=55726, budget=120.0)
TrialKey(config_id=80, instance=89, seed=55726, budget=120.0)
TrialKey(config_id=81, instance=23, seed=55726, budget=120.0)
TrialKey(config_id=82, instance=95, seed=55726, budget=120.0)
TrialKey(config_id=83, instance=58, seed=55726, budget=120.0)
TrialKey(config_id=84, instance=59, seed=55726, budget=120.0)
TrialKey(config_id=85, instance=79, seed=55726, budget=120.0)
TrialKey(config_id=86, instance=51, seed=55726, budget=120.0)
TrialKey(config_id=87, instance=45, seed=55726, budget=120.0)
TrialKey(config_id=88, instance=74, seed=55726, budget=120.0)
TrialKey(config_id=89, instance=79, seed=55726, budget=120.0)
TrialKey(config_id=90, instance=10, seed=55726, budget=120.0)
TrialKey(config_id=91, instance=60, seed=55726, budget=120.0)
TrialKey(config_id=92, instance=46, seed=55726, budget=120.0)
TrialKey(config_id=93, instance=44, seed=55726, budget=120.0)
TrialKey(config_id=94, instance=58, seed=55726, budget=120.0)
TrialKey(config_id=95, instance=13, seed=55726, budget=120.0)
TrialKey(config_id=96, instance=52, seed=55726, budget=120.0)
TrialKey(config_id=97, instance=87, seed=55726, budget=120.0)
TrialKey(config_id=98, instance=31, seed=55726, budget=120.0)
TrialKey(config_id=99, instance=83, seed=55726, budget=120.0)
TrialKey(config_id=100, instance=10, seed=55726, budget=120.0)
TrialKey(config_id=101, instance=20, seed=55726, budget=120.0)
TrialKey(config_id=102, instance=53, seed=55726, budget=120.0)
TrialKey(config_id=103, instance=68, seed=55726, budget=120.0)
TrialKey(config_id=104, instance=33, seed=55726, budget=120.0)
TrialKey(config_id=105, instance=69, seed=55726, budget=120.0)
TrialKey(config_id=106, instance=12, seed=55726, budget=120.0)
TrialKey(config_id=107, instance=72, seed=55726, budget=120.0)
TrialKey(config_id=108, instance=45, seed=55726, budget=120.0)
TrialKey(config_id=109, instance=77, seed=55726, budget=120.0)
TrialKey(config_id=110, instance=92, seed=55726, budget=120.0)
TrialKey(config_id=111, instance=56, seed=55726, budget=120.0)
TrialKey(config_id=112, instance=30, seed=55726, budget=120.0)
[INFO][abstract_initial_design.py:95] Reducing the number of initial configurations from 160 to 25 (max_ratio == 0.25).
[INFO][abstract_initial_design.py:147] Using 1 initial design configurations and 0 additional configurations.
Starting Optimization Incumbent ITR 0
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[INFO][abstract_intensifier.py:515] Added config 22d081 as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined



 ...Automatically synthesizing end-to-end Deep ML pipeline for the regression task....

Enjoy your coffee â˜• â˜• ..
 
Sampled Downstream Model is weighted_ensemble_r_LGB_L1_1
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2044, in objective_function
    zip(tab_embeds, outputs)]
NameError: name 'outputs' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined



 ...Automatically synthesizing end-to-end Deep ML pipeline for the regression task....

Enjoy your coffee â˜• â˜• ..
 
Sampled Downstream Model is weighted_ensemble_r_XT_L1_1
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2044, in objective_function
    zip(tab_embeds, outputs)]
NameError: name 'outputs' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined



 ...Automatically synthesizing end-to-end Deep ML pipeline for the regression task....

Enjoy your coffee â˜• â˜• ..
 
Sampled Downstream Model is weighted_ensemble_r_XT_L1_1
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2044, in objective_function
    zip(tab_embeds, outputs)]
NameError: name 'outputs' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined



 ...Automatically synthesizing end-to-end Deep ML pipeline for the regression task....

Enjoy your coffee â˜• â˜• ..
 
Sampled Downstream Model is weighted_ensemble_r_XT_L1_1
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2044, in objective_function
    zip(tab_embeds, outputs)]
NameError: name 'outputs' is not defined



 ...Automatically synthesizing end-to-end Deep ML pipeline for the regression task....

Enjoy your coffee â˜• â˜• ..
 
Sampled Downstream Model is stacked_ensemble_r_LGB_L1_1
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2044, in objective_function
    zip(tab_embeds, outputs)]
NameError: name 'outputs' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined



 ...Automatically synthesizing end-to-end Deep ML pipeline for the regression task....

Enjoy your coffee â˜• â˜• ..
 
Sampled Downstream Model is stacked_ensemble_r_CAT_L1_1
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2044, in objective_function
    zip(tab_embeds, outputs)]
NameError: name 'outputs' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined



 ...Automatically synthesizing end-to-end Deep ML pipeline for the regression task....

Enjoy your coffee â˜• â˜• ..
 
Sampled Downstream Model is weighted_ensemble_r_CAT_L1_2
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2044, in objective_function
    zip(tab_embeds, outputs)]
NameError: name 'outputs' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2256, in objective_function
    return objective_value  # + add the valse scores
NameError: name 'objective_value' is not defined



 ...Automatically synthesizing end-to-end Deep ML pipeline for the regression task....

Enjoy your coffee â˜• â˜• ..
 
Sampled Downstream Model is stacked_ensemble_r_LGB_L1_3
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2044, in objective_function
    zip(tab_embeds, outputs)]
NameError: name 'outputs' is not defined



 ...Automatically synthesizing end-to-end Deep ML pipeline for the regression task....

Enjoy your coffee â˜• â˜• ..
 
Sampled Downstream Model is stacked_ensemble_r_CAT_L1_2
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 173, in run
    rval = self(config_copy, target_function, kwargs)
  File "/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/smac/runner/target_function_runner.py", line 246, in __call__
    return algorithm(config, **algorithm_kwargs)
  File "SMAC_REG_MOD1.py", line 2044, in objective_function
    zip(tab_embeds, outputs)]
NameError: name 'outputs' is not defined



 ...Automatically synthesizing end-to-end Deep ML pipeline for the regression task....

Enjoy your coffee â˜• â˜• ..
 
Sampled Downstream Model is stacked_ensemble_r_LGB_L1_2
Selected Pre-Trained Model is Data2VecTextModel
The length of the tokenized tensors is 500
ITR 0
ITR 1
ITR 2
ITR 3
ITR 4
ITR 5
ITR 6
ITR 7
ITR 8
ITR 9
ITR 10
ITR 11
ITR 12
ITR 13
ITR 14
ITR 15
ITR 16
ITR 17
ITR 18
ITR 19
ITR 20
ITR 21
ITR 22
ITR 23
ITR 24
ITR 25
ITR 26
ITR 27
ITR 28
ITR 29
ITR 30
ITR 31
ITR 32
ITR 33
ITR 34
ITR 35
ITR 36
ITR 37
ITR 38
ITR 39
ITR 40
ITR 41
ITR 42
ITR 43
ITR 44
ITR 45
ITR 46
ITR 47
ITR 48
ITR 49
ITR 50
ITR 51
ITR 52
ITR 53
ITR 54
ITR 55
ITR 56
ITR 57
ITR 58
ITR 59
ITR 60
ITR 61
ITR 62
ITR 63
ITR 64
ITR 65
ITR 66
ITR 67
ITR 68
ITR 69
ITR 70
ITR 71
ITR 72
ITR 73
ITR 74
ITR 75
ITR 76
ITR 77
ITR 78
ITR 79
ITR 80
ITR 81
ITR 82
ITR 83
ITR 84
ITR 85
ITR 86
ITR 87
ITR 88
ITR 89
ITR 90
ITR 91
ITR 92
ITR 93
ITR 94
ITR 95
ITR 96
ITR 97
ITR 98
ITR 99
ITR 100
ITR 101
ITR 102
ITR 103
ITR 104
ITR 105
ITR 106
ITR 107
ITR 108
ITR 109
ITR 110
ITR 111
ITR 112
ITR 113
ITR 114
ITR 115
ITR 116
ITR 117
ITR 118
ITR 119
ITR 120
ITR 121
ITR 122
ITR 123
ITR 124
ITR 125
ITR 126
ITR 127
ITR 128
ITR 129
ITR 130
ITR 131
ITR 132
ITR 133
ITR 134
ITR 135
ITR 136
ITR 137
ITR 138
ITR 139
ITR 140
ITR 141
ITR 142
ITR 143
ITR 144
ITR 145
ITR 146
ITR 147
ITR 148
ITR 149
ITR 150
ITR 151
ITR 152
ITR 153
ITR 154
ITR 155
ITR 156
ITR 157
ITR 158
ITR 159
ITR 160
ITR 161
ITR 162
ITR 163
ITR 164
ITR 165
ITR 166
ITR 167
ITR 168
ITR 169
ITR 170
ITR 171
ITR 172
ITR 173
ITR 174
ITR 175
ITR 176
ITR 177
ITR 178
ITR 179
ITR 180
ITR 181
ITR 182
ITR 183
ITR 184
ITR 185
ITR 186
ITR 187
ITR 188
ITR 189
ITR 190
ITR 191
ITR 192
ITR 193
ITR 194
ITR 195
ITR 196
ITR 197
ITR 198
ITR 199
ITR 200
ITR 201
ITR 202
ITR 203
ITR 204
ITR 205
ITR 206
ITR 207
ITR 208
ITR 209
ITR 210
ITR 211
ITR 212
ITR 213
ITR 214
ITR 215
ITR 216
ITR 217
ITR 218
ITR 219
ITR 220
ITR 221
ITR 222
ITR 223
ITR 224
ITR 225
ITR 226
ITR 227
ITR 228
ITR 229
ITR 230
ITR 231
ITR 232
ITR 233
ITR 234
ITR 235
ITR 236
ITR 237
ITR 238
ITR 239
ITR 240
ITR 241
ITR 242
ITR 243
ITR 244
ITR 245
ITR 246
ITR 247
ITR 248
ITR 249
ITR 250
ITR 251
ITR 252
ITR 253
ITR 254
ITR 255
ITR 256
ITR 257
ITR 258
ITR 259
ITR 260
ITR 261
ITR 262
ITR 263
ITR 264
ITR 265
ITR 266
ITR 267
ITR 268
ITR 269
ITR 270
ITR 271
ITR 272
ITR 273
ITR 274
ITR 275
ITR 276
ITR 277
ITR 278
ITR 279
ITR 280
ITR 281
ITR 282
ITR 283
ITR 284
ITR 285
ITR 286
ITR 287
ITR 288
ITR 289
ITR 290
ITR 291
ITR 292
ITR 293
ITR 294
ITR 295
ITR 296
ITR 297
ITR 298
ITR 299
ITR 300
ITR 301
ITR 302
ITR 303
ITR 304
ITR 305
ITR 306
ITR 307
ITR 308
ITR 309
ITR 310
ITR 311
ITR 312
ITR 313
ITR 314
ITR 315
ITR 316
ITR 317
ITR 318
ITR 319
ITR 320
ITR 321
ITR 322
ITR 323
ITR 324
ITR 325
ITR 326
ITR 327
ITR 328
ITR 329
ITR 330
ITR 331
ITR 332
ITR 333
ITR 334
ITR 335
ITR 336
ITR 337
ITR 338
ITR 339
ITR 340
ITR 341
ITR 342
ITR 343
ITR 344
ITR 345
ITR 346
ITR 347
ITR 348
ITR 349
ITR 350
ITR 351
ITR 352
ITR 353
ITR 354
ITR 355
ITR 356
ITR 357
ITR 358
ITR 359
ITR 360
ITR 361
ITR 362
ITR 363
ITR 364
ITR 365
ITR 366
ITR 367
ITR 368
ITR 369
ITR 370
ITR 371
ITR 372
ITR 373
ITR 374
ITR 375
ITR 376
ITR 377
ITR 378
ITR 379
ITR 380
ITR 381
ITR 382
ITR 383
ITR 384
ITR 385
ITR 386
ITR 387
ITR 388
ITR 389
ITR 390
ITR 391
ITR 392
ITR 393
ITR 394
ITR 395
ITR 396
ITR 397
ITR 398
ITR 399
ITR 400
ITR 401
ITR 402
ITR 403
ITR 404
ITR 405
ITR 406
ITR 407
ITR 408
ITR 409
ITR 410
ITR 411
ITR 412
ITR 413
ITR 414
ITR 415
ITR 416
ITR 417
ITR 418
ITR 419
ITR 420
ITR 421
ITR 422
ITR 423
ITR 424
ITR 425
ITR 426
ITR 427
ITR 428
ITR 429
ITR 430
ITR 431
ITR 432
ITR 433
ITR 434
ITR 435
ITR 436
ITR 437
ITR 438
ITR 439
ITR 440
ITR 441
ITR 442
ITR 443
ITR 444
ITR 445
ITR 446
ITR 447
ITR 448
ITR 449
ITR 450
ITR 451
ITR 452
ITR 453
ITR 454
ITR 455
ITR 456
ITR 457
ITR 458
ITR 459
ITR 460
ITR 461
ITR 462
ITR 463
ITR 464
ITR 465
ITR 466
ITR 467
ITR 468
ITR 469
ITR 470
ITR 471
ITR 472
ITR 473
ITR 474
ITR 475
ITR 476
ITR 477
ITR 478
ITR 479
ITR 480
ITR 481
ITR 482
ITR 483
ITR 484
ITR 485
ITR 486
ITR 487
ITR 488
ITR 489
ITR 490
ITR 491
ITR 492
ITR 493
ITR 494
ITR 495
ITR 496
ITR 497
ITR 498
ITR 499
The max len is 1809
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/numpy/lib/function_base.py:4573: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/numpy/lib/function_base.py:4573: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/numpy/lib/function_base.py:4573: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/numpy/lib/function_base.py:4573: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/numpy/lib/function_base.py:4573: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/numpy/lib/function_base.py:4573: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    994586.74 MB
	Train Data (Original)  Memory Usage: 1.81 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 194 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Stage 5 Generators:
		Fitting DropDuplicatesFeatureGenerator...
	Unused Original Features (Count: 193): ['1616', '1617', '1618', '1619', '1620', '1621', '1622', '1623', '1624', '1625', '1626', '1627', '1628', '1629', '1630', '1631', '1632', '1633', '1634', '1635', '1636', '1637', '1638', '1639', '1640', '1641', '1642', '1643', '1644', '1645', '1646', '1647', '1648', '1649', '1650', '1651', '1652', '1653', '1654', '1655', '1656', '1657', '1658', '1659', '1660', '1661', '1662', '1663', '1664', '1665', '1666', '1667', '1668', '1669', '1670', '1671', '1672', '1673', '1674', '1675', '1676', '1677', '1678', '1679', '1680', '1681', '1682', '1683', '1684', '1685', '1686', '1687', '1688', '1689', '1690', '1691', '1692', '1693', '1694', '1695', '1696', '1697', '1698', '1699', '1700', '1701', '1702', '1703', '1704', '1705', '1706', '1707', '1708', '1709', '1710', '1711', '1712', '1713', '1714', '1715', '1716', '1717', '1718', '1719', '1720', '1721', '1722', '1723', '1724', '1725', '1726', '1727', '1728', '1729', '1730', '1731', '1732', '1733', '1734', '1735', '1736', '1737', '1738', '1739', '1740', '1741', '1742', '1743', '1744', '1745', '1746', '1747', '1748', '1749', '1750', '1751', '1752', '1753', '1754', '1755', '1756', '1757', '1758', '1759', '1760', '1761', '1762', '1763', '1764', '1765', '1766', '1767', '1768', '1769', '1770', '1771', '1772', '1773', '1774', '1775', '1776', '1777', '1778', '1779', '1780', '1781', '1782', '1783', '1784', '1785', '1786', '1787', '1788', '1789', '1790', '1791', '1792', '1793', '1794', '1795', '1796', '1797', '1798', '1799', '1800', '1801', '1802', '1803', '1804', '1805', '1806', '1807', '1808']
		These features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.
		Features can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.
		These features do not need to be present at inference time.
		('float', []) : 193 | ['1616', '1617', '1618', '1619', '1620', ...]
	Types of features in original data (raw dtype, special dtypes):
		('float', []) : 1616 | ['0', '1', '2', '3', '4', ...]
	Types of features in processed data (raw dtype, special dtypes):
		('float', [])     : 1615 | ['0', '1', '2', '3', '4', ...]
		('int', ['bool']) :    1 | ['1615']
	12.9s = Fit runtime
	1616 features in original data used to generate 1616 features in processed data.
	Train Data (Processed) Memory Usage: 1.62 MB (0.0% of available memory)
<class 'pandas.core.frame.DataFrame'>
Hyperparameter Set
Hyperparameter Set
Learning rate set to 0.032889
0:	learn: 0.8552494	total: 130ms	remaining: 2m 10s
1:	learn: 0.8524303	total: 165ms	remaining: 1m 22s
2:	learn: 0.8486662	total: 197ms	remaining: 1m 5s
3:	learn: 0.8452724	total: 229ms	remaining: 57.1s
4:	learn: 0.8431664	total: 269ms	remaining: 53.5s
5:	learn: 0.8409805	total: 303ms	remaining: 50.1s
6:	learn: 0.8390561	total: 336ms	remaining: 47.7s
7:	learn: 0.8346168	total: 367ms	remaining: 45.5s
8:	learn: 0.8301172	total: 403ms	remaining: 44.4s
9:	learn: 0.8281132	total: 447ms	remaining: 44.2s
10:	learn: 0.8268768	total: 483ms	remaining: 43.5s
11:	learn: 0.8245000	total: 518ms	remaining: 42.6s
12:	learn: 0.8214656	total: 549ms	remaining: 41.7s
13:	learn: 0.8187898	total: 580ms	remaining: 40.8s
14:	learn: 0.8157954	total: 619ms	remaining: 40.6s
15:	learn: 0.8140377	total: 655ms	remaining: 40.3s
16:	learn: 0.8123198	total: 692ms	remaining: 40s
17:	learn: 0.8085390	total: 724ms	remaining: 39.5s
18:	learn: 0.8052622	total: 758ms	remaining: 39.2s
19:	learn: 0.8026435	total: 789ms	remaining: 38.7s
20:	learn: 0.8018006	total: 819ms	remaining: 38.2s
21:	learn: 0.8007000	total: 853ms	remaining: 37.9s
22:	learn: 0.7982813	total: 885ms	remaining: 37.6s
23:	learn: 0.7969412	total: 924ms	remaining: 37.6s
24:	learn: 0.7943164	total: 958ms	remaining: 37.4s
25:	learn: 0.7933730	total: 992ms	remaining: 37.1s
26:	learn: 0.7920494	total: 1.02s	remaining: 36.9s
27:	learn: 0.7886645	total: 1.05s	remaining: 36.6s
28:	learn: 0.7848702	total: 1.09s	remaining: 36.4s
29:	learn: 0.7805669	total: 1.12s	remaining: 36.1s
30:	learn: 0.7780254	total: 1.15s	remaining: 35.9s
31:	learn: 0.7770102	total: 1.18s	remaining: 35.7s
32:	learn: 0.7745860	total: 1.22s	remaining: 35.8s
33:	learn: 0.7733063	total: 1.26s	remaining: 35.7s
34:	learn: 0.7701655	total: 1.29s	remaining: 35.5s
35:	learn: 0.7668575	total: 1.31s	remaining: 35s
36:	learn: 0.7630725	total: 1.35s	remaining: 35.1s
37:	learn: 0.7599124	total: 1.38s	remaining: 34.9s
38:	learn: 0.7578208	total: 1.41s	remaining: 34.8s
39:	learn: 0.7561373	total: 1.44s	remaining: 34.6s
40:	learn: 0.7550843	total: 1.47s	remaining: 34.5s
41:	learn: 0.7519404	total: 1.5s	remaining: 34.3s
42:	learn: 0.7487951	total: 1.53s	remaining: 34.2s
43:	learn: 0.7467204	total: 1.57s	remaining: 34.2s
44:	learn: 0.7428118	total: 1.6s	remaining: 34s
45:	learn: 0.7396055	total: 1.63s	remaining: 33.9s
46:	learn: 0.7387251	total: 1.66s	remaining: 33.7s
47:	learn: 0.7361469	total: 1.69s	remaining: 33.6s
48:	learn: 0.7352386	total: 1.73s	remaining: 33.6s
49:	learn: 0.7312640	total: 1.76s	remaining: 33.5s
50:	learn: 0.7296183	total: 1.79s	remaining: 33.4s
51:	learn: 0.7263201	total: 1.82s	remaining: 33.2s
52:	learn: 0.7223733	total: 1.85s	remaining: 33.1s
53:	learn: 0.7202517	total: 1.88s	remaining: 33s
54:	learn: 0.7176908	total: 1.92s	remaining: 32.9s
55:	learn: 0.7139608	total: 1.95s	remaining: 32.8s
56:	learn: 0.7118258	total: 1.98s	remaining: 32.7s
57:	learn: 0.7100912	total: 2s	remaining: 32.6s
58:	learn: 0.7077558	total: 2.04s	remaining: 32.5s
59:	learn: 0.7054226	total: 2.07s	remaining: 32.4s
60:	learn: 0.7022235	total: 2.1s	remaining: 32.4s
61:	learn: 0.6993528	total: 2.14s	remaining: 32.4s
62:	learn: 0.6970585	total: 2.17s	remaining: 32.3s
63:	learn: 0.6940251	total: 2.2s	remaining: 32.2s
64:	learn: 0.6909180	total: 2.23s	remaining: 32.1s
65:	learn: 0.6855323	total: 2.27s	remaining: 32.1s
66:	learn: 0.6823923	total: 2.3s	remaining: 32s
67:	learn: 0.6805245	total: 2.33s	remaining: 31.9s
68:	learn: 0.6793957	total: 2.36s	remaining: 31.8s
69:	learn: 0.6759821	total: 2.39s	remaining: 31.7s
70:	learn: 0.6754031	total: 2.42s	remaining: 31.7s
71:	learn: 0.6722322	total: 2.45s	remaining: 31.6s
72:	learn: 0.6681062	total: 2.48s	remaining: 31.5s
73:	learn: 0.6650081	total: 2.52s	remaining: 31.5s
74:	learn: 0.6609672	total: 2.55s	remaining: 31.4s
75:	learn: 0.6580376	total: 2.58s	remaining: 31.3s
76:	learn: 0.6553965	total: 2.61s	remaining: 31.2s
77:	learn: 0.6511128	total: 2.64s	remaining: 31.2s
78:	learn: 0.6490977	total: 2.67s	remaining: 31.1s
79:	learn: 0.6457704	total: 2.7s	remaining: 31s
80:	learn: 0.6428233	total: 2.73s	remaining: 31s
81:	learn: 0.6395677	total: 2.76s	remaining: 30.9s
82:	learn: 0.6362543	total: 2.79s	remaining: 30.9s
83:	learn: 0.6351996	total: 2.82s	remaining: 30.8s
84:	learn: 0.6329731	total: 2.86s	remaining: 30.8s
85:	learn: 0.6315502	total: 2.89s	remaining: 30.7s
86:	learn: 0.6285046	total: 2.92s	remaining: 30.6s
87:	learn: 0.6256433	total: 2.95s	remaining: 30.6s
88:	learn: 0.6235934	total: 2.98s	remaining: 30.5s
89:	learn: 0.6218962	total: 3.01s	remaining: 30.4s
90:	learn: 0.6191894	total: 3.04s	remaining: 30.4s
91:	learn: 0.6161929	total: 3.07s	remaining: 30.3s
92:	learn: 0.6132376	total: 3.1s	remaining: 30.2s
93:	learn: 0.6112758	total: 3.13s	remaining: 30.2s
94:	learn: 0.6091427	total: 3.16s	remaining: 30.1s
95:	learn: 0.6070271	total: 3.2s	remaining: 30.1s
96:	learn: 0.6027002	total: 3.23s	remaining: 30s
97:	learn: 0.6004132	total: 3.26s	remaining: 30s
98:	learn: 0.5972827	total: 3.29s	remaining: 30s
99:	learn: 0.5946759	total: 3.32s	remaining: 29.9s
100:	learn: 0.5928559	total: 3.35s	remaining: 29.8s
101:	learn: 0.5906070	total: 3.38s	remaining: 29.8s
102:	learn: 0.5876020	total: 3.41s	remaining: 29.7s
103:	learn: 0.5841471	total: 3.44s	remaining: 29.7s
104:	learn: 0.5812363	total: 3.47s	remaining: 29.6s
105:	learn: 0.5787590	total: 3.5s	remaining: 29.5s
106:	learn: 0.5756030	total: 3.53s	remaining: 29.5s
107:	learn: 0.5729879	total: 3.56s	remaining: 29.4s
108:	learn: 0.5693334	total: 3.59s	remaining: 29.3s
109:	learn: 0.5660143	total: 3.62s	remaining: 29.3s
110:	learn: 0.5644715	total: 3.66s	remaining: 29.3s
111:	learn: 0.5613487	total: 3.69s	remaining: 29.2s
112:	learn: 0.5590737	total: 3.71s	remaining: 29.2s
113:	learn: 0.5562266	total: 3.74s	remaining: 29.1s
114:	learn: 0.5549275	total: 3.77s	remaining: 29s
115:	learn: 0.5516619	total: 3.81s	remaining: 29s
116:	learn: 0.5493564	total: 3.83s	remaining: 28.9s
117:	learn: 0.5468536	total: 3.86s	remaining: 28.9s
118:	learn: 0.5446445	total: 3.89s	remaining: 28.8s
119:	learn: 0.5423551	total: 3.92s	remaining: 28.8s
120:	learn: 0.5401294	total: 3.95s	remaining: 28.7s
121:	learn: 0.5376056	total: 3.98s	remaining: 28.7s
122:	learn: 0.5357432	total: 4.01s	remaining: 28.6s
123:	learn: 0.5337329	total: 4.04s	remaining: 28.6s
124:	learn: 0.5319570	total: 4.08s	remaining: 28.6s
125:	learn: 0.5298559	total: 4.12s	remaining: 28.5s
126:	learn: 0.5272257	total: 4.14s	remaining: 28.5s
127:	learn: 0.5265329	total: 4.18s	remaining: 28.5s
128:	learn: 0.5240831	total: 4.21s	remaining: 28.5s
129:	learn: 0.5212171	total: 4.25s	remaining: 28.4s
130:	learn: 0.5191055	total: 4.28s	remaining: 28.4s
131:	learn: 0.5171597	total: 4.31s	remaining: 28.4s
132:	learn: 0.5151983	total: 4.34s	remaining: 28.3s
133:	learn: 0.5131249	total: 4.38s	remaining: 28.3s
134:	learn: 0.5125209	total: 4.4s	remaining: 28.2s
135:	learn: 0.5106051	total: 4.43s	remaining: 28.2s
136:	learn: 0.5088716	total: 4.46s	remaining: 28.1s
137:	learn: 0.5065806	total: 4.5s	remaining: 28.1s
138:	learn: 0.5044399	total: 4.53s	remaining: 28.1s
139:	learn: 0.5020473	total: 4.56s	remaining: 28s
140:	learn: 0.4989616	total: 4.59s	remaining: 28s
141:	learn: 0.4973249	total: 4.62s	remaining: 27.9s
142:	learn: 0.4952943	total: 4.66s	remaining: 27.9s
143:	learn: 0.4945829	total: 4.69s	remaining: 27.9s
144:	learn: 0.4916822	total: 4.72s	remaining: 27.8s
145:	learn: 0.4896530	total: 4.75s	remaining: 27.8s
146:	learn: 0.4878617	total: 4.79s	remaining: 27.8s
147:	learn: 0.4863622	total: 4.82s	remaining: 27.7s
148:	learn: 0.4845144	total: 4.85s	remaining: 27.7s
149:	learn: 0.4819987	total: 4.88s	remaining: 27.7s
150:	learn: 0.4797503	total: 4.92s	remaining: 27.7s
151:	learn: 0.4779339	total: 4.95s	remaining: 27.6s
152:	learn: 0.4761716	total: 4.98s	remaining: 27.6s
153:	learn: 0.4735606	total: 5.01s	remaining: 27.6s
154:	learn: 0.4718072	total: 5.05s	remaining: 27.5s
155:	learn: 0.4700361	total: 5.08s	remaining: 27.5s
156:	learn: 0.4692228	total: 5.11s	remaining: 27.4s
157:	learn: 0.4667814	total: 5.14s	remaining: 27.4s
158:	learn: 0.4644680	total: 5.17s	remaining: 27.4s
159:	learn: 0.4629052	total: 5.2s	remaining: 27.3s
160:	learn: 0.4600931	total: 5.23s	remaining: 27.3s
161:	learn: 0.4577855	total: 5.26s	remaining: 27.2s
162:	learn: 0.4558277	total: 5.29s	remaining: 27.2s
163:	learn: 0.4521970	total: 5.33s	remaining: 27.2s
164:	learn: 0.4499491	total: 5.36s	remaining: 27.1s
165:	learn: 0.4470922	total: 5.39s	remaining: 27.1s
166:	learn: 0.4453153	total: 5.42s	remaining: 27s
167:	learn: 0.4438063	total: 5.45s	remaining: 27s
168:	learn: 0.4412521	total: 5.48s	remaining: 26.9s
169:	learn: 0.4395897	total: 5.51s	remaining: 26.9s
170:	learn: 0.4388673	total: 5.54s	remaining: 26.9s
171:	learn: 0.4363815	total: 5.57s	remaining: 26.8s
172:	learn: 0.4334541	total: 5.6s	remaining: 26.8s
173:	learn: 0.4309879	total: 5.63s	remaining: 26.7s
174:	learn: 0.4284703	total: 5.66s	remaining: 26.7s
175:	learn: 0.4261326	total: 5.69s	remaining: 26.6s
176:	learn: 0.4237390	total: 5.72s	remaining: 26.6s
177:	learn: 0.4204125	total: 5.75s	remaining: 26.6s
178:	learn: 0.4183448	total: 5.78s	remaining: 26.5s
179:	learn: 0.4156741	total: 5.81s	remaining: 26.5s
180:	learn: 0.4125037	total: 5.84s	remaining: 26.4s
181:	learn: 0.4114090	total: 5.88s	remaining: 26.4s
182:	learn: 0.4094766	total: 5.91s	remaining: 26.4s
183:	learn: 0.4075154	total: 5.94s	remaining: 26.3s
184:	learn: 0.4057957	total: 5.97s	remaining: 26.3s
185:	learn: 0.4037259	total: 6s	remaining: 26.2s
186:	learn: 0.4021037	total: 6.03s	remaining: 26.2s
187:	learn: 0.4000189	total: 6.06s	remaining: 26.2s
188:	learn: 0.3969993	total: 6.09s	remaining: 26.1s
189:	learn: 0.3961884	total: 6.12s	remaining: 26.1s
190:	learn: 0.3936529	total: 6.15s	remaining: 26.1s
191:	learn: 0.3913464	total: 6.18s	remaining: 26s
192:	learn: 0.3894485	total: 6.21s	remaining: 26s
193:	learn: 0.3874613	total: 6.24s	remaining: 25.9s
194:	learn: 0.3858558	total: 6.27s	remaining: 25.9s
195:	learn: 0.3831845	total: 6.3s	remaining: 25.8s
196:	learn: 0.3811605	total: 6.33s	remaining: 25.8s
197:	learn: 0.3785776	total: 6.36s	remaining: 25.8s
198:	learn: 0.3756238	total: 6.39s	remaining: 25.7s
199:	learn: 0.3730584	total: 6.42s	remaining: 25.7s
200:	learn: 0.3704766	total: 6.46s	remaining: 25.7s
201:	learn: 0.3686907	total: 6.49s	remaining: 25.6s
202:	learn: 0.3658227	total: 6.53s	remaining: 25.6s
203:	learn: 0.3635441	total: 6.56s	remaining: 25.6s
204:	learn: 0.3619895	total: 6.59s	remaining: 25.6s
205:	learn: 0.3596461	total: 6.63s	remaining: 25.5s
206:	learn: 0.3562472	total: 6.65s	remaining: 25.5s
207:	learn: 0.3533843	total: 6.68s	remaining: 25.5s
208:	learn: 0.3516063	total: 6.72s	remaining: 25.4s
209:	learn: 0.3496378	total: 6.75s	remaining: 25.4s
210:	learn: 0.3478379	total: 6.77s	remaining: 25.3s
211:	learn: 0.3460140	total: 6.8s	remaining: 25.3s
212:	learn: 0.3434440	total: 6.83s	remaining: 25.2s
213:	learn: 0.3412819	total: 6.86s	remaining: 25.2s
214:	learn: 0.3395032	total: 6.89s	remaining: 25.1s
215:	learn: 0.3373021	total: 6.92s	remaining: 25.1s
216:	learn: 0.3355657	total: 6.95s	remaining: 25.1s
217:	learn: 0.3337116	total: 6.97s	remaining: 25s
218:	learn: 0.3317349	total: 7s	remaining: 25s
219:	learn: 0.3292569	total: 7.03s	remaining: 24.9s
220:	learn: 0.3280876	total: 7.05s	remaining: 24.9s
221:	learn: 0.3267792	total: 7.08s	remaining: 24.8s
222:	learn: 0.3244310	total: 7.11s	remaining: 24.8s
223:	learn: 0.3226876	total: 7.14s	remaining: 24.7s
224:	learn: 0.3202463	total: 7.17s	remaining: 24.7s
225:	learn: 0.3172812	total: 7.19s	remaining: 24.6s
226:	learn: 0.3150043	total: 7.22s	remaining: 24.6s
227:	learn: 0.3122468	total: 7.26s	remaining: 24.6s
228:	learn: 0.3110836	total: 7.29s	remaining: 24.6s
229:	learn: 0.3094806	total: 7.32s	remaining: 24.5s
230:	learn: 0.3072006	total: 7.34s	remaining: 24.5s
231:	learn: 0.3054222	total: 7.38s	remaining: 24.4s
232:	learn: 0.3023218	total: 7.41s	remaining: 24.4s
233:	learn: 0.2993057	total: 7.44s	remaining: 24.4s
234:	learn: 0.2982577	total: 7.47s	remaining: 24.3s
235:	learn: 0.2959657	total: 7.49s	remaining: 24.3s
236:	learn: 0.2938448	total: 7.52s	remaining: 24.2s
237:	learn: 0.2918595	total: 7.55s	remaining: 24.2s
238:	learn: 0.2895205	total: 7.58s	remaining: 24.1s
239:	learn: 0.2869110	total: 7.61s	remaining: 24.1s
240:	learn: 0.2852232	total: 7.64s	remaining: 24.1s
241:	learn: 0.2827556	total: 7.67s	remaining: 24s
242:	learn: 0.2800961	total: 7.7s	remaining: 24s
243:	learn: 0.2782880	total: 7.72s	remaining: 23.9s
244:	learn: 0.2759449	total: 7.75s	remaining: 23.9s
245:	learn: 0.2743406	total: 7.78s	remaining: 23.9s
246:	learn: 0.2730731	total: 7.81s	remaining: 23.8s
247:	learn: 0.2713232	total: 7.84s	remaining: 23.8s
248:	learn: 0.2693766	total: 7.88s	remaining: 23.8s
249:	learn: 0.2672642	total: 7.91s	remaining: 23.7s
250:	learn: 0.2655235	total: 7.94s	remaining: 23.7s
251:	learn: 0.2629721	total: 7.97s	remaining: 23.7s
252:	learn: 0.2609184	total: 8s	remaining: 23.6s
253:	learn: 0.2587838	total: 8.03s	remaining: 23.6s
254:	learn: 0.2562942	total: 8.07s	remaining: 23.6s
255:	learn: 0.2543761	total: 8.1s	remaining: 23.5s
256:	learn: 0.2525263	total: 8.12s	remaining: 23.5s
257:	learn: 0.2510223	total: 8.16s	remaining: 23.5s
258:	learn: 0.2498905	total: 8.19s	remaining: 23.4s
259:	learn: 0.2484751	total: 8.22s	remaining: 23.4s
260:	learn: 0.2469764	total: 8.26s	remaining: 23.4s
261:	learn: 0.2449675	total: 8.29s	remaining: 23.3s
262:	learn: 0.2425604	total: 8.31s	remaining: 23.3s
263:	learn: 0.2404454	total: 8.35s	remaining: 23.3s
264:	learn: 0.2383626	total: 8.37s	remaining: 23.2s
265:	learn: 0.2362781	total: 8.4s	remaining: 23.2s
266:	learn: 0.2344534	total: 8.43s	remaining: 23.1s
267:	learn: 0.2327109	total: 8.47s	remaining: 23.1s
268:	learn: 0.2312364	total: 8.5s	remaining: 23.1s
269:	learn: 0.2295899	total: 8.53s	remaining: 23.1s
270:	learn: 0.2275531	total: 8.56s	remaining: 23s
271:	learn: 0.2252717	total: 8.59s	remaining: 23s
272:	learn: 0.2231422	total: 8.62s	remaining: 22.9s
273:	learn: 0.2211067	total: 8.64s	remaining: 22.9s
274:	learn: 0.2196446	total: 8.68s	remaining: 22.9s
275:	learn: 0.2183806	total: 8.71s	remaining: 22.9s
276:	learn: 0.2162777	total: 8.74s	remaining: 22.8s
277:	learn: 0.2147153	total: 8.78s	remaining: 22.8s
278:	learn: 0.2128517	total: 8.81s	remaining: 22.8s
279:	learn: 0.2110477	total: 8.84s	remaining: 22.7s
280:	learn: 0.2093819	total: 8.87s	remaining: 22.7s
281:	learn: 0.2072034	total: 8.9s	remaining: 22.7s
282:	learn: 0.2061928	total: 8.93s	remaining: 22.6s
283:	learn: 0.2045488	total: 8.97s	remaining: 22.6s
284:	learn: 0.2026333	total: 9s	remaining: 22.6s
285:	learn: 0.2014106	total: 9.03s	remaining: 22.5s
286:	learn: 0.1994832	total: 9.06s	remaining: 22.5s
287:	learn: 0.1973468	total: 9.09s	remaining: 22.5s
288:	learn: 0.1955405	total: 9.12s	remaining: 22.4s
289:	learn: 0.1940111	total: 9.15s	remaining: 22.4s
290:	learn: 0.1930900	total: 9.18s	remaining: 22.4s
291:	learn: 0.1913864	total: 9.21s	remaining: 22.3s
292:	learn: 0.1894372	total: 9.25s	remaining: 22.3s
293:	learn: 0.1878344	total: 9.28s	remaining: 22.3s
294:	learn: 0.1865936	total: 9.31s	remaining: 22.2s
295:	learn: 0.1855667	total: 9.34s	remaining: 22.2s
296:	learn: 0.1838711	total: 9.37s	remaining: 22.2s
297:	learn: 0.1821768	total: 9.4s	remaining: 22.1s
298:	learn: 0.1804780	total: 9.43s	remaining: 22.1s
299:	learn: 0.1785915	total: 9.46s	remaining: 22.1s
300:	learn: 0.1769625	total: 9.5s	remaining: 22.1s
301:	learn: 0.1756652	total: 9.53s	remaining: 22s
302:	learn: 0.1739879	total: 9.56s	remaining: 22s
303:	learn: 0.1726338	total: 9.59s	remaining: 22s
304:	learn: 0.1716840	total: 9.62s	remaining: 21.9s
305:	learn: 0.1706625	total: 9.65s	remaining: 21.9s
306:	learn: 0.1692854	total: 9.68s	remaining: 21.9s
307:	learn: 0.1685124	total: 9.71s	remaining: 21.8s
308:	learn: 0.1677579	total: 9.74s	remaining: 21.8s
309:	learn: 0.1666969	total: 9.78s	remaining: 21.8s
310:	learn: 0.1651876	total: 9.81s	remaining: 21.7s
311:	learn: 0.1634920	total: 9.84s	remaining: 21.7s
312:	learn: 0.1626290	total: 9.87s	remaining: 21.7s
313:	learn: 0.1616209	total: 9.9s	remaining: 21.6s
314:	learn: 0.1600148	total: 9.93s	remaining: 21.6s
315:	learn: 0.1588174	total: 9.96s	remaining: 21.6s
316:	learn: 0.1575108	total: 9.99s	remaining: 21.5s
317:	learn: 0.1562181	total: 10s	remaining: 21.5s
318:	learn: 0.1546766	total: 10s	remaining: 21.5s
319:	learn: 0.1531642	total: 10.1s	remaining: 21.4s
320:	learn: 0.1517502	total: 10.1s	remaining: 21.4s
321:	learn: 0.1503460	total: 10.1s	remaining: 21.3s
322:	learn: 0.1488844	total: 10.2s	remaining: 21.3s
323:	learn: 0.1476778	total: 10.2s	remaining: 21.3s
324:	learn: 0.1462489	total: 10.2s	remaining: 21.2s
325:	learn: 0.1454111	total: 10.3s	remaining: 21.2s
326:	learn: 0.1446234	total: 10.3s	remaining: 21.2s
327:	learn: 0.1435206	total: 10.3s	remaining: 21.1s
328:	learn: 0.1422329	total: 10.4s	remaining: 21.1s
329:	learn: 0.1410344	total: 10.4s	remaining: 21.1s
330:	learn: 0.1398832	total: 10.4s	remaining: 21.1s
331:	learn: 0.1383967	total: 10.5s	remaining: 21s
332:	learn: 0.1374040	total: 10.5s	remaining: 21s
333:	learn: 0.1363616	total: 10.5s	remaining: 21s
334:	learn: 0.1350615	total: 10.5s	remaining: 20.9s
335:	learn: 0.1337014	total: 10.6s	remaining: 20.9s
336:	learn: 0.1328463	total: 10.6s	remaining: 20.9s
337:	learn: 0.1314823	total: 10.6s	remaining: 20.8s
338:	learn: 0.1303009	total: 10.7s	remaining: 20.8s
339:	learn: 0.1290706	total: 10.7s	remaining: 20.8s
340:	learn: 0.1281912	total: 10.7s	remaining: 20.7s
341:	learn: 0.1271457	total: 10.8s	remaining: 20.7s
342:	learn: 0.1260113	total: 10.8s	remaining: 20.7s
343:	learn: 0.1252735	total: 10.8s	remaining: 20.6s
344:	learn: 0.1240608	total: 10.8s	remaining: 20.6s
345:	learn: 0.1230251	total: 10.9s	remaining: 20.6s
346:	learn: 0.1221914	total: 10.9s	remaining: 20.5s
347:	learn: 0.1211534	total: 10.9s	remaining: 20.5s
348:	learn: 0.1203863	total: 11s	remaining: 20.5s
349:	learn: 0.1194557	total: 11s	remaining: 20.4s
350:	learn: 0.1185578	total: 11s	remaining: 20.4s
351:	learn: 0.1173753	total: 11.1s	remaining: 20.4s
352:	learn: 0.1166175	total: 11.1s	remaining: 20.3s
353:	learn: 0.1155751	total: 11.1s	remaining: 20.3s
354:	learn: 0.1149364	total: 11.2s	remaining: 20.3s
355:	learn: 0.1139205	total: 11.2s	remaining: 20.2s
356:	learn: 0.1130835	total: 11.2s	remaining: 20.2s
357:	learn: 0.1123561	total: 11.2s	remaining: 20.2s
358:	learn: 0.1114380	total: 11.3s	remaining: 20.1s
359:	learn: 0.1105826	total: 11.3s	remaining: 20.1s
360:	learn: 0.1097363	total: 11.3s	remaining: 20.1s
361:	learn: 0.1087786	total: 11.4s	remaining: 20s
362:	learn: 0.1079171	total: 11.4s	remaining: 20s
363:	learn: 0.1071279	total: 11.4s	remaining: 20s
364:	learn: 0.1063005	total: 11.5s	remaining: 19.9s
365:	learn: 0.1054202	total: 11.5s	remaining: 19.9s
366:	learn: 0.1046302	total: 11.5s	remaining: 19.9s
367:	learn: 0.1041325	total: 11.5s	remaining: 19.8s
368:	learn: 0.1031753	total: 11.6s	remaining: 19.8s
369:	learn: 0.1024111	total: 11.6s	remaining: 19.8s
370:	learn: 0.1017578	total: 11.6s	remaining: 19.7s
371:	learn: 0.1012301	total: 11.7s	remaining: 19.7s
372:	learn: 0.1004561	total: 11.7s	remaining: 19.7s
373:	learn: 0.0995960	total: 11.7s	remaining: 19.6s
374:	learn: 0.0986879	total: 11.8s	remaining: 19.6s
375:	learn: 0.0982521	total: 11.8s	remaining: 19.6s
376:	learn: 0.0975143	total: 11.8s	remaining: 19.5s
377:	learn: 0.0965949	total: 11.9s	remaining: 19.5s
378:	learn: 0.0960321	total: 11.9s	remaining: 19.5s
379:	learn: 0.0950034	total: 11.9s	remaining: 19.4s
380:	learn: 0.0942555	total: 11.9s	remaining: 19.4s
381:	learn: 0.0934098	total: 12s	remaining: 19.4s
382:	learn: 0.0926682	total: 12s	remaining: 19.3s
383:	learn: 0.0919385	total: 12s	remaining: 19.3s
384:	learn: 0.0911960	total: 12.1s	remaining: 19.3s
385:	learn: 0.0906972	total: 12.1s	remaining: 19.2s
386:	learn: 0.0898713	total: 12.1s	remaining: 19.2s
387:	learn: 0.0890116	total: 12.2s	remaining: 19.2s
388:	learn: 0.0883166	total: 12.2s	remaining: 19.1s
389:	learn: 0.0876735	total: 12.2s	remaining: 19.1s
390:	learn: 0.0868864	total: 12.2s	remaining: 19.1s
391:	learn: 0.0864455	total: 12.3s	remaining: 19s
392:	learn: 0.0856181	total: 12.3s	remaining: 19s
393:	learn: 0.0848382	total: 12.3s	remaining: 19s
394:	learn: 0.0843390	total: 12.4s	remaining: 19s
395:	learn: 0.0838017	total: 12.4s	remaining: 18.9s
396:	learn: 0.0833007	total: 12.4s	remaining: 18.9s
397:	learn: 0.0827373	total: 12.5s	remaining: 18.9s
398:	learn: 0.0820078	total: 12.5s	remaining: 18.8s
399:	learn: 0.0812473	total: 12.5s	remaining: 18.8s
400:	learn: 0.0806227	total: 12.6s	remaining: 18.8s
401:	learn: 0.0799058	total: 12.6s	remaining: 18.7s
402:	learn: 0.0791084	total: 12.6s	remaining: 18.7s
403:	learn: 0.0784603	total: 12.7s	remaining: 18.7s
404:	learn: 0.0777917	total: 12.7s	remaining: 18.6s
405:	learn: 0.0770018	total: 12.7s	remaining: 18.6s
406:	learn: 0.0762515	total: 12.7s	remaining: 18.6s
407:	learn: 0.0759015	total: 12.8s	remaining: 18.5s
408:	learn: 0.0753167	total: 12.8s	remaining: 18.5s
409:	learn: 0.0745815	total: 12.8s	remaining: 18.5s
410:	learn: 0.0738177	total: 12.9s	remaining: 18.4s
411:	learn: 0.0732510	total: 12.9s	remaining: 18.4s
412:	learn: 0.0729768	total: 12.9s	remaining: 18.4s
413:	learn: 0.0723300	total: 13s	remaining: 18.3s
414:	learn: 0.0716916	total: 13s	remaining: 18.3s
415:	learn: 0.0711309	total: 13s	remaining: 18.3s
416:	learn: 0.0705433	total: 13s	remaining: 18.2s
417:	learn: 0.0699339	total: 13.1s	remaining: 18.2s
418:	learn: 0.0693365	total: 13.1s	remaining: 18.2s
419:	learn: 0.0687504	total: 13.1s	remaining: 18.1s
420:	learn: 0.0680202	total: 13.2s	remaining: 18.1s
421:	learn: 0.0674811	total: 13.2s	remaining: 18.1s
422:	learn: 0.0668355	total: 13.2s	remaining: 18s
423:	learn: 0.0664409	total: 13.3s	remaining: 18s
424:	learn: 0.0658368	total: 13.3s	remaining: 18s
425:	learn: 0.0652489	total: 13.3s	remaining: 18s
426:	learn: 0.0647263	total: 13.4s	remaining: 17.9s
427:	learn: 0.0641865	total: 13.4s	remaining: 17.9s
428:	learn: 0.0638276	total: 13.4s	remaining: 17.9s
429:	learn: 0.0633140	total: 13.5s	remaining: 17.8s
430:	learn: 0.0628053	total: 13.5s	remaining: 17.8s
431:	learn: 0.0623170	total: 13.5s	remaining: 17.8s
432:	learn: 0.0620416	total: 13.5s	remaining: 17.7s
433:	learn: 0.0614975	total: 13.6s	remaining: 17.7s
434:	learn: 0.0609935	total: 13.6s	remaining: 17.7s
435:	learn: 0.0606788	total: 13.6s	remaining: 17.7s
436:	learn: 0.0604556	total: 13.7s	remaining: 17.6s
437:	learn: 0.0601037	total: 13.7s	remaining: 17.6s
438:	learn: 0.0596663	total: 13.7s	remaining: 17.6s
439:	learn: 0.0591397	total: 13.8s	remaining: 17.5s
440:	learn: 0.0587368	total: 13.8s	remaining: 17.5s
441:	learn: 0.0583048	total: 13.8s	remaining: 17.5s
442:	learn: 0.0578892	total: 13.9s	remaining: 17.4s
443:	learn: 0.0575514	total: 13.9s	remaining: 17.4s
444:	learn: 0.0569471	total: 13.9s	remaining: 17.4s
445:	learn: 0.0565386	total: 14s	remaining: 17.3s
446:	learn: 0.0560554	total: 14s	remaining: 17.3s
447:	learn: 0.0554920	total: 14s	remaining: 17.3s
448:	learn: 0.0550722	total: 14.1s	remaining: 17.3s
449:	learn: 0.0547796	total: 14.1s	remaining: 17.2s
450:	learn: 0.0543426	total: 14.1s	remaining: 17.2s
451:	learn: 0.0538708	total: 14.2s	remaining: 17.2s
452:	learn: 0.0535514	total: 14.2s	remaining: 17.1s
453:	learn: 0.0531055	total: 14.2s	remaining: 17.1s
454:	learn: 0.0526545	total: 14.3s	remaining: 17.1s
455:	learn: 0.0521908	total: 14.3s	remaining: 17s
456:	learn: 0.0517126	total: 14.3s	remaining: 17s
457:	learn: 0.0513363	total: 14.4s	remaining: 17s
458:	learn: 0.0509021	total: 14.4s	remaining: 17s
459:	learn: 0.0504570	total: 14.4s	remaining: 16.9s
460:	learn: 0.0499831	total: 14.5s	remaining: 16.9s
461:	learn: 0.0495327	total: 14.5s	remaining: 16.9s
462:	learn: 0.0490593	total: 14.5s	remaining: 16.8s
463:	learn: 0.0486887	total: 14.5s	remaining: 16.8s
464:	learn: 0.0482003	total: 14.6s	remaining: 16.8s
465:	learn: 0.0479514	total: 14.6s	remaining: 16.7s
466:	learn: 0.0474895	total: 14.6s	remaining: 16.7s
467:	learn: 0.0473355	total: 14.7s	remaining: 16.7s
468:	learn: 0.0469262	total: 14.7s	remaining: 16.6s
469:	learn: 0.0465305	total: 14.7s	remaining: 16.6s
470:	learn: 0.0461817	total: 14.8s	remaining: 16.6s
471:	learn: 0.0459638	total: 14.8s	remaining: 16.6s
472:	learn: 0.0455450	total: 14.8s	remaining: 16.5s
473:	learn: 0.0454088	total: 14.9s	remaining: 16.5s
474:	learn: 0.0450848	total: 14.9s	remaining: 16.5s
475:	learn: 0.0447071	total: 14.9s	remaining: 16.4s
476:	learn: 0.0443396	total: 14.9s	remaining: 16.4s
477:	learn: 0.0439817	total: 15s	remaining: 16.4s
478:	learn: 0.0438678	total: 15s	remaining: 16.3s
479:	learn: 0.0436471	total: 15s	remaining: 16.3s
480:	learn: 0.0432128	total: 15.1s	remaining: 16.3s
481:	learn: 0.0428806	total: 15.1s	remaining: 16.2s
482:	learn: 0.0424668	total: 15.1s	remaining: 16.2s
483:	learn: 0.0420811	total: 15.2s	remaining: 16.2s
484:	learn: 0.0417534	total: 15.2s	remaining: 16.2s
485:	learn: 0.0413986	total: 15.2s	remaining: 16.1s
486:	learn: 0.0411744	total: 15.3s	remaining: 16.1s
487:	learn: 0.0408200	total: 15.3s	remaining: 16.1s
488:	learn: 0.0404673	total: 15.3s	remaining: 16s
489:	learn: 0.0401051	total: 15.4s	remaining: 16s
490:	learn: 0.0399367	total: 15.4s	remaining: 16s
491:	learn: 0.0396261	total: 15.4s	remaining: 15.9s
492:	learn: 0.0393330	total: 15.5s	remaining: 15.9s
493:	learn: 0.0389922	total: 15.5s	remaining: 15.9s
494:	learn: 0.0387537	total: 15.5s	remaining: 15.8s
495:	learn: 0.0384740	total: 15.6s	remaining: 15.8s
496:	learn: 0.0381492	total: 15.6s	remaining: 15.8s
497:	learn: 0.0377594	total: 15.6s	remaining: 15.7s
498:	learn: 0.0375205	total: 15.6s	remaining: 15.7s
499:	learn: 0.0371247	total: 15.7s	remaining: 15.7s
500:	learn: 0.0370139	total: 15.7s	remaining: 15.6s
501:	learn: 0.0367199	total: 15.7s	remaining: 15.6s
502:	learn: 0.0363561	total: 15.8s	remaining: 15.6s
503:	learn: 0.0360497	total: 15.8s	remaining: 15.5s
504:	learn: 0.0357906	total: 15.8s	remaining: 15.5s
505:	learn: 0.0355096	total: 15.9s	remaining: 15.5s
506:	learn: 0.0353000	total: 15.9s	remaining: 15.5s
507:	learn: 0.0349826	total: 15.9s	remaining: 15.4s
508:	learn: 0.0347792	total: 16s	remaining: 15.4s
509:	learn: 0.0345053	total: 16s	remaining: 15.4s
510:	learn: 0.0342430	total: 16s	remaining: 15.3s
511:	learn: 0.0339338	total: 16.1s	remaining: 15.3s
512:	learn: 0.0336211	total: 16.1s	remaining: 15.3s
513:	learn: 0.0333624	total: 16.1s	remaining: 15.2s
514:	learn: 0.0330627	total: 16.1s	remaining: 15.2s
515:	learn: 0.0329270	total: 16.2s	remaining: 15.2s
516:	learn: 0.0328312	total: 16.2s	remaining: 15.1s
517:	learn: 0.0325254	total: 16.2s	remaining: 15.1s
518:	learn: 0.0323169	total: 16.3s	remaining: 15.1s
519:	learn: 0.0320442	total: 16.3s	remaining: 15s
520:	learn: 0.0318133	total: 16.3s	remaining: 15s
521:	learn: 0.0315608	total: 16.4s	remaining: 15s
522:	learn: 0.0313212	total: 16.4s	remaining: 15s
523:	learn: 0.0310683	total: 16.4s	remaining: 14.9s
524:	learn: 0.0307870	total: 16.5s	remaining: 14.9s
525:	learn: 0.0304759	total: 16.5s	remaining: 14.9s
526:	learn: 0.0301569	total: 16.5s	remaining: 14.8s
527:	learn: 0.0299212	total: 16.6s	remaining: 14.8s
528:	learn: 0.0296515	total: 16.6s	remaining: 14.8s
529:	learn: 0.0293792	total: 16.6s	remaining: 14.8s
530:	learn: 0.0290595	total: 16.7s	remaining: 14.7s
531:	learn: 0.0288285	total: 16.7s	remaining: 14.7s
532:	learn: 0.0285652	total: 16.7s	remaining: 14.7s
533:	learn: 0.0283891	total: 16.8s	remaining: 14.6s
534:	learn: 0.0282216	total: 16.8s	remaining: 14.6s
535:	learn: 0.0279752	total: 16.8s	remaining: 14.6s
536:	learn: 0.0277361	total: 16.9s	remaining: 14.5s
537:	learn: 0.0274532	total: 16.9s	remaining: 14.5s
538:	learn: 0.0272114	total: 16.9s	remaining: 14.5s
539:	learn: 0.0269786	total: 16.9s	remaining: 14.4s
540:	learn: 0.0267229	total: 17s	remaining: 14.4s
541:	learn: 0.0264911	total: 17s	remaining: 14.4s
542:	learn: 0.0262542	total: 17s	remaining: 14.3s
543:	learn: 0.0261496	total: 17.1s	remaining: 14.3s
544:	learn: 0.0259852	total: 17.1s	remaining: 14.3s
545:	learn: 0.0257814	total: 17.1s	remaining: 14.3s
546:	learn: 0.0255400	total: 17.2s	remaining: 14.2s
547:	learn: 0.0253116	total: 17.2s	remaining: 14.2s
548:	learn: 0.0252364	total: 17.2s	remaining: 14.2s
549:	learn: 0.0250221	total: 17.3s	remaining: 14.1s
550:	learn: 0.0248112	total: 17.3s	remaining: 14.1s
551:	learn: 0.0245755	total: 17.3s	remaining: 14.1s
552:	learn: 0.0243829	total: 17.4s	remaining: 14s
553:	learn: 0.0241938	total: 17.4s	remaining: 14s
554:	learn: 0.0240076	total: 17.4s	remaining: 14s
555:	learn: 0.0238298	total: 17.4s	remaining: 13.9s
556:	learn: 0.0236352	total: 17.5s	remaining: 13.9s
557:	learn: 0.0234507	total: 17.5s	remaining: 13.9s
558:	learn: 0.0232629	total: 17.5s	remaining: 13.8s
559:	learn: 0.0230490	total: 17.6s	remaining: 13.8s
560:	learn: 0.0228358	total: 17.6s	remaining: 13.8s
561:	learn: 0.0226289	total: 17.6s	remaining: 13.7s
562:	learn: 0.0224534	total: 17.7s	remaining: 13.7s
563:	learn: 0.0222695	total: 17.7s	remaining: 13.7s
564:	learn: 0.0221507	total: 17.7s	remaining: 13.6s
565:	learn: 0.0219508	total: 17.8s	remaining: 13.6s
566:	learn: 0.0217748	total: 17.8s	remaining: 13.6s
567:	learn: 0.0215758	total: 17.8s	remaining: 13.5s
568:	learn: 0.0214511	total: 17.8s	remaining: 13.5s
569:	learn: 0.0213154	total: 17.9s	remaining: 13.5s
570:	learn: 0.0211182	total: 17.9s	remaining: 13.4s
571:	learn: 0.0209562	total: 17.9s	remaining: 13.4s
572:	learn: 0.0208829	total: 18s	remaining: 13.4s
573:	learn: 0.0206977	total: 18s	remaining: 13.4s
574:	learn: 0.0205235	total: 18s	remaining: 13.3s
575:	learn: 0.0204546	total: 18.1s	remaining: 13.3s
576:	learn: 0.0202825	total: 18.1s	remaining: 13.3s
577:	learn: 0.0201988	total: 18.1s	remaining: 13.2s
578:	learn: 0.0200202	total: 18.1s	remaining: 13.2s
579:	learn: 0.0198921	total: 18.2s	remaining: 13.2s
580:	learn: 0.0197449	total: 18.2s	remaining: 13.1s
581:	learn: 0.0196073	total: 18.2s	remaining: 13.1s
582:	learn: 0.0194388	total: 18.3s	remaining: 13.1s
583:	learn: 0.0192229	total: 18.3s	remaining: 13s
584:	learn: 0.0190355	total: 18.3s	remaining: 13s
585:	learn: 0.0188356	total: 18.4s	remaining: 13s
586:	learn: 0.0187503	total: 18.4s	remaining: 12.9s
587:	learn: 0.0185770	total: 18.4s	remaining: 12.9s
588:	learn: 0.0184139	total: 18.5s	remaining: 12.9s
589:	learn: 0.0182450	total: 18.5s	remaining: 12.8s
590:	learn: 0.0181150	total: 18.5s	remaining: 12.8s
591:	learn: 0.0180080	total: 18.5s	remaining: 12.8s
592:	learn: 0.0179529	total: 18.6s	remaining: 12.7s
593:	learn: 0.0178407	total: 18.6s	remaining: 12.7s
594:	learn: 0.0176951	total: 18.6s	remaining: 12.7s
595:	learn: 0.0175996	total: 18.7s	remaining: 12.6s
596:	learn: 0.0174244	total: 18.7s	remaining: 12.6s
597:	learn: 0.0172826	total: 18.7s	remaining: 12.6s
598:	learn: 0.0171439	total: 18.8s	remaining: 12.6s
599:	learn: 0.0170221	total: 18.8s	remaining: 12.5s
600:	learn: 0.0168826	total: 18.8s	remaining: 12.5s
601:	learn: 0.0167274	total: 18.8s	remaining: 12.5s
602:	learn: 0.0165800	total: 18.9s	remaining: 12.4s
603:	learn: 0.0164534	total: 18.9s	remaining: 12.4s
604:	learn: 0.0163625	total: 18.9s	remaining: 12.4s
605:	learn: 0.0162279	total: 19s	remaining: 12.3s
606:	learn: 0.0160839	total: 19s	remaining: 12.3s
607:	learn: 0.0159561	total: 19s	remaining: 12.3s
608:	learn: 0.0157953	total: 19.1s	remaining: 12.2s
609:	learn: 0.0156462	total: 19.1s	remaining: 12.2s
610:	learn: 0.0154989	total: 19.1s	remaining: 12.2s
611:	learn: 0.0154537	total: 19.1s	remaining: 12.1s
612:	learn: 0.0153083	total: 19.2s	remaining: 12.1s
613:	learn: 0.0151637	total: 19.2s	remaining: 12.1s
614:	learn: 0.0150509	total: 19.3s	remaining: 12.1s
615:	learn: 0.0148898	total: 19.3s	remaining: 12s
616:	learn: 0.0147714	total: 19.3s	remaining: 12s
617:	learn: 0.0146702	total: 19.3s	remaining: 12s
618:	learn: 0.0145422	total: 19.4s	remaining: 11.9s
619:	learn: 0.0144327	total: 19.4s	remaining: 11.9s
620:	learn: 0.0143006	total: 19.5s	remaining: 11.9s
621:	learn: 0.0141672	total: 19.5s	remaining: 11.8s
622:	learn: 0.0140539	total: 19.5s	remaining: 11.8s
623:	learn: 0.0139501	total: 19.6s	remaining: 11.8s
624:	learn: 0.0138263	total: 19.6s	remaining: 11.8s
625:	learn: 0.0137251	total: 19.6s	remaining: 11.7s
626:	learn: 0.0136052	total: 19.6s	remaining: 11.7s
627:	learn: 0.0134930	total: 19.7s	remaining: 11.7s
628:	learn: 0.0133971	total: 19.7s	remaining: 11.6s
629:	learn: 0.0133122	total: 19.7s	remaining: 11.6s
630:	learn: 0.0132635	total: 19.8s	remaining: 11.6s
631:	learn: 0.0131590	total: 19.8s	remaining: 11.5s
632:	learn: 0.0130498	total: 19.8s	remaining: 11.5s
633:	learn: 0.0129571	total: 19.9s	remaining: 11.5s
634:	learn: 0.0129193	total: 19.9s	remaining: 11.4s
635:	learn: 0.0128049	total: 19.9s	remaining: 11.4s
636:	learn: 0.0127003	total: 20s	remaining: 11.4s
637:	learn: 0.0126188	total: 20s	remaining: 11.3s
638:	learn: 0.0125048	total: 20s	remaining: 11.3s
639:	learn: 0.0124109	total: 20.1s	remaining: 11.3s
640:	learn: 0.0123112	total: 20.1s	remaining: 11.3s
641:	learn: 0.0122020	total: 20.1s	remaining: 11.2s
642:	learn: 0.0121149	total: 20.2s	remaining: 11.2s
643:	learn: 0.0120173	total: 20.2s	remaining: 11.2s
644:	learn: 0.0119161	total: 20.2s	remaining: 11.1s
645:	learn: 0.0118333	total: 20.3s	remaining: 11.1s
646:	learn: 0.0117399	total: 20.3s	remaining: 11.1s
647:	learn: 0.0116313	total: 20.3s	remaining: 11s
648:	learn: 0.0115230	total: 20.3s	remaining: 11s
649:	learn: 0.0114109	total: 20.4s	remaining: 11s
650:	learn: 0.0113207	total: 20.4s	remaining: 10.9s
651:	learn: 0.0112230	total: 20.4s	remaining: 10.9s
652:	learn: 0.0111475	total: 20.5s	remaining: 10.9s
653:	learn: 0.0110421	total: 20.5s	remaining: 10.8s
654:	learn: 0.0109394	total: 20.5s	remaining: 10.8s
655:	learn: 0.0109013	total: 20.6s	remaining: 10.8s
656:	learn: 0.0107933	total: 20.6s	remaining: 10.8s
657:	learn: 0.0107058	total: 20.6s	remaining: 10.7s
658:	learn: 0.0106108	total: 20.7s	remaining: 10.7s
659:	learn: 0.0105181	total: 20.7s	remaining: 10.7s
660:	learn: 0.0104200	total: 20.7s	remaining: 10.6s
661:	learn: 0.0103623	total: 20.8s	remaining: 10.6s
662:	learn: 0.0102671	total: 20.8s	remaining: 10.6s
663:	learn: 0.0102196	total: 20.8s	remaining: 10.5s
664:	learn: 0.0101214	total: 20.8s	remaining: 10.5s
665:	learn: 0.0100347	total: 20.9s	remaining: 10.5s
666:	learn: 0.0099414	total: 20.9s	remaining: 10.4s
667:	learn: 0.0098623	total: 20.9s	remaining: 10.4s
668:	learn: 0.0097852	total: 21s	remaining: 10.4s
669:	learn: 0.0097098	total: 21s	remaining: 10.3s
670:	learn: 0.0096381	total: 21s	remaining: 10.3s
671:	learn: 0.0095666	total: 21.1s	remaining: 10.3s
672:	learn: 0.0094859	total: 21.1s	remaining: 10.2s
673:	learn: 0.0093993	total: 21.1s	remaining: 10.2s
674:	learn: 0.0093406	total: 21.2s	remaining: 10.2s
675:	learn: 0.0092757	total: 21.2s	remaining: 10.2s
676:	learn: 0.0092000	total: 21.2s	remaining: 10.1s
677:	learn: 0.0091180	total: 21.3s	remaining: 10.1s
678:	learn: 0.0090365	total: 21.3s	remaining: 10.1s
679:	learn: 0.0089571	total: 21.3s	remaining: 10s
680:	learn: 0.0088620	total: 21.3s	remaining: 10s
681:	learn: 0.0088145	total: 21.4s	remaining: 9.97s
682:	learn: 0.0087460	total: 21.4s	remaining: 9.94s
683:	learn: 0.0086990	total: 21.5s	remaining: 9.91s
684:	learn: 0.0086252	total: 21.5s	remaining: 9.88s
685:	learn: 0.0085503	total: 21.5s	remaining: 9.85s
686:	learn: 0.0085031	total: 21.6s	remaining: 9.82s
687:	learn: 0.0084226	total: 21.6s	remaining: 9.79s
688:	learn: 0.0083435	total: 21.6s	remaining: 9.76s
689:	learn: 0.0082686	total: 21.6s	remaining: 9.72s
690:	learn: 0.0081877	total: 21.7s	remaining: 9.69s
691:	learn: 0.0081236	total: 21.7s	remaining: 9.66s
692:	learn: 0.0080523	total: 21.7s	remaining: 9.63s
693:	learn: 0.0080032	total: 21.8s	remaining: 9.6s
694:	learn: 0.0079224	total: 21.8s	remaining: 9.57s
695:	learn: 0.0078708	total: 21.8s	remaining: 9.54s
696:	learn: 0.0078149	total: 21.9s	remaining: 9.5s
697:	learn: 0.0077414	total: 21.9s	remaining: 9.47s
698:	learn: 0.0077149	total: 21.9s	remaining: 9.44s
699:	learn: 0.0076294	total: 22s	remaining: 9.41s
700:	learn: 0.0075555	total: 22s	remaining: 9.38s
701:	learn: 0.0074906	total: 22s	remaining: 9.34s
702:	learn: 0.0074257	total: 22s	remaining: 9.31s
703:	learn: 0.0073708	total: 22.1s	remaining: 9.28s
704:	learn: 0.0073173	total: 22.1s	remaining: 9.25s
705:	learn: 0.0072463	total: 22.1s	remaining: 9.22s
706:	learn: 0.0071876	total: 22.2s	remaining: 9.19s
707:	learn: 0.0071361	total: 22.2s	remaining: 9.15s
708:	learn: 0.0070871	total: 22.2s	remaining: 9.12s
709:	learn: 0.0070510	total: 22.3s	remaining: 9.09s
710:	learn: 0.0069857	total: 22.3s	remaining: 9.06s
711:	learn: 0.0069290	total: 22.3s	remaining: 9.03s
712:	learn: 0.0068618	total: 22.3s	remaining: 8.99s
713:	learn: 0.0067934	total: 22.4s	remaining: 8.96s
714:	learn: 0.0067549	total: 22.4s	remaining: 8.93s
715:	learn: 0.0066895	total: 22.4s	remaining: 8.9s
716:	learn: 0.0066211	total: 22.5s	remaining: 8.87s
717:	learn: 0.0065875	total: 22.5s	remaining: 8.84s
718:	learn: 0.0065531	total: 22.5s	remaining: 8.81s
719:	learn: 0.0064898	total: 22.6s	remaining: 8.78s
720:	learn: 0.0064427	total: 22.6s	remaining: 8.74s
721:	learn: 0.0063908	total: 22.6s	remaining: 8.71s
722:	learn: 0.0063330	total: 22.7s	remaining: 8.68s
723:	learn: 0.0062842	total: 22.7s	remaining: 8.65s
724:	learn: 0.0062352	total: 22.7s	remaining: 8.62s
725:	learn: 0.0061883	total: 22.8s	remaining: 8.59s
726:	learn: 0.0061631	total: 22.8s	remaining: 8.55s
727:	learn: 0.0061089	total: 22.8s	remaining: 8.52s
728:	learn: 0.0060750	total: 22.8s	remaining: 8.49s
729:	learn: 0.0060259	total: 22.9s	remaining: 8.46s
730:	learn: 0.0059743	total: 22.9s	remaining: 8.43s
731:	learn: 0.0059123	total: 22.9s	remaining: 8.4s
732:	learn: 0.0058981	total: 23s	remaining: 8.37s
733:	learn: 0.0058370	total: 23s	remaining: 8.34s
734:	learn: 0.0057820	total: 23s	remaining: 8.31s
735:	learn: 0.0057326	total: 23.1s	remaining: 8.28s
736:	learn: 0.0056850	total: 23.1s	remaining: 8.25s
737:	learn: 0.0056316	total: 23.1s	remaining: 8.21s
738:	learn: 0.0055815	total: 23.2s	remaining: 8.18s
739:	learn: 0.0055362	total: 23.2s	remaining: 8.15s
740:	learn: 0.0054927	total: 23.2s	remaining: 8.12s
741:	learn: 0.0054581	total: 23.3s	remaining: 8.09s
742:	learn: 0.0054072	total: 23.3s	remaining: 8.05s
743:	learn: 0.0053674	total: 23.3s	remaining: 8.03s
744:	learn: 0.0053382	total: 23.4s	remaining: 8s
745:	learn: 0.0052921	total: 23.4s	remaining: 7.96s
746:	learn: 0.0052581	total: 23.4s	remaining: 7.93s
747:	learn: 0.0052332	total: 23.4s	remaining: 7.9s
748:	learn: 0.0051895	total: 23.5s	remaining: 7.87s
749:	learn: 0.0051537	total: 23.5s	remaining: 7.83s
750:	learn: 0.0051184	total: 23.5s	remaining: 7.8s
751:	learn: 0.0050780	total: 23.6s	remaining: 7.77s
752:	learn: 0.0050352	total: 23.6s	remaining: 7.74s
753:	learn: 0.0049933	total: 23.6s	remaining: 7.71s
754:	learn: 0.0049529	total: 23.7s	remaining: 7.68s
755:	learn: 0.0049386	total: 23.7s	remaining: 7.65s
756:	learn: 0.0048897	total: 23.7s	remaining: 7.62s
757:	learn: 0.0048484	total: 23.8s	remaining: 7.58s
758:	learn: 0.0048153	total: 23.8s	remaining: 7.55s
759:	learn: 0.0047802	total: 23.8s	remaining: 7.52s
760:	learn: 0.0047420	total: 23.9s	remaining: 7.49s
761:	learn: 0.0047073	total: 23.9s	remaining: 7.46s
762:	learn: 0.0046631	total: 23.9s	remaining: 7.43s
763:	learn: 0.0046188	total: 23.9s	remaining: 7.4s
764:	learn: 0.0045710	total: 24s	remaining: 7.37s
765:	learn: 0.0045312	total: 24s	remaining: 7.33s
766:	learn: 0.0044856	total: 24s	remaining: 7.3s
767:	learn: 0.0044538	total: 24.1s	remaining: 7.27s
768:	learn: 0.0044312	total: 24.1s	remaining: 7.24s
769:	learn: 0.0043907	total: 24.1s	remaining: 7.21s
770:	learn: 0.0043541	total: 24.2s	remaining: 7.18s
771:	learn: 0.0043163	total: 24.2s	remaining: 7.14s
772:	learn: 0.0042863	total: 24.2s	remaining: 7.11s
773:	learn: 0.0042476	total: 24.3s	remaining: 7.08s
774:	learn: 0.0042105	total: 24.3s	remaining: 7.05s
775:	learn: 0.0041745	total: 24.3s	remaining: 7.02s
776:	learn: 0.0041599	total: 24.4s	remaining: 6.99s
777:	learn: 0.0041204	total: 24.4s	remaining: 6.96s
778:	learn: 0.0040914	total: 24.4s	remaining: 6.93s
779:	learn: 0.0040561	total: 24.5s	remaining: 6.9s
780:	learn: 0.0040175	total: 24.5s	remaining: 6.87s
781:	learn: 0.0039924	total: 24.5s	remaining: 6.84s
782:	learn: 0.0039572	total: 24.6s	remaining: 6.8s
783:	learn: 0.0039160	total: 24.6s	remaining: 6.77s
784:	learn: 0.0038887	total: 24.6s	remaining: 6.74s
785:	learn: 0.0038637	total: 24.7s	remaining: 6.71s
786:	learn: 0.0038376	total: 24.7s	remaining: 6.68s
787:	learn: 0.0037982	total: 24.7s	remaining: 6.65s
788:	learn: 0.0037640	total: 24.8s	remaining: 6.62s
789:	learn: 0.0037270	total: 24.8s	remaining: 6.59s
790:	learn: 0.0036958	total: 24.8s	remaining: 6.56s
791:	learn: 0.0036650	total: 24.9s	remaining: 6.53s
792:	learn: 0.0036312	total: 24.9s	remaining: 6.5s
793:	learn: 0.0035959	total: 24.9s	remaining: 6.47s
794:	learn: 0.0035704	total: 25s	remaining: 6.43s
795:	learn: 0.0035352	total: 25s	remaining: 6.41s
796:	learn: 0.0035031	total: 25s	remaining: 6.38s
797:	learn: 0.0034707	total: 25.1s	remaining: 6.34s
798:	learn: 0.0034416	total: 25.1s	remaining: 6.32s
799:	learn: 0.0034291	total: 25.1s	remaining: 6.28s
800:	learn: 0.0034043	total: 25.2s	remaining: 6.25s
801:	learn: 0.0033788	total: 25.2s	remaining: 6.22s
802:	learn: 0.0033460	total: 25.2s	remaining: 6.19s
803:	learn: 0.0033215	total: 25.3s	remaining: 6.16s
804:	learn: 0.0032940	total: 25.3s	remaining: 6.13s
805:	learn: 0.0032659	total: 25.3s	remaining: 6.1s
806:	learn: 0.0032318	total: 25.4s	remaining: 6.07s
807:	learn: 0.0032041	total: 25.4s	remaining: 6.04s
808:	learn: 0.0031745	total: 25.4s	remaining: 6s
809:	learn: 0.0031439	total: 25.5s	remaining: 5.97s
810:	learn: 0.0031285	total: 25.5s	remaining: 5.94s
811:	learn: 0.0031082	total: 25.5s	remaining: 5.91s
812:	learn: 0.0030769	total: 25.6s	remaining: 5.88s
813:	learn: 0.0030490	total: 25.6s	remaining: 5.85s
814:	learn: 0.0030264	total: 25.6s	remaining: 5.82s
815:	learn: 0.0029974	total: 25.7s	remaining: 5.78s
816:	learn: 0.0029793	total: 25.7s	remaining: 5.75s
817:	learn: 0.0029491	total: 25.7s	remaining: 5.72s
818:	learn: 0.0029261	total: 25.7s	remaining: 5.69s
819:	learn: 0.0028999	total: 25.8s	remaining: 5.66s
820:	learn: 0.0028889	total: 25.8s	remaining: 5.63s
821:	learn: 0.0028608	total: 25.9s	remaining: 5.6s
822:	learn: 0.0028409	total: 25.9s	remaining: 5.57s
823:	learn: 0.0028124	total: 25.9s	remaining: 5.54s
824:	learn: 0.0027896	total: 26s	remaining: 5.5s
825:	learn: 0.0027663	total: 26s	remaining: 5.47s
826:	learn: 0.0027479	total: 26s	remaining: 5.44s
827:	learn: 0.0027321	total: 26s	remaining: 5.41s
828:	learn: 0.0027151	total: 26.1s	remaining: 5.38s
829:	learn: 0.0026942	total: 26.1s	remaining: 5.35s
830:	learn: 0.0026773	total: 26.1s	remaining: 5.32s
831:	learn: 0.0026707	total: 26.2s	remaining: 5.29s
832:	learn: 0.0026464	total: 26.2s	remaining: 5.25s
833:	learn: 0.0026280	total: 26.2s	remaining: 5.22s
834:	learn: 0.0026032	total: 26.3s	remaining: 5.19s
835:	learn: 0.0025834	total: 26.3s	remaining: 5.16s
836:	learn: 0.0025595	total: 26.3s	remaining: 5.13s
837:	learn: 0.0025346	total: 26.4s	remaining: 5.1s
838:	learn: 0.0025109	total: 26.4s	remaining: 5.07s
839:	learn: 0.0024905	total: 26.4s	remaining: 5.04s
840:	learn: 0.0024747	total: 26.5s	remaining: 5s
841:	learn: 0.0024516	total: 26.5s	remaining: 4.97s
842:	learn: 0.0024391	total: 26.5s	remaining: 4.94s
843:	learn: 0.0024200	total: 26.6s	remaining: 4.91s
844:	learn: 0.0024018	total: 26.6s	remaining: 4.88s
845:	learn: 0.0023805	total: 26.6s	remaining: 4.85s
846:	learn: 0.0023649	total: 26.7s	remaining: 4.82s
847:	learn: 0.0023472	total: 26.7s	remaining: 4.78s
848:	learn: 0.0023309	total: 26.7s	remaining: 4.75s
849:	learn: 0.0023201	total: 26.8s	remaining: 4.72s
850:	learn: 0.0023033	total: 26.8s	remaining: 4.69s
851:	learn: 0.0022818	total: 26.8s	remaining: 4.66s
852:	learn: 0.0022692	total: 26.8s	remaining: 4.63s
853:	learn: 0.0022459	total: 26.9s	remaining: 4.59s
854:	learn: 0.0022242	total: 26.9s	remaining: 4.56s
855:	learn: 0.0022064	total: 26.9s	remaining: 4.53s
856:	learn: 0.0021850	total: 27s	remaining: 4.5s
857:	learn: 0.0021689	total: 27s	remaining: 4.47s
858:	learn: 0.0021523	total: 27s	remaining: 4.44s
859:	learn: 0.0021354	total: 27.1s	remaining: 4.41s
860:	learn: 0.0021201	total: 27.1s	remaining: 4.38s
861:	learn: 0.0021097	total: 27.1s	remaining: 4.34s
862:	learn: 0.0021043	total: 27.2s	remaining: 4.31s
863:	learn: 0.0020908	total: 27.2s	remaining: 4.28s
864:	learn: 0.0020714	total: 27.2s	remaining: 4.25s
865:	learn: 0.0020560	total: 27.3s	remaining: 4.22s
866:	learn: 0.0020367	total: 27.3s	remaining: 4.19s
867:	learn: 0.0020305	total: 27.3s	remaining: 4.16s
868:	learn: 0.0020101	total: 27.4s	remaining: 4.13s
869:	learn: 0.0019965	total: 27.4s	remaining: 4.09s
870:	learn: 0.0019810	total: 27.4s	remaining: 4.06s
871:	learn: 0.0019613	total: 27.5s	remaining: 4.03s
872:	learn: 0.0019450	total: 27.5s	remaining: 4s
873:	learn: 0.0019283	total: 27.5s	remaining: 3.97s
874:	learn: 0.0019136	total: 27.6s	remaining: 3.94s
875:	learn: 0.0018961	total: 27.6s	remaining: 3.9s
876:	learn: 0.0018778	total: 27.6s	remaining: 3.87s
877:	learn: 0.0018625	total: 27.7s	remaining: 3.84s
878:	learn: 0.0018492	total: 27.7s	remaining: 3.81s
879:	learn: 0.0018332	total: 27.7s	remaining: 3.78s
880:	learn: 0.0018156	total: 27.8s	remaining: 3.75s
881:	learn: 0.0017995	total: 27.8s	remaining: 3.72s
882:	learn: 0.0017858	total: 27.8s	remaining: 3.69s
883:	learn: 0.0017685	total: 27.8s	remaining: 3.65s
884:	learn: 0.0017540	total: 27.9s	remaining: 3.62s
885:	learn: 0.0017379	total: 27.9s	remaining: 3.59s
886:	learn: 0.0017215	total: 27.9s	remaining: 3.56s
887:	learn: 0.0017131	total: 28s	remaining: 3.53s
888:	learn: 0.0017004	total: 28s	remaining: 3.5s
889:	learn: 0.0016867	total: 28s	remaining: 3.46s
890:	learn: 0.0016722	total: 28.1s	remaining: 3.43s
891:	learn: 0.0016577	total: 28.1s	remaining: 3.4s
892:	learn: 0.0016433	total: 28.1s	remaining: 3.37s
893:	learn: 0.0016258	total: 28.2s	remaining: 3.34s
894:	learn: 0.0016113	total: 28.2s	remaining: 3.31s
895:	learn: 0.0015955	total: 28.2s	remaining: 3.28s
896:	learn: 0.0015807	total: 28.3s	remaining: 3.25s
897:	learn: 0.0015670	total: 28.3s	remaining: 3.21s
898:	learn: 0.0015556	total: 28.4s	remaining: 3.19s
899:	learn: 0.0015407	total: 28.4s	remaining: 3.15s
900:	learn: 0.0015286	total: 28.4s	remaining: 3.12s
901:	learn: 0.0015154	total: 28.5s	remaining: 3.09s
902:	learn: 0.0015010	total: 28.5s	remaining: 3.06s
903:	learn: 0.0014909	total: 28.5s	remaining: 3.03s
904:	learn: 0.0014786	total: 28.5s	remaining: 3s
905:	learn: 0.0014649	total: 28.6s	remaining: 2.96s
906:	learn: 0.0014522	total: 28.6s	remaining: 2.93s
907:	learn: 0.0014376	total: 28.7s	remaining: 2.9s
908:	learn: 0.0014247	total: 28.7s	remaining: 2.87s
909:	learn: 0.0014115	total: 28.7s	remaining: 2.84s
910:	learn: 0.0014005	total: 28.8s	remaining: 2.81s
911:	learn: 0.0013885	total: 28.8s	remaining: 2.78s
912:	learn: 0.0013778	total: 28.8s	remaining: 2.75s
913:	learn: 0.0013674	total: 28.8s	remaining: 2.71s
914:	learn: 0.0013553	total: 28.9s	remaining: 2.68s
915:	learn: 0.0013418	total: 28.9s	remaining: 2.65s
916:	learn: 0.0013297	total: 28.9s	remaining: 2.62s
917:	learn: 0.0013193	total: 29s	remaining: 2.59s
918:	learn: 0.0013085	total: 29s	remaining: 2.56s
919:	learn: 0.0012969	total: 29s	remaining: 2.52s
920:	learn: 0.0012851	total: 29.1s	remaining: 2.49s
921:	learn: 0.0012805	total: 29.1s	remaining: 2.46s
922:	learn: 0.0012705	total: 29.1s	remaining: 2.43s
923:	learn: 0.0012589	total: 29.2s	remaining: 2.4s
924:	learn: 0.0012493	total: 29.2s	remaining: 2.37s
925:	learn: 0.0012422	total: 29.2s	remaining: 2.34s
926:	learn: 0.0012316	total: 29.3s	remaining: 2.31s
927:	learn: 0.0012226	total: 29.3s	remaining: 2.27s
928:	learn: 0.0012148	total: 29.3s	remaining: 2.24s
929:	learn: 0.0012043	total: 29.4s	remaining: 2.21s
930:	learn: 0.0011957	total: 29.4s	remaining: 2.18s
931:	learn: 0.0011868	total: 29.4s	remaining: 2.15s
932:	learn: 0.0011784	total: 29.5s	remaining: 2.12s
933:	learn: 0.0011677	total: 29.5s	remaining: 2.08s
934:	learn: 0.0011579	total: 29.5s	remaining: 2.05s
935:	learn: 0.0011492	total: 29.6s	remaining: 2.02s
936:	learn: 0.0011429	total: 29.6s	remaining: 1.99s
937:	learn: 0.0011325	total: 29.6s	remaining: 1.96s
938:	learn: 0.0011207	total: 29.7s	remaining: 1.93s
939:	learn: 0.0011108	total: 29.7s	remaining: 1.9s
940:	learn: 0.0011019	total: 29.7s	remaining: 1.86s
941:	learn: 0.0010929	total: 29.8s	remaining: 1.83s
942:	learn: 0.0010845	total: 29.8s	remaining: 1.8s
943:	learn: 0.0010787	total: 29.8s	remaining: 1.77s
944:	learn: 0.0010707	total: 29.8s	remaining: 1.74s
945:	learn: 0.0010613	total: 29.9s	remaining: 1.71s
946:	learn: 0.0010538	total: 29.9s	remaining: 1.67s
947:	learn: 0.0010457	total: 29.9s	remaining: 1.64s
948:	learn: 0.0010370	total: 30s	remaining: 1.61s
949:	learn: 0.0010277	total: 30s	remaining: 1.58s
950:	learn: 0.0010208	total: 30s	remaining: 1.55s
951:	learn: 0.0010111	total: 30.1s	remaining: 1.52s
952:	learn: 0.0010021	total: 30.1s	remaining: 1.48s
953:	learn: 0.0009953	total: 30.1s	remaining: 1.45s
954:	learn: 0.0009870	total: 30.2s	remaining: 1.42s
955:	learn: 0.0009782	total: 30.2s	remaining: 1.39s
956:	learn: 0.0009703	total: 30.2s	remaining: 1.36s
957:	learn: 0.0009633	total: 30.3s	remaining: 1.33s
958:	learn: 0.0009552	total: 30.3s	remaining: 1.29s
959:	learn: 0.0009452	total: 30.3s	remaining: 1.26s
960:	learn: 0.0009375	total: 30.3s	remaining: 1.23s
961:	learn: 0.0009283	total: 30.4s	remaining: 1.2s
962:	learn: 0.0009205	total: 30.4s	remaining: 1.17s
963:	learn: 0.0009110	total: 30.4s	remaining: 1.14s
964:	learn: 0.0009054	total: 30.5s	remaining: 1.1s
965:	learn: 0.0008986	total: 30.5s	remaining: 1.07s
966:	learn: 0.0008925	total: 30.5s	remaining: 1.04s
967:	learn: 0.0008860	total: 30.6s	remaining: 1.01s
968:	learn: 0.0008768	total: 30.6s	remaining: 979ms
969:	learn: 0.0008683	total: 30.6s	remaining: 947ms
970:	learn: 0.0008591	total: 30.7s	remaining: 915ms
971:	learn: 0.0008538	total: 30.7s	remaining: 884ms
972:	learn: 0.0008510	total: 30.7s	remaining: 852ms
973:	learn: 0.0008434	total: 30.7s	remaining: 821ms
974:	learn: 0.0008375	total: 30.8s	remaining: 789ms
975:	learn: 0.0008297	total: 30.8s	remaining: 757ms
976:	learn: 0.0008242	total: 30.8s	remaining: 726ms
977:	learn: 0.0008170	total: 30.9s	remaining: 694ms
978:	learn: 0.0008090	total: 30.9s	remaining: 663ms
979:	learn: 0.0008039	total: 30.9s	remaining: 631ms
980:	learn: 0.0007987	total: 31s	remaining: 600ms
981:	learn: 0.0007905	total: 31s	remaining: 568ms
982:	learn: 0.0007824	total: 31s	remaining: 536ms
983:	learn: 0.0007767	total: 31.1s	remaining: 505ms
984:	learn: 0.0007697	total: 31.1s	remaining: 473ms
985:	learn: 0.0007642	total: 31.1s	remaining: 442ms
986:	learn: 0.0007582	total: 31.2s	remaining: 410ms
987:	learn: 0.0007520	total: 31.2s	remaining: 379ms
988:	learn: 0.0007446	total: 31.2s	remaining: 347ms
989:	learn: 0.0007384	total: 31.3s	remaining: 316ms
990:	learn: 0.0007343	total: 31.3s	remaining: 284ms
991:	learn: 0.0007279	total: 31.3s	remaining: 253ms
992:	learn: 0.0007221	total: 31.4s	remaining: 221ms
993:	learn: 0.0007156	total: 31.4s	remaining: 189ms
994:	learn: 0.0007099	total: 31.4s	remaining: 158ms
995:	learn: 0.0007043	total: 31.4s	remaining: 126ms
996:	learn: 0.0006989	total: 31.5s	remaining: 94.7ms
997:	learn: 0.0006923	total: 31.5s	remaining: 63.2ms
998:	learn: 0.0006869	total: 31.5s	remaining: 31.6ms
999:	learn: 0.0006816	total: 31.6s	remaining: 0us
Learning rate set to 0.030829
0:	learn: 0.8392865	total: 45ms	remaining: 44.9s
1:	learn: 0.8362034	total: 78.8ms	remaining: 39.3s
2:	learn: 0.8297772	total: 111ms	remaining: 36.9s
3:	learn: 0.8258956	total: 145ms	remaining: 36.2s
4:	learn: 0.8224905	total: 180ms	remaining: 35.9s
5:	learn: 0.8197899	total: 214ms	remaining: 35.4s
6:	learn: 0.8150927	total: 243ms	remaining: 34.5s
7:	learn: 0.8096767	total: 273ms	remaining: 33.9s
8:	learn: 0.8056548	total: 305ms	remaining: 33.6s
9:	learn: 0.8042272	total: 334ms	remaining: 33s
10:	learn: 0.8002744	total: 365ms	remaining: 32.8s
11:	learn: 0.7965510	total: 395ms	remaining: 32.6s
12:	learn: 0.7925155	total: 428ms	remaining: 32.5s
13:	learn: 0.7904637	total: 461ms	remaining: 32.4s
14:	learn: 0.7858093	total: 495ms	remaining: 32.5s
15:	learn: 0.7824230	total: 530ms	remaining: 32.6s
16:	learn: 0.7782514	total: 559ms	remaining: 32.4s
17:	learn: 0.7739112	total: 588ms	remaining: 32.1s
18:	learn: 0.7705486	total: 617ms	remaining: 31.8s
19:	learn: 0.7670700	total: 646ms	remaining: 31.6s
20:	learn: 0.7634371	total: 675ms	remaining: 31.5s
21:	learn: 0.7579273	total: 704ms	remaining: 31.3s
22:	learn: 0.7543832	total: 733ms	remaining: 31.1s
23:	learn: 0.7515166	total: 763ms	remaining: 31s
24:	learn: 0.7468706	total: 791ms	remaining: 30.9s
25:	learn: 0.7414616	total: 822ms	remaining: 30.8s
26:	learn: 0.7394213	total: 853ms	remaining: 30.7s
27:	learn: 0.7365984	total: 883ms	remaining: 30.7s
28:	learn: 0.7324628	total: 912ms	remaining: 30.5s
29:	learn: 0.7297789	total: 940ms	remaining: 30.4s
30:	learn: 0.7269697	total: 970ms	remaining: 30.3s
31:	learn: 0.7264343	total: 994ms	remaining: 30.1s
32:	learn: 0.7233797	total: 1.02s	remaining: 30s
33:	learn: 0.7191542	total: 1.05s	remaining: 29.9s
34:	learn: 0.7156238	total: 1.08s	remaining: 29.8s
35:	learn: 0.7134712	total: 1.11s	remaining: 29.7s
36:	learn: 0.7097028	total: 1.14s	remaining: 29.6s
37:	learn: 0.7071675	total: 1.17s	remaining: 29.5s
38:	learn: 0.7059797	total: 1.2s	remaining: 29.5s
39:	learn: 0.7025398	total: 1.23s	remaining: 29.5s
40:	learn: 0.7003725	total: 1.26s	remaining: 29.4s
41:	learn: 0.6973396	total: 1.28s	remaining: 29.3s
42:	learn: 0.6945657	total: 1.31s	remaining: 29.2s
43:	learn: 0.6919753	total: 1.34s	remaining: 29.2s
44:	learn: 0.6900587	total: 1.37s	remaining: 29.1s
45:	learn: 0.6870298	total: 1.4s	remaining: 29s
46:	learn: 0.6813887	total: 1.43s	remaining: 29s
47:	learn: 0.6759796	total: 1.46s	remaining: 29s
48:	learn: 0.6726135	total: 1.49s	remaining: 28.9s
49:	learn: 0.6690806	total: 1.52s	remaining: 29s
50:	learn: 0.6659051	total: 1.55s	remaining: 28.9s
51:	learn: 0.6635834	total: 1.58s	remaining: 28.9s
52:	learn: 0.6600191	total: 1.61s	remaining: 28.8s
53:	learn: 0.6579784	total: 1.64s	remaining: 28.7s
54:	learn: 0.6552344	total: 1.67s	remaining: 28.7s
55:	learn: 0.6515462	total: 1.7s	remaining: 28.6s
56:	learn: 0.6484923	total: 1.73s	remaining: 28.6s
57:	learn: 0.6472331	total: 1.76s	remaining: 28.6s
58:	learn: 0.6452255	total: 1.79s	remaining: 28.5s
59:	learn: 0.6409207	total: 1.83s	remaining: 28.7s
60:	learn: 0.6379186	total: 1.86s	remaining: 28.6s
61:	learn: 0.6344702	total: 1.89s	remaining: 28.5s
62:	learn: 0.6305014	total: 1.92s	remaining: 28.5s
63:	learn: 0.6280713	total: 1.95s	remaining: 28.4s
64:	learn: 0.6262583	total: 1.97s	remaining: 28.4s
65:	learn: 0.6245070	total: 2s	remaining: 28.3s
66:	learn: 0.6210210	total: 2.03s	remaining: 28.3s
67:	learn: 0.6183980	total: 2.07s	remaining: 28.4s
68:	learn: 0.6135705	total: 2.1s	remaining: 28.3s
69:	learn: 0.6107695	total: 2.13s	remaining: 28.3s
70:	learn: 0.6076822	total: 2.16s	remaining: 28.3s
71:	learn: 0.6043597	total: 2.19s	remaining: 28.2s
72:	learn: 0.6018144	total: 2.22s	remaining: 28.2s
73:	learn: 0.5985812	total: 2.25s	remaining: 28.2s
74:	learn: 0.5961717	total: 2.28s	remaining: 28.1s
75:	learn: 0.5932641	total: 2.3s	remaining: 28s
76:	learn: 0.5896423	total: 2.33s	remaining: 28s
77:	learn: 0.5868851	total: 2.36s	remaining: 27.9s
78:	learn: 0.5838435	total: 2.39s	remaining: 27.9s
79:	learn: 0.5811191	total: 2.42s	remaining: 27.8s
80:	learn: 0.5771858	total: 2.45s	remaining: 27.8s
81:	learn: 0.5734843	total: 2.48s	remaining: 27.8s
82:	learn: 0.5710079	total: 2.51s	remaining: 27.7s
83:	learn: 0.5683016	total: 2.54s	remaining: 27.7s
84:	learn: 0.5648864	total: 2.56s	remaining: 27.6s
85:	learn: 0.5606276	total: 2.6s	remaining: 27.6s
86:	learn: 0.5572835	total: 2.62s	remaining: 27.5s
87:	learn: 0.5548315	total: 2.65s	remaining: 27.5s
88:	learn: 0.5506534	total: 2.68s	remaining: 27.4s
89:	learn: 0.5484806	total: 2.71s	remaining: 27.4s
90:	learn: 0.5460359	total: 2.75s	remaining: 27.4s
91:	learn: 0.5432579	total: 2.77s	remaining: 27.4s
92:	learn: 0.5406692	total: 2.8s	remaining: 27.3s
93:	learn: 0.5367887	total: 2.83s	remaining: 27.3s
94:	learn: 0.5332503	total: 2.86s	remaining: 27.2s
95:	learn: 0.5316980	total: 2.89s	remaining: 27.2s
96:	learn: 0.5279087	total: 2.92s	remaining: 27.2s
97:	learn: 0.5255435	total: 2.95s	remaining: 27.2s
98:	learn: 0.5226250	total: 2.98s	remaining: 27.1s
99:	learn: 0.5216441	total: 3.01s	remaining: 27.1s
100:	learn: 0.5196983	total: 3.04s	remaining: 27.1s
101:	learn: 0.5170333	total: 3.07s	remaining: 27.1s
102:	learn: 0.5144263	total: 3.1s	remaining: 27s
103:	learn: 0.5118066	total: 3.13s	remaining: 27s
104:	learn: 0.5082156	total: 3.16s	remaining: 27s
105:	learn: 0.5057562	total: 3.19s	remaining: 26.9s
106:	learn: 0.5040740	total: 3.22s	remaining: 26.9s
107:	learn: 0.5027795	total: 3.25s	remaining: 26.8s
108:	learn: 0.5013707	total: 3.28s	remaining: 26.8s
109:	learn: 0.4992815	total: 3.32s	remaining: 26.8s
110:	learn: 0.4969448	total: 3.35s	remaining: 26.8s
111:	learn: 0.4944815	total: 3.38s	remaining: 26.8s
112:	learn: 0.4913262	total: 3.42s	remaining: 26.8s
113:	learn: 0.4894544	total: 3.44s	remaining: 26.8s
114:	learn: 0.4880628	total: 3.47s	remaining: 26.7s
115:	learn: 0.4854671	total: 3.5s	remaining: 26.7s
116:	learn: 0.4828275	total: 3.53s	remaining: 26.6s
117:	learn: 0.4799369	total: 3.56s	remaining: 26.6s
118:	learn: 0.4773963	total: 3.59s	remaining: 26.6s
119:	learn: 0.4746758	total: 3.63s	remaining: 26.6s
120:	learn: 0.4721825	total: 3.65s	remaining: 26.6s
121:	learn: 0.4697312	total: 3.68s	remaining: 26.5s
122:	learn: 0.4671843	total: 3.71s	remaining: 26.5s
123:	learn: 0.4642476	total: 3.74s	remaining: 26.4s
124:	learn: 0.4631611	total: 3.77s	remaining: 26.4s
125:	learn: 0.4609785	total: 3.8s	remaining: 26.3s
126:	learn: 0.4582765	total: 3.82s	remaining: 26.3s
127:	learn: 0.4565090	total: 3.85s	remaining: 26.2s
128:	learn: 0.4536309	total: 3.88s	remaining: 26.2s
129:	learn: 0.4521391	total: 3.92s	remaining: 26.2s
130:	learn: 0.4489919	total: 3.95s	remaining: 26.2s
131:	learn: 0.4469720	total: 3.98s	remaining: 26.2s
132:	learn: 0.4447353	total: 4.02s	remaining: 26.2s
133:	learn: 0.4433819	total: 4.05s	remaining: 26.2s
134:	learn: 0.4419060	total: 4.08s	remaining: 26.1s
135:	learn: 0.4405801	total: 4.11s	remaining: 26.1s
136:	learn: 0.4384826	total: 4.13s	remaining: 26s
137:	learn: 0.4353776	total: 4.16s	remaining: 26s
138:	learn: 0.4329163	total: 4.21s	remaining: 26.1s
139:	learn: 0.4310488	total: 4.24s	remaining: 26.1s
140:	learn: 0.4285313	total: 4.27s	remaining: 26s
141:	learn: 0.4257686	total: 4.3s	remaining: 26s
142:	learn: 0.4234478	total: 4.33s	remaining: 26s
143:	learn: 0.4209417	total: 4.36s	remaining: 25.9s
144:	learn: 0.4188523	total: 4.39s	remaining: 25.9s
145:	learn: 0.4159120	total: 4.42s	remaining: 25.9s
146:	learn: 0.4137696	total: 4.45s	remaining: 25.8s
147:	learn: 0.4110072	total: 4.48s	remaining: 25.8s
148:	learn: 0.4090318	total: 4.51s	remaining: 25.8s
149:	learn: 0.4074227	total: 4.54s	remaining: 25.7s
150:	learn: 0.4049607	total: 4.57s	remaining: 25.7s
151:	learn: 0.4016686	total: 4.6s	remaining: 25.7s
152:	learn: 0.4000504	total: 4.63s	remaining: 25.6s
153:	learn: 0.3973705	total: 4.66s	remaining: 25.6s
154:	learn: 0.3945265	total: 4.69s	remaining: 25.6s
155:	learn: 0.3921516	total: 4.72s	remaining: 25.5s
156:	learn: 0.3903277	total: 4.75s	remaining: 25.5s
157:	learn: 0.3868978	total: 4.78s	remaining: 25.5s
158:	learn: 0.3848740	total: 4.82s	remaining: 25.5s
159:	learn: 0.3816680	total: 4.85s	remaining: 25.4s
160:	learn: 0.3796439	total: 4.87s	remaining: 25.4s
161:	learn: 0.3769746	total: 4.9s	remaining: 25.4s
162:	learn: 0.3751506	total: 4.94s	remaining: 25.4s
163:	learn: 0.3725344	total: 4.96s	remaining: 25.3s
164:	learn: 0.3701402	total: 4.99s	remaining: 25.3s
165:	learn: 0.3678977	total: 5.02s	remaining: 25.2s
166:	learn: 0.3660413	total: 5.05s	remaining: 25.2s
167:	learn: 0.3630268	total: 5.08s	remaining: 25.1s
168:	learn: 0.3599491	total: 5.11s	remaining: 25.1s
169:	learn: 0.3579815	total: 5.15s	remaining: 25.1s
170:	learn: 0.3557993	total: 5.18s	remaining: 25.1s
171:	learn: 0.3536061	total: 5.21s	remaining: 25.1s
172:	learn: 0.3517822	total: 5.24s	remaining: 25s
173:	learn: 0.3509555	total: 5.26s	remaining: 25s
174:	learn: 0.3480888	total: 5.29s	remaining: 25s
175:	learn: 0.3452866	total: 5.32s	remaining: 24.9s
176:	learn: 0.3436073	total: 5.35s	remaining: 24.9s
177:	learn: 0.3406856	total: 5.38s	remaining: 24.8s
178:	learn: 0.3385143	total: 5.4s	remaining: 24.8s
179:	learn: 0.3369936	total: 5.43s	remaining: 24.8s
180:	learn: 0.3348521	total: 5.47s	remaining: 24.7s
181:	learn: 0.3322927	total: 5.49s	remaining: 24.7s
182:	learn: 0.3302678	total: 5.52s	remaining: 24.6s
183:	learn: 0.3287842	total: 5.55s	remaining: 24.6s
184:	learn: 0.3267703	total: 5.58s	remaining: 24.6s
185:	learn: 0.3255993	total: 5.6s	remaining: 24.5s
186:	learn: 0.3230106	total: 5.63s	remaining: 24.5s
187:	learn: 0.3217009	total: 5.66s	remaining: 24.4s
188:	learn: 0.3190375	total: 5.68s	remaining: 24.4s
189:	learn: 0.3168755	total: 5.71s	remaining: 24.4s
190:	learn: 0.3147692	total: 5.74s	remaining: 24.3s
191:	learn: 0.3137031	total: 5.78s	remaining: 24.3s
192:	learn: 0.3114385	total: 5.81s	remaining: 24.3s
193:	learn: 0.3090481	total: 5.84s	remaining: 24.3s
194:	learn: 0.3062541	total: 5.88s	remaining: 24.3s
195:	learn: 0.3036585	total: 5.9s	remaining: 24.2s
196:	learn: 0.3006316	total: 5.94s	remaining: 24.2s
197:	learn: 0.2987674	total: 5.97s	remaining: 24.2s
198:	learn: 0.2965805	total: 6s	remaining: 24.1s
199:	learn: 0.2942106	total: 6.03s	remaining: 24.1s
200:	learn: 0.2918720	total: 6.06s	remaining: 24.1s
201:	learn: 0.2892284	total: 6.1s	remaining: 24.1s
202:	learn: 0.2863113	total: 6.13s	remaining: 24.1s
203:	learn: 0.2839087	total: 6.15s	remaining: 24s
204:	learn: 0.2825533	total: 6.19s	remaining: 24s
205:	learn: 0.2805734	total: 6.22s	remaining: 24s
206:	learn: 0.2784906	total: 6.25s	remaining: 23.9s
207:	learn: 0.2759233	total: 6.28s	remaining: 23.9s
208:	learn: 0.2737453	total: 6.31s	remaining: 23.9s
209:	learn: 0.2715415	total: 6.34s	remaining: 23.9s
210:	learn: 0.2691389	total: 6.37s	remaining: 23.8s
211:	learn: 0.2669958	total: 6.41s	remaining: 23.8s
212:	learn: 0.2650700	total: 6.43s	remaining: 23.8s
213:	learn: 0.2636578	total: 6.46s	remaining: 23.7s
214:	learn: 0.2617389	total: 6.49s	remaining: 23.7s
215:	learn: 0.2590581	total: 6.52s	remaining: 23.7s
216:	learn: 0.2572948	total: 6.55s	remaining: 23.6s
217:	learn: 0.2560064	total: 6.58s	remaining: 23.6s
218:	learn: 0.2533002	total: 6.61s	remaining: 23.6s
219:	learn: 0.2512331	total: 6.63s	remaining: 23.5s
220:	learn: 0.2492811	total: 6.67s	remaining: 23.5s
221:	learn: 0.2471929	total: 6.7s	remaining: 23.5s
222:	learn: 0.2451209	total: 6.72s	remaining: 23.4s
223:	learn: 0.2437879	total: 6.76s	remaining: 23.4s
224:	learn: 0.2412162	total: 6.79s	remaining: 23.4s
225:	learn: 0.2392645	total: 6.82s	remaining: 23.3s
226:	learn: 0.2368722	total: 6.85s	remaining: 23.3s
227:	learn: 0.2351573	total: 6.88s	remaining: 23.3s
228:	learn: 0.2333569	total: 6.9s	remaining: 23.2s
229:	learn: 0.2313078	total: 6.93s	remaining: 23.2s
230:	learn: 0.2289253	total: 6.96s	remaining: 23.2s
231:	learn: 0.2272718	total: 6.99s	remaining: 23.2s
232:	learn: 0.2244456	total: 7.02s	remaining: 23.1s
233:	learn: 0.2223263	total: 7.04s	remaining: 23.1s
234:	learn: 0.2200962	total: 7.07s	remaining: 23s
235:	learn: 0.2178164	total: 7.09s	remaining: 23s
236:	learn: 0.2156254	total: 7.12s	remaining: 22.9s
237:	learn: 0.2138174	total: 7.15s	remaining: 22.9s
238:	learn: 0.2116885	total: 7.19s	remaining: 22.9s
239:	learn: 0.2097028	total: 7.21s	remaining: 22.8s
240:	learn: 0.2076110	total: 7.24s	remaining: 22.8s
241:	learn: 0.2060081	total: 7.27s	remaining: 22.8s
242:	learn: 0.2038907	total: 7.3s	remaining: 22.7s
243:	learn: 0.2018120	total: 7.32s	remaining: 22.7s
244:	learn: 0.2001681	total: 7.35s	remaining: 22.7s
245:	learn: 0.1987083	total: 7.38s	remaining: 22.6s
246:	learn: 0.1972301	total: 7.41s	remaining: 22.6s
247:	learn: 0.1959150	total: 7.44s	remaining: 22.6s
248:	learn: 0.1936025	total: 7.47s	remaining: 22.5s
249:	learn: 0.1918996	total: 7.5s	remaining: 22.5s
250:	learn: 0.1898456	total: 7.53s	remaining: 22.5s
251:	learn: 0.1884608	total: 7.56s	remaining: 22.4s
252:	learn: 0.1871344	total: 7.59s	remaining: 22.4s
253:	learn: 0.1851865	total: 7.62s	remaining: 22.4s
254:	learn: 0.1834564	total: 7.65s	remaining: 22.4s
255:	learn: 0.1818111	total: 7.68s	remaining: 22.3s
256:	learn: 0.1801733	total: 7.71s	remaining: 22.3s
257:	learn: 0.1789470	total: 7.74s	remaining: 22.3s
258:	learn: 0.1771330	total: 7.77s	remaining: 22.2s
259:	learn: 0.1754141	total: 7.8s	remaining: 22.2s
260:	learn: 0.1737894	total: 7.83s	remaining: 22.2s
261:	learn: 0.1717258	total: 7.86s	remaining: 22.1s
262:	learn: 0.1701978	total: 7.89s	remaining: 22.1s
263:	learn: 0.1690613	total: 7.92s	remaining: 22.1s
264:	learn: 0.1678616	total: 7.95s	remaining: 22s
265:	learn: 0.1663871	total: 7.97s	remaining: 22s
266:	learn: 0.1647411	total: 8s	remaining: 22s
267:	learn: 0.1630424	total: 8.03s	remaining: 21.9s
268:	learn: 0.1614820	total: 8.07s	remaining: 21.9s
269:	learn: 0.1598535	total: 8.1s	remaining: 21.9s
270:	learn: 0.1586717	total: 8.12s	remaining: 21.9s
271:	learn: 0.1570750	total: 8.15s	remaining: 21.8s
272:	learn: 0.1555656	total: 8.19s	remaining: 21.8s
273:	learn: 0.1541450	total: 8.21s	remaining: 21.8s
274:	learn: 0.1531132	total: 8.24s	remaining: 21.7s
275:	learn: 0.1516153	total: 8.29s	remaining: 21.7s
276:	learn: 0.1503845	total: 8.31s	remaining: 21.7s
277:	learn: 0.1491557	total: 8.34s	remaining: 21.7s
278:	learn: 0.1481662	total: 8.38s	remaining: 21.6s
279:	learn: 0.1467510	total: 8.4s	remaining: 21.6s
280:	learn: 0.1453617	total: 8.43s	remaining: 21.6s
281:	learn: 0.1439993	total: 8.46s	remaining: 21.5s
282:	learn: 0.1425689	total: 8.49s	remaining: 21.5s
283:	learn: 0.1411506	total: 8.52s	remaining: 21.5s
284:	learn: 0.1398212	total: 8.55s	remaining: 21.5s
285:	learn: 0.1383407	total: 8.58s	remaining: 21.4s
286:	learn: 0.1368852	total: 8.61s	remaining: 21.4s
287:	learn: 0.1353929	total: 8.64s	remaining: 21.4s
288:	learn: 0.1338930	total: 8.67s	remaining: 21.3s
289:	learn: 0.1327011	total: 8.7s	remaining: 21.3s
290:	learn: 0.1314579	total: 8.73s	remaining: 21.3s
291:	learn: 0.1301942	total: 8.76s	remaining: 21.2s
292:	learn: 0.1296381	total: 8.79s	remaining: 21.2s
293:	learn: 0.1282601	total: 8.82s	remaining: 21.2s
294:	learn: 0.1267624	total: 8.84s	remaining: 21.1s
295:	learn: 0.1252625	total: 8.87s	remaining: 21.1s
296:	learn: 0.1238693	total: 8.9s	remaining: 21.1s
297:	learn: 0.1224864	total: 8.93s	remaining: 21s
298:	learn: 0.1216518	total: 8.96s	remaining: 21s
299:	learn: 0.1205866	total: 8.99s	remaining: 21s
300:	learn: 0.1192784	total: 9.02s	remaining: 20.9s
301:	learn: 0.1179936	total: 9.05s	remaining: 20.9s
302:	learn: 0.1169602	total: 9.08s	remaining: 20.9s
303:	learn: 0.1157804	total: 9.11s	remaining: 20.9s
304:	learn: 0.1146542	total: 9.14s	remaining: 20.8s
305:	learn: 0.1134225	total: 9.17s	remaining: 20.8s
306:	learn: 0.1121500	total: 9.2s	remaining: 20.8s
307:	learn: 0.1109667	total: 9.23s	remaining: 20.7s
308:	learn: 0.1102484	total: 9.26s	remaining: 20.7s
309:	learn: 0.1091256	total: 9.29s	remaining: 20.7s
310:	learn: 0.1080877	total: 9.32s	remaining: 20.6s
311:	learn: 0.1068583	total: 9.35s	remaining: 20.6s
312:	learn: 0.1061319	total: 9.38s	remaining: 20.6s
313:	learn: 0.1049432	total: 9.41s	remaining: 20.6s
314:	learn: 0.1038397	total: 9.44s	remaining: 20.5s
315:	learn: 0.1028406	total: 9.46s	remaining: 20.5s
316:	learn: 0.1018465	total: 9.49s	remaining: 20.5s
317:	learn: 0.1006714	total: 9.52s	remaining: 20.4s
318:	learn: 0.0996257	total: 9.55s	remaining: 20.4s
319:	learn: 0.0987020	total: 9.58s	remaining: 20.4s
320:	learn: 0.0977438	total: 9.61s	remaining: 20.3s
321:	learn: 0.0973038	total: 9.63s	remaining: 20.3s
322:	learn: 0.0962898	total: 9.66s	remaining: 20.3s
323:	learn: 0.0954214	total: 9.71s	remaining: 20.3s
324:	learn: 0.0944954	total: 9.75s	remaining: 20.2s
325:	learn: 0.0937382	total: 9.78s	remaining: 20.2s
326:	learn: 0.0928443	total: 9.81s	remaining: 20.2s
327:	learn: 0.0919772	total: 9.84s	remaining: 20.2s
328:	learn: 0.0914663	total: 9.88s	remaining: 20.1s
329:	learn: 0.0905103	total: 9.91s	remaining: 20.1s
330:	learn: 0.0896332	total: 9.94s	remaining: 20.1s
331:	learn: 0.0890347	total: 9.97s	remaining: 20.1s
332:	learn: 0.0881536	total: 10s	remaining: 20s
333:	learn: 0.0872537	total: 10s	remaining: 20s
334:	learn: 0.0865539	total: 10.1s	remaining: 20s
335:	learn: 0.0856368	total: 10.1s	remaining: 19.9s
336:	learn: 0.0849269	total: 10.1s	remaining: 19.9s
337:	learn: 0.0840998	total: 10.1s	remaining: 19.9s
338:	learn: 0.0832733	total: 10.2s	remaining: 19.8s
339:	learn: 0.0827626	total: 10.2s	remaining: 19.8s
340:	learn: 0.0820015	total: 10.2s	remaining: 19.8s
341:	learn: 0.0811537	total: 10.3s	remaining: 19.8s
342:	learn: 0.0806428	total: 10.3s	remaining: 19.7s
343:	learn: 0.0797667	total: 10.3s	remaining: 19.7s
344:	learn: 0.0789833	total: 10.4s	remaining: 19.7s
345:	learn: 0.0781631	total: 10.4s	remaining: 19.6s
346:	learn: 0.0776760	total: 10.4s	remaining: 19.6s
347:	learn: 0.0769335	total: 10.4s	remaining: 19.6s
348:	learn: 0.0761639	total: 10.5s	remaining: 19.5s
349:	learn: 0.0753324	total: 10.5s	remaining: 19.5s
350:	learn: 0.0747828	total: 10.5s	remaining: 19.5s
351:	learn: 0.0741933	total: 10.6s	remaining: 19.4s
352:	learn: 0.0734398	total: 10.6s	remaining: 19.4s
353:	learn: 0.0728127	total: 10.6s	remaining: 19.4s
354:	learn: 0.0724342	total: 10.6s	remaining: 19.3s
355:	learn: 0.0718352	total: 10.7s	remaining: 19.3s
356:	learn: 0.0711572	total: 10.7s	remaining: 19.3s
357:	learn: 0.0705682	total: 10.7s	remaining: 19.3s
358:	learn: 0.0700396	total: 10.8s	remaining: 19.2s
359:	learn: 0.0692997	total: 10.8s	remaining: 19.2s
360:	learn: 0.0689430	total: 10.8s	remaining: 19.2s
361:	learn: 0.0682186	total: 10.9s	remaining: 19.1s
362:	learn: 0.0675369	total: 10.9s	remaining: 19.1s
363:	learn: 0.0668439	total: 10.9s	remaining: 19.1s
364:	learn: 0.0661323	total: 10.9s	remaining: 19s
365:	learn: 0.0655195	total: 11s	remaining: 19s
366:	learn: 0.0648455	total: 11s	remaining: 19s
367:	learn: 0.0644201	total: 11.1s	remaining: 19s
368:	learn: 0.0639425	total: 11.1s	remaining: 18.9s
369:	learn: 0.0632587	total: 11.1s	remaining: 18.9s
370:	learn: 0.0628806	total: 11.1s	remaining: 18.9s
371:	learn: 0.0624969	total: 11.2s	remaining: 18.9s
372:	learn: 0.0618848	total: 11.2s	remaining: 18.8s
373:	learn: 0.0613361	total: 11.2s	remaining: 18.8s
374:	learn: 0.0609794	total: 11.3s	remaining: 18.8s
375:	learn: 0.0603481	total: 11.3s	remaining: 18.7s
376:	learn: 0.0598064	total: 11.3s	remaining: 18.7s
377:	learn: 0.0592150	total: 11.3s	remaining: 18.7s
378:	learn: 0.0589301	total: 11.4s	remaining: 18.6s
379:	learn: 0.0584677	total: 11.4s	remaining: 18.6s
380:	learn: 0.0580578	total: 11.4s	remaining: 18.6s
381:	learn: 0.0577452	total: 11.5s	remaining: 18.5s
382:	learn: 0.0574204	total: 11.5s	remaining: 18.5s
383:	learn: 0.0568430	total: 11.5s	remaining: 18.5s
384:	learn: 0.0565535	total: 11.5s	remaining: 18.4s
385:	learn: 0.0561159	total: 11.6s	remaining: 18.4s
386:	learn: 0.0557954	total: 11.6s	remaining: 18.4s
387:	learn: 0.0552321	total: 11.6s	remaining: 18.4s
388:	learn: 0.0547645	total: 11.7s	remaining: 18.3s
389:	learn: 0.0541637	total: 11.7s	remaining: 18.3s
390:	learn: 0.0537682	total: 11.7s	remaining: 18.3s
391:	learn: 0.0532105	total: 11.8s	remaining: 18.2s
392:	learn: 0.0526166	total: 11.8s	remaining: 18.2s
393:	learn: 0.0522591	total: 11.8s	remaining: 18.2s
394:	learn: 0.0517024	total: 11.9s	remaining: 18.2s
395:	learn: 0.0514255	total: 11.9s	remaining: 18.1s
396:	learn: 0.0510936	total: 11.9s	remaining: 18.1s
397:	learn: 0.0505815	total: 11.9s	remaining: 18.1s
398:	learn: 0.0500560	total: 12s	remaining: 18s
399:	learn: 0.0496206	total: 12s	remaining: 18s
400:	learn: 0.0491204	total: 12s	remaining: 18s
401:	learn: 0.0486405	total: 12.1s	remaining: 17.9s
402:	learn: 0.0481890	total: 12.1s	remaining: 17.9s
403:	learn: 0.0477836	total: 12.1s	remaining: 17.9s
404:	learn: 0.0475136	total: 12.2s	remaining: 17.9s
405:	learn: 0.0470410	total: 12.2s	remaining: 17.8s
406:	learn: 0.0467054	total: 12.2s	remaining: 17.8s
407:	learn: 0.0462850	total: 12.3s	remaining: 17.8s
408:	learn: 0.0460506	total: 12.3s	remaining: 17.7s
409:	learn: 0.0456847	total: 12.3s	remaining: 17.7s
410:	learn: 0.0452681	total: 12.3s	remaining: 17.7s
411:	learn: 0.0447983	total: 12.4s	remaining: 17.7s
412:	learn: 0.0443804	total: 12.4s	remaining: 17.6s
413:	learn: 0.0439570	total: 12.4s	remaining: 17.6s
414:	learn: 0.0437286	total: 12.5s	remaining: 17.6s
415:	learn: 0.0434446	total: 12.5s	remaining: 17.5s
416:	learn: 0.0429518	total: 12.5s	remaining: 17.5s
417:	learn: 0.0425332	total: 12.5s	remaining: 17.5s
418:	learn: 0.0420704	total: 12.6s	remaining: 17.4s
419:	learn: 0.0418091	total: 12.6s	remaining: 17.4s
420:	learn: 0.0413637	total: 12.6s	remaining: 17.4s
421:	learn: 0.0409826	total: 12.7s	remaining: 17.3s
422:	learn: 0.0405573	total: 12.7s	remaining: 17.3s
423:	learn: 0.0402215	total: 12.7s	remaining: 17.3s
424:	learn: 0.0399869	total: 12.7s	remaining: 17.2s
425:	learn: 0.0396646	total: 12.8s	remaining: 17.2s
426:	learn: 0.0392148	total: 12.8s	remaining: 17.2s
427:	learn: 0.0388748	total: 12.8s	remaining: 17.2s
428:	learn: 0.0384683	total: 12.9s	remaining: 17.1s
429:	learn: 0.0380856	total: 12.9s	remaining: 17.1s
430:	learn: 0.0376740	total: 12.9s	remaining: 17.1s
431:	learn: 0.0374769	total: 13s	remaining: 17s
432:	learn: 0.0372758	total: 13s	remaining: 17s
433:	learn: 0.0369573	total: 13s	remaining: 17s
434:	learn: 0.0367150	total: 13s	remaining: 16.9s
435:	learn: 0.0364332	total: 13.1s	remaining: 16.9s
436:	learn: 0.0360786	total: 13.1s	remaining: 16.9s
437:	learn: 0.0357036	total: 13.1s	remaining: 16.8s
438:	learn: 0.0354990	total: 13.2s	remaining: 16.8s
439:	learn: 0.0351713	total: 13.2s	remaining: 16.8s
440:	learn: 0.0349742	total: 13.2s	remaining: 16.7s
441:	learn: 0.0346447	total: 13.2s	remaining: 16.7s
442:	learn: 0.0343518	total: 13.3s	remaining: 16.7s
443:	learn: 0.0339627	total: 13.3s	remaining: 16.7s
444:	learn: 0.0337082	total: 13.3s	remaining: 16.6s
445:	learn: 0.0335199	total: 13.4s	remaining: 16.6s
446:	learn: 0.0332985	total: 13.4s	remaining: 16.6s
447:	learn: 0.0330530	total: 13.4s	remaining: 16.5s
448:	learn: 0.0327762	total: 13.4s	remaining: 16.5s
449:	learn: 0.0324638	total: 13.5s	remaining: 16.5s
450:	learn: 0.0321344	total: 13.5s	remaining: 16.4s
451:	learn: 0.0318424	total: 13.5s	remaining: 16.4s
452:	learn: 0.0316115	total: 13.6s	remaining: 16.4s
453:	learn: 0.0312888	total: 13.6s	remaining: 16.3s
454:	learn: 0.0310008	total: 13.6s	remaining: 16.3s
455:	learn: 0.0307019	total: 13.6s	remaining: 16.3s
456:	learn: 0.0304065	total: 13.7s	remaining: 16.3s
457:	learn: 0.0300871	total: 13.7s	remaining: 16.2s
458:	learn: 0.0298150	total: 13.7s	remaining: 16.2s
459:	learn: 0.0294933	total: 13.8s	remaining: 16.2s
460:	learn: 0.0291957	total: 13.8s	remaining: 16.1s
461:	learn: 0.0289515	total: 13.8s	remaining: 16.1s
462:	learn: 0.0286962	total: 13.9s	remaining: 16.1s
463:	learn: 0.0284384	total: 13.9s	remaining: 16.1s
464:	learn: 0.0281742	total: 13.9s	remaining: 16s
465:	learn: 0.0278989	total: 14s	remaining: 16s
466:	learn: 0.0275921	total: 14s	remaining: 16s
467:	learn: 0.0273280	total: 14s	remaining: 15.9s
468:	learn: 0.0271683	total: 14.1s	remaining: 15.9s
469:	learn: 0.0268743	total: 14.1s	remaining: 15.9s
470:	learn: 0.0265950	total: 14.2s	remaining: 15.9s
471:	learn: 0.0264200	total: 14.2s	remaining: 15.9s
472:	learn: 0.0261263	total: 14.2s	remaining: 15.8s
473:	learn: 0.0258361	total: 14.3s	remaining: 15.8s
474:	learn: 0.0256178	total: 14.3s	remaining: 15.8s
475:	learn: 0.0253855	total: 14.3s	remaining: 15.8s
476:	learn: 0.0251522	total: 14.3s	remaining: 15.7s
477:	learn: 0.0250053	total: 14.4s	remaining: 15.7s
478:	learn: 0.0248763	total: 14.4s	remaining: 15.7s
479:	learn: 0.0246710	total: 14.4s	remaining: 15.6s
480:	learn: 0.0244269	total: 14.5s	remaining: 15.6s
481:	learn: 0.0242007	total: 14.5s	remaining: 15.6s
482:	learn: 0.0240870	total: 14.5s	remaining: 15.5s
483:	learn: 0.0238359	total: 14.5s	remaining: 15.5s
484:	learn: 0.0236213	total: 14.6s	remaining: 15.5s
485:	learn: 0.0234326	total: 14.6s	remaining: 15.4s
486:	learn: 0.0232282	total: 14.6s	remaining: 15.4s
487:	learn: 0.0229889	total: 14.7s	remaining: 15.4s
488:	learn: 0.0228500	total: 14.7s	remaining: 15.4s
489:	learn: 0.0226435	total: 14.7s	remaining: 15.3s
490:	learn: 0.0224261	total: 14.8s	remaining: 15.3s
491:	learn: 0.0221813	total: 14.8s	remaining: 15.3s
492:	learn: 0.0219166	total: 14.8s	remaining: 15.2s
493:	learn: 0.0217584	total: 14.8s	remaining: 15.2s
494:	learn: 0.0215223	total: 14.9s	remaining: 15.2s
495:	learn: 0.0213668	total: 14.9s	remaining: 15.2s
496:	learn: 0.0211922	total: 15s	remaining: 15.1s
497:	learn: 0.0209725	total: 15s	remaining: 15.1s
498:	learn: 0.0207601	total: 15s	remaining: 15.1s
499:	learn: 0.0205488	total: 15.1s	remaining: 15.1s
500:	learn: 0.0203577	total: 15.1s	remaining: 15s
501:	learn: 0.0202267	total: 15.1s	remaining: 15s
502:	learn: 0.0200777	total: 15.2s	remaining: 15s
503:	learn: 0.0198602	total: 15.2s	remaining: 14.9s
504:	learn: 0.0197075	total: 15.3s	remaining: 14.9s
505:	learn: 0.0195165	total: 15.3s	remaining: 14.9s
506:	learn: 0.0193834	total: 15.3s	remaining: 14.9s
507:	learn: 0.0191914	total: 15.3s	remaining: 14.9s
508:	learn: 0.0190415	total: 15.4s	remaining: 14.8s
509:	learn: 0.0189101	total: 15.4s	remaining: 14.8s
510:	learn: 0.0187331	total: 15.4s	remaining: 14.7s
511:	learn: 0.0185305	total: 15.4s	remaining: 14.7s
512:	learn: 0.0183648	total: 15.5s	remaining: 14.7s
513:	learn: 0.0182387	total: 15.5s	remaining: 14.7s
514:	learn: 0.0180645	total: 15.5s	remaining: 14.6s
515:	learn: 0.0179219	total: 15.6s	remaining: 14.6s
516:	learn: 0.0177197	total: 15.6s	remaining: 14.6s
517:	learn: 0.0175937	total: 15.6s	remaining: 14.5s
518:	learn: 0.0174108	total: 15.6s	remaining: 14.5s
519:	learn: 0.0172402	total: 15.7s	remaining: 14.5s
520:	learn: 0.0170936	total: 15.7s	remaining: 14.4s
521:	learn: 0.0169569	total: 15.7s	remaining: 14.4s
522:	learn: 0.0168113	total: 15.8s	remaining: 14.4s
523:	learn: 0.0166327	total: 15.8s	remaining: 14.3s
524:	learn: 0.0164983	total: 15.8s	remaining: 14.3s
525:	learn: 0.0163257	total: 15.9s	remaining: 14.3s
526:	learn: 0.0161854	total: 15.9s	remaining: 14.3s
527:	learn: 0.0160403	total: 15.9s	remaining: 14.2s
528:	learn: 0.0159355	total: 15.9s	remaining: 14.2s
529:	learn: 0.0157734	total: 16s	remaining: 14.2s
530:	learn: 0.0156557	total: 16s	remaining: 14.1s
531:	learn: 0.0155240	total: 16s	remaining: 14.1s
532:	learn: 0.0154159	total: 16.1s	remaining: 14.1s
533:	learn: 0.0153530	total: 16.1s	remaining: 14s
534:	learn: 0.0152421	total: 16.1s	remaining: 14s
535:	learn: 0.0151416	total: 16.2s	remaining: 14s
536:	learn: 0.0150749	total: 16.2s	remaining: 14s
537:	learn: 0.0149747	total: 16.2s	remaining: 13.9s
538:	learn: 0.0148819	total: 16.3s	remaining: 13.9s
539:	learn: 0.0147491	total: 16.3s	remaining: 13.9s
540:	learn: 0.0146245	total: 16.3s	remaining: 13.8s
541:	learn: 0.0144761	total: 16.3s	remaining: 13.8s
542:	learn: 0.0143244	total: 16.4s	remaining: 13.8s
543:	learn: 0.0142050	total: 16.4s	remaining: 13.8s
544:	learn: 0.0140851	total: 16.4s	remaining: 13.7s
545:	learn: 0.0139908	total: 16.5s	remaining: 13.7s
546:	learn: 0.0139066	total: 16.5s	remaining: 13.7s
547:	learn: 0.0137611	total: 16.5s	remaining: 13.6s
548:	learn: 0.0136600	total: 16.6s	remaining: 13.6s
549:	learn: 0.0135414	total: 16.6s	remaining: 13.6s
550:	learn: 0.0134038	total: 16.6s	remaining: 13.6s
551:	learn: 0.0133067	total: 16.7s	remaining: 13.5s
552:	learn: 0.0131926	total: 16.7s	remaining: 13.5s
553:	learn: 0.0130557	total: 16.7s	remaining: 13.5s
554:	learn: 0.0129681	total: 16.7s	remaining: 13.4s
555:	learn: 0.0128612	total: 16.8s	remaining: 13.4s
556:	learn: 0.0128166	total: 16.8s	remaining: 13.4s
557:	learn: 0.0127009	total: 16.9s	remaining: 13.4s
558:	learn: 0.0125895	total: 16.9s	remaining: 13.3s
559:	learn: 0.0125248	total: 16.9s	remaining: 13.3s
560:	learn: 0.0124138	total: 17s	remaining: 13.3s
561:	learn: 0.0123044	total: 17s	remaining: 13.2s
562:	learn: 0.0121974	total: 17s	remaining: 13.2s
563:	learn: 0.0121291	total: 17.1s	remaining: 13.2s
564:	learn: 0.0120350	total: 17.1s	remaining: 13.1s
565:	learn: 0.0119442	total: 17.1s	remaining: 13.1s
566:	learn: 0.0118524	total: 17.1s	remaining: 13.1s
567:	learn: 0.0117435	total: 17.2s	remaining: 13.1s
568:	learn: 0.0117096	total: 17.2s	remaining: 13s
569:	learn: 0.0116298	total: 17.2s	remaining: 13s
570:	learn: 0.0115956	total: 17.3s	remaining: 13s
571:	learn: 0.0114776	total: 17.3s	remaining: 12.9s
572:	learn: 0.0113622	total: 17.3s	remaining: 12.9s
573:	learn: 0.0112919	total: 17.3s	remaining: 12.9s
574:	learn: 0.0112272	total: 17.4s	remaining: 12.8s
575:	learn: 0.0111100	total: 17.4s	remaining: 12.8s
576:	learn: 0.0110161	total: 17.5s	remaining: 12.8s
577:	learn: 0.0108837	total: 17.5s	remaining: 12.8s
578:	learn: 0.0108551	total: 17.5s	remaining: 12.7s
579:	learn: 0.0107614	total: 17.5s	remaining: 12.7s
580:	learn: 0.0106618	total: 17.6s	remaining: 12.7s
581:	learn: 0.0105905	total: 17.6s	remaining: 12.7s
582:	learn: 0.0104814	total: 17.7s	remaining: 12.6s
583:	learn: 0.0103971	total: 17.7s	remaining: 12.6s
584:	learn: 0.0103252	total: 17.7s	remaining: 12.6s
585:	learn: 0.0102148	total: 17.7s	remaining: 12.5s
586:	learn: 0.0101862	total: 17.8s	remaining: 12.5s
587:	learn: 0.0101470	total: 17.8s	remaining: 12.5s
588:	learn: 0.0100369	total: 17.8s	remaining: 12.4s
589:	learn: 0.0099378	total: 17.9s	remaining: 12.4s
590:	learn: 0.0098890	total: 17.9s	remaining: 12.4s
591:	learn: 0.0098263	total: 17.9s	remaining: 12.3s
592:	learn: 0.0097444	total: 17.9s	remaining: 12.3s
593:	learn: 0.0096673	total: 18s	remaining: 12.3s
594:	learn: 0.0096080	total: 18s	remaining: 12.3s
595:	learn: 0.0095358	total: 18s	remaining: 12.2s
596:	learn: 0.0094776	total: 18.1s	remaining: 12.2s
597:	learn: 0.0094056	total: 18.1s	remaining: 12.2s
598:	learn: 0.0093088	total: 18.1s	remaining: 12.1s
599:	learn: 0.0092791	total: 18.2s	remaining: 12.1s
600:	learn: 0.0092529	total: 18.2s	remaining: 12.1s
601:	learn: 0.0091694	total: 18.2s	remaining: 12.1s
602:	learn: 0.0090833	total: 18.3s	remaining: 12s
603:	learn: 0.0089919	total: 18.3s	remaining: 12s
604:	learn: 0.0089239	total: 18.3s	remaining: 12s
605:	learn: 0.0088880	total: 18.4s	remaining: 11.9s
606:	learn: 0.0088151	total: 18.4s	remaining: 11.9s
607:	learn: 0.0087196	total: 18.4s	remaining: 11.9s
608:	learn: 0.0086292	total: 18.5s	remaining: 11.8s
609:	learn: 0.0086012	total: 18.5s	remaining: 11.8s
610:	learn: 0.0085002	total: 18.5s	remaining: 11.8s
611:	learn: 0.0084216	total: 18.5s	remaining: 11.8s
612:	learn: 0.0083430	total: 18.6s	remaining: 11.7s
613:	learn: 0.0082626	total: 18.6s	remaining: 11.7s
614:	learn: 0.0081977	total: 18.6s	remaining: 11.7s
615:	learn: 0.0081389	total: 18.7s	remaining: 11.6s
616:	learn: 0.0080757	total: 18.7s	remaining: 11.6s
617:	learn: 0.0080078	total: 18.7s	remaining: 11.6s
618:	learn: 0.0079279	total: 18.7s	remaining: 11.5s
619:	learn: 0.0078529	total: 18.8s	remaining: 11.5s
620:	learn: 0.0077971	total: 18.8s	remaining: 11.5s
621:	learn: 0.0077212	total: 18.8s	remaining: 11.4s
622:	learn: 0.0076466	total: 18.9s	remaining: 11.4s
623:	learn: 0.0075834	total: 18.9s	remaining: 11.4s
624:	learn: 0.0075259	total: 18.9s	remaining: 11.4s
625:	learn: 0.0074624	total: 18.9s	remaining: 11.3s
626:	learn: 0.0073746	total: 19s	remaining: 11.3s
627:	learn: 0.0073538	total: 19s	remaining: 11.3s
628:	learn: 0.0073073	total: 19.1s	remaining: 11.2s
629:	learn: 0.0072832	total: 19.1s	remaining: 11.2s
630:	learn: 0.0072381	total: 19.1s	remaining: 11.2s
631:	learn: 0.0071550	total: 19.1s	remaining: 11.2s
632:	learn: 0.0071011	total: 19.2s	remaining: 11.1s
633:	learn: 0.0070764	total: 19.2s	remaining: 11.1s
634:	learn: 0.0070305	total: 19.2s	remaining: 11.1s
635:	learn: 0.0069800	total: 19.3s	remaining: 11s
636:	learn: 0.0069201	total: 19.3s	remaining: 11s
637:	learn: 0.0068629	total: 19.3s	remaining: 11s
638:	learn: 0.0068225	total: 19.4s	remaining: 10.9s
639:	learn: 0.0067747	total: 19.4s	remaining: 10.9s
640:	learn: 0.0067534	total: 19.4s	remaining: 10.9s
641:	learn: 0.0067182	total: 19.5s	remaining: 10.8s
642:	learn: 0.0066701	total: 19.5s	remaining: 10.8s
643:	learn: 0.0066002	total: 19.5s	remaining: 10.8s
644:	learn: 0.0065383	total: 19.5s	remaining: 10.8s
645:	learn: 0.0064700	total: 19.6s	remaining: 10.7s
646:	learn: 0.0064019	total: 19.6s	remaining: 10.7s
647:	learn: 0.0063349	total: 19.6s	remaining: 10.7s
648:	learn: 0.0062773	total: 19.7s	remaining: 10.6s
649:	learn: 0.0062182	total: 19.7s	remaining: 10.6s
650:	learn: 0.0061720	total: 19.7s	remaining: 10.6s
651:	learn: 0.0061328	total: 19.7s	remaining: 10.5s
652:	learn: 0.0060815	total: 19.8s	remaining: 10.5s
653:	learn: 0.0060342	total: 19.8s	remaining: 10.5s
654:	learn: 0.0059604	total: 19.8s	remaining: 10.4s
655:	learn: 0.0059064	total: 19.8s	remaining: 10.4s
656:	learn: 0.0058529	total: 19.9s	remaining: 10.4s
657:	learn: 0.0058359	total: 19.9s	remaining: 10.3s
658:	learn: 0.0058100	total: 19.9s	remaining: 10.3s
659:	learn: 0.0057653	total: 20s	remaining: 10.3s
660:	learn: 0.0057274	total: 20s	remaining: 10.3s
661:	learn: 0.0056838	total: 20s	remaining: 10.2s
662:	learn: 0.0056381	total: 20s	remaining: 10.2s
663:	learn: 0.0055975	total: 20.1s	remaining: 10.2s
664:	learn: 0.0055737	total: 20.1s	remaining: 10.1s
665:	learn: 0.0055078	total: 20.1s	remaining: 10.1s
666:	learn: 0.0054503	total: 20.2s	remaining: 10.1s
667:	learn: 0.0053915	total: 20.2s	remaining: 10s
668:	learn: 0.0053460	total: 20.2s	remaining: 10s
669:	learn: 0.0053279	total: 20.3s	remaining: 9.98s
670:	learn: 0.0052969	total: 20.3s	remaining: 9.95s
671:	learn: 0.0052597	total: 20.3s	remaining: 9.91s
672:	learn: 0.0052076	total: 20.3s	remaining: 9.88s
673:	learn: 0.0051583	total: 20.4s	remaining: 9.85s
674:	learn: 0.0051105	total: 20.4s	remaining: 9.82s
675:	learn: 0.0050606	total: 20.4s	remaining: 9.79s
676:	learn: 0.0050045	total: 20.5s	remaining: 9.76s
677:	learn: 0.0049759	total: 20.5s	remaining: 9.73s
678:	learn: 0.0049306	total: 20.5s	remaining: 9.7s
679:	learn: 0.0049143	total: 20.6s	remaining: 9.67s
680:	learn: 0.0048723	total: 20.6s	remaining: 9.64s
681:	learn: 0.0048242	total: 20.6s	remaining: 9.61s
682:	learn: 0.0047773	total: 20.6s	remaining: 9.58s
683:	learn: 0.0047574	total: 20.7s	remaining: 9.55s
684:	learn: 0.0047384	total: 20.7s	remaining: 9.52s
685:	learn: 0.0046907	total: 20.7s	remaining: 9.49s
686:	learn: 0.0046447	total: 20.8s	remaining: 9.46s
687:	learn: 0.0046113	total: 20.8s	remaining: 9.43s
688:	learn: 0.0045761	total: 20.8s	remaining: 9.4s
689:	learn: 0.0045617	total: 20.8s	remaining: 9.37s
690:	learn: 0.0045491	total: 20.9s	remaining: 9.34s
691:	learn: 0.0045210	total: 20.9s	remaining: 9.3s
692:	learn: 0.0044789	total: 20.9s	remaining: 9.27s
693:	learn: 0.0044624	total: 21s	remaining: 9.24s
694:	learn: 0.0044206	total: 21s	remaining: 9.21s
695:	learn: 0.0043773	total: 21s	remaining: 9.18s
696:	learn: 0.0043422	total: 21.1s	remaining: 9.15s
697:	learn: 0.0043119	total: 21.1s	remaining: 9.13s
698:	learn: 0.0042827	total: 21.1s	remaining: 9.09s
699:	learn: 0.0042356	total: 21.1s	remaining: 9.06s
700:	learn: 0.0042131	total: 21.2s	remaining: 9.03s
701:	learn: 0.0041740	total: 21.2s	remaining: 9s
702:	learn: 0.0041592	total: 21.2s	remaining: 8.97s
703:	learn: 0.0041143	total: 21.3s	remaining: 8.95s
704:	learn: 0.0041027	total: 21.3s	remaining: 8.92s
705:	learn: 0.0040723	total: 21.3s	remaining: 8.89s
706:	learn: 0.0040460	total: 21.4s	remaining: 8.86s
707:	learn: 0.0040028	total: 21.4s	remaining: 8.83s
708:	learn: 0.0039619	total: 21.4s	remaining: 8.8s
709:	learn: 0.0039326	total: 21.5s	remaining: 8.77s
710:	learn: 0.0039205	total: 21.5s	remaining: 8.73s
711:	learn: 0.0038878	total: 21.5s	remaining: 8.7s
712:	learn: 0.0038572	total: 21.5s	remaining: 8.67s
713:	learn: 0.0038166	total: 21.6s	remaining: 8.64s
714:	learn: 0.0037848	total: 21.6s	remaining: 8.62s
715:	learn: 0.0037759	total: 21.6s	remaining: 8.58s
716:	learn: 0.0037397	total: 21.7s	remaining: 8.55s
717:	learn: 0.0037298	total: 21.7s	remaining: 8.52s
718:	learn: 0.0036946	total: 21.7s	remaining: 8.49s
719:	learn: 0.0036568	total: 21.8s	remaining: 8.46s
720:	learn: 0.0036216	total: 21.8s	remaining: 8.43s
721:	learn: 0.0035950	total: 21.8s	remaining: 8.41s
722:	learn: 0.0035601	total: 21.9s	remaining: 8.38s
723:	learn: 0.0035399	total: 21.9s	remaining: 8.35s
724:	learn: 0.0035133	total: 21.9s	remaining: 8.32s
725:	learn: 0.0034785	total: 22s	remaining: 8.29s
726:	learn: 0.0034447	total: 22s	remaining: 8.26s
727:	learn: 0.0034197	total: 22s	remaining: 8.23s
728:	learn: 0.0033846	total: 22.1s	remaining: 8.2s
729:	learn: 0.0033551	total: 22.1s	remaining: 8.17s
730:	learn: 0.0033226	total: 22.1s	remaining: 8.14s
731:	learn: 0.0032972	total: 22.1s	remaining: 8.11s
732:	learn: 0.0032884	total: 22.2s	remaining: 8.08s
733:	learn: 0.0032571	total: 22.2s	remaining: 8.05s
734:	learn: 0.0032404	total: 22.2s	remaining: 8.02s
735:	learn: 0.0032093	total: 22.3s	remaining: 7.99s
736:	learn: 0.0031867	total: 22.3s	remaining: 7.96s
737:	learn: 0.0031576	total: 22.3s	remaining: 7.93s
738:	learn: 0.0031354	total: 22.3s	remaining: 7.89s
739:	learn: 0.0031040	total: 22.4s	remaining: 7.86s
740:	learn: 0.0030706	total: 22.4s	remaining: 7.83s
741:	learn: 0.0030579	total: 22.4s	remaining: 7.8s
742:	learn: 0.0030458	total: 22.5s	remaining: 7.77s
743:	learn: 0.0030237	total: 22.5s	remaining: 7.74s
744:	learn: 0.0029966	total: 22.5s	remaining: 7.71s
745:	learn: 0.0029757	total: 22.5s	remaining: 7.67s
746:	learn: 0.0029516	total: 22.6s	remaining: 7.64s
747:	learn: 0.0029279	total: 22.6s	remaining: 7.61s
748:	learn: 0.0028974	total: 22.6s	remaining: 7.58s
749:	learn: 0.0028747	total: 22.6s	remaining: 7.55s
750:	learn: 0.0028486	total: 22.7s	remaining: 7.52s
751:	learn: 0.0028380	total: 22.7s	remaining: 7.49s
752:	learn: 0.0028287	total: 22.7s	remaining: 7.45s
753:	learn: 0.0028070	total: 22.7s	remaining: 7.42s
754:	learn: 0.0027871	total: 22.8s	remaining: 7.39s
755:	learn: 0.0027626	total: 22.8s	remaining: 7.36s
756:	learn: 0.0027420	total: 22.8s	remaining: 7.33s
757:	learn: 0.0027214	total: 22.8s	remaining: 7.29s
758:	learn: 0.0026908	total: 22.9s	remaining: 7.26s
759:	learn: 0.0026663	total: 22.9s	remaining: 7.23s
760:	learn: 0.0026394	total: 22.9s	remaining: 7.2s
761:	learn: 0.0026189	total: 23s	remaining: 7.17s
762:	learn: 0.0025981	total: 23s	remaining: 7.14s
763:	learn: 0.0025744	total: 23s	remaining: 7.11s
764:	learn: 0.0025561	total: 23s	remaining: 7.08s
765:	learn: 0.0025292	total: 23.1s	remaining: 7.05s
766:	learn: 0.0025022	total: 23.1s	remaining: 7.01s
767:	learn: 0.0024752	total: 23.1s	remaining: 6.98s
768:	learn: 0.0024653	total: 23.1s	remaining: 6.95s
769:	learn: 0.0024407	total: 23.2s	remaining: 6.92s
770:	learn: 0.0024306	total: 23.2s	remaining: 6.89s
771:	learn: 0.0024105	total: 23.2s	remaining: 6.86s
772:	learn: 0.0023914	total: 23.2s	remaining: 6.83s
773:	learn: 0.0023690	total: 23.3s	remaining: 6.79s
774:	learn: 0.0023619	total: 23.3s	remaining: 6.76s
775:	learn: 0.0023368	total: 23.3s	remaining: 6.73s
776:	learn: 0.0023197	total: 23.3s	remaining: 6.7s
777:	learn: 0.0022995	total: 23.4s	remaining: 6.67s
778:	learn: 0.0022788	total: 23.4s	remaining: 6.63s
779:	learn: 0.0022589	total: 23.4s	remaining: 6.6s
780:	learn: 0.0022425	total: 23.4s	remaining: 6.57s
781:	learn: 0.0022365	total: 23.5s	remaining: 6.54s
782:	learn: 0.0022143	total: 23.5s	remaining: 6.51s
783:	learn: 0.0022092	total: 23.5s	remaining: 6.48s
784:	learn: 0.0021923	total: 23.5s	remaining: 6.45s
785:	learn: 0.0021747	total: 23.6s	remaining: 6.42s
786:	learn: 0.0021688	total: 23.6s	remaining: 6.38s
787:	learn: 0.0021483	total: 23.6s	remaining: 6.35s
788:	learn: 0.0021329	total: 23.6s	remaining: 6.32s
789:	learn: 0.0021162	total: 23.7s	remaining: 6.29s
790:	learn: 0.0021102	total: 23.7s	remaining: 6.26s
791:	learn: 0.0020953	total: 23.7s	remaining: 6.23s
792:	learn: 0.0020771	total: 23.8s	remaining: 6.2s
793:	learn: 0.0020573	total: 23.8s	remaining: 6.17s
794:	learn: 0.0020469	total: 23.8s	remaining: 6.14s
795:	learn: 0.0020292	total: 23.8s	remaining: 6.11s
796:	learn: 0.0020171	total: 23.9s	remaining: 6.08s
797:	learn: 0.0019987	total: 23.9s	remaining: 6.05s
798:	learn: 0.0019890	total: 23.9s	remaining: 6.02s
799:	learn: 0.0019717	total: 24s	remaining: 5.99s
800:	learn: 0.0019519	total: 24s	remaining: 5.96s
801:	learn: 0.0019360	total: 24s	remaining: 5.93s
802:	learn: 0.0019196	total: 24s	remaining: 5.9s
803:	learn: 0.0019065	total: 24.1s	remaining: 5.87s
804:	learn: 0.0018964	total: 24.1s	remaining: 5.84s
805:	learn: 0.0018839	total: 24.1s	remaining: 5.81s
806:	learn: 0.0018674	total: 24.2s	remaining: 5.78s
807:	learn: 0.0018613	total: 24.2s	remaining: 5.75s
808:	learn: 0.0018554	total: 24.2s	remaining: 5.71s
809:	learn: 0.0018392	total: 24.2s	remaining: 5.68s
810:	learn: 0.0018334	total: 24.3s	remaining: 5.65s
811:	learn: 0.0018147	total: 24.3s	remaining: 5.62s
812:	learn: 0.0017962	total: 24.3s	remaining: 5.59s
813:	learn: 0.0017806	total: 24.3s	remaining: 5.56s
814:	learn: 0.0017658	total: 24.4s	remaining: 5.53s
815:	learn: 0.0017526	total: 24.4s	remaining: 5.5s
816:	learn: 0.0017367	total: 24.4s	remaining: 5.47s
817:	learn: 0.0017301	total: 24.4s	remaining: 5.44s
818:	learn: 0.0017171	total: 24.5s	remaining: 5.41s
819:	learn: 0.0017064	total: 24.5s	remaining: 5.38s
820:	learn: 0.0016938	total: 24.5s	remaining: 5.35s
821:	learn: 0.0016801	total: 24.6s	remaining: 5.32s
822:	learn: 0.0016626	total: 24.6s	remaining: 5.29s
823:	learn: 0.0016446	total: 24.6s	remaining: 5.26s
824:	learn: 0.0016319	total: 24.6s	remaining: 5.23s
825:	learn: 0.0016176	total: 24.7s	remaining: 5.2s
826:	learn: 0.0016069	total: 24.7s	remaining: 5.17s
827:	learn: 0.0015955	total: 24.7s	remaining: 5.14s
828:	learn: 0.0015783	total: 24.8s	remaining: 5.11s
829:	learn: 0.0015624	total: 24.8s	remaining: 5.07s
830:	learn: 0.0015492	total: 24.8s	remaining: 5.04s
831:	learn: 0.0015343	total: 24.8s	remaining: 5.01s
832:	learn: 0.0015221	total: 24.9s	remaining: 4.98s
833:	learn: 0.0015059	total: 24.9s	remaining: 4.95s
834:	learn: 0.0014883	total: 24.9s	remaining: 4.92s
835:	learn: 0.0014746	total: 24.9s	remaining: 4.89s
836:	learn: 0.0014696	total: 25s	remaining: 4.86s
837:	learn: 0.0014587	total: 25s	remaining: 4.83s
838:	learn: 0.0014434	total: 25s	remaining: 4.8s
839:	learn: 0.0014334	total: 25s	remaining: 4.77s
840:	learn: 0.0014199	total: 25.1s	remaining: 4.74s
841:	learn: 0.0014050	total: 25.1s	remaining: 4.71s
842:	learn: 0.0013957	total: 25.1s	remaining: 4.68s
843:	learn: 0.0013919	total: 25.2s	remaining: 4.65s
844:	learn: 0.0013774	total: 25.2s	remaining: 4.62s
845:	learn: 0.0013643	total: 25.2s	remaining: 4.59s
846:	learn: 0.0013602	total: 25.2s	remaining: 4.56s
847:	learn: 0.0013564	total: 25.3s	remaining: 4.53s
848:	learn: 0.0013432	total: 25.3s	remaining: 4.5s
849:	learn: 0.0013311	total: 25.3s	remaining: 4.47s
850:	learn: 0.0013202	total: 25.4s	remaining: 4.44s
851:	learn: 0.0013067	total: 25.4s	remaining: 4.41s
852:	learn: 0.0012953	total: 25.4s	remaining: 4.38s
853:	learn: 0.0012862	total: 25.4s	remaining: 4.35s
854:	learn: 0.0012718	total: 25.5s	remaining: 4.32s
855:	learn: 0.0012598	total: 25.5s	remaining: 4.29s
856:	learn: 0.0012486	total: 25.5s	remaining: 4.26s
857:	learn: 0.0012378	total: 25.6s	remaining: 4.23s
858:	learn: 0.0012282	total: 25.6s	remaining: 4.2s
859:	learn: 0.0012188	total: 25.6s	remaining: 4.17s
860:	learn: 0.0012155	total: 25.7s	remaining: 4.14s
861:	learn: 0.0012063	total: 25.7s	remaining: 4.11s
862:	learn: 0.0011981	total: 25.7s	remaining: 4.08s
863:	learn: 0.0011947	total: 25.7s	remaining: 4.05s
864:	learn: 0.0011857	total: 25.8s	remaining: 4.02s
865:	learn: 0.0011827	total: 25.8s	remaining: 3.99s
866:	learn: 0.0011701	total: 25.8s	remaining: 3.96s
867:	learn: 0.0011580	total: 25.9s	remaining: 3.93s
868:	learn: 0.0011481	total: 25.9s	remaining: 3.9s
869:	learn: 0.0011397	total: 25.9s	remaining: 3.87s
870:	learn: 0.0011318	total: 26s	remaining: 3.84s
871:	learn: 0.0011207	total: 26s	remaining: 3.81s
872:	learn: 0.0011095	total: 26s	remaining: 3.79s
873:	learn: 0.0011063	total: 26s	remaining: 3.75s
874:	learn: 0.0010968	total: 26.1s	remaining: 3.72s
875:	learn: 0.0010887	total: 26.1s	remaining: 3.69s
876:	learn: 0.0010772	total: 26.1s	remaining: 3.66s
877:	learn: 0.0010688	total: 26.2s	remaining: 3.63s
878:	learn: 0.0010617	total: 26.2s	remaining: 3.6s
879:	learn: 0.0010525	total: 26.2s	remaining: 3.57s
880:	learn: 0.0010433	total: 26.2s	remaining: 3.54s
881:	learn: 0.0010340	total: 26.3s	remaining: 3.51s
882:	learn: 0.0010293	total: 26.3s	remaining: 3.48s
883:	learn: 0.0010202	total: 26.3s	remaining: 3.45s
884:	learn: 0.0010130	total: 26.4s	remaining: 3.42s
885:	learn: 0.0010036	total: 26.4s	remaining: 3.39s
886:	learn: 0.0009953	total: 26.4s	remaining: 3.36s
887:	learn: 0.0009853	total: 26.4s	remaining: 3.33s
888:	learn: 0.0009776	total: 26.4s	remaining: 3.3s
889:	learn: 0.0009677	total: 26.5s	remaining: 3.27s
890:	learn: 0.0009589	total: 26.5s	remaining: 3.24s
891:	learn: 0.0009514	total: 26.5s	remaining: 3.21s
892:	learn: 0.0009422	total: 26.6s	remaining: 3.18s
893:	learn: 0.0009357	total: 26.6s	remaining: 3.15s
894:	learn: 0.0009329	total: 26.6s	remaining: 3.12s
895:	learn: 0.0009304	total: 26.7s	remaining: 3.09s
896:	learn: 0.0009232	total: 26.7s	remaining: 3.06s
897:	learn: 0.0009150	total: 26.7s	remaining: 3.03s
898:	learn: 0.0009083	total: 26.7s	remaining: 3s
899:	learn: 0.0009028	total: 26.8s	remaining: 2.97s
900:	learn: 0.0008947	total: 26.8s	remaining: 2.94s
901:	learn: 0.0008871	total: 26.8s	remaining: 2.91s
902:	learn: 0.0008776	total: 26.8s	remaining: 2.88s
903:	learn: 0.0008707	total: 26.9s	remaining: 2.85s
904:	learn: 0.0008616	total: 26.9s	remaining: 2.82s
905:	learn: 0.0008587	total: 26.9s	remaining: 2.79s
906:	learn: 0.0008512	total: 27s	remaining: 2.76s
907:	learn: 0.0008436	total: 27s	remaining: 2.73s
908:	learn: 0.0008361	total: 27s	remaining: 2.7s
909:	learn: 0.0008299	total: 27s	remaining: 2.67s
910:	learn: 0.0008216	total: 27.1s	remaining: 2.64s
911:	learn: 0.0008139	total: 27.1s	remaining: 2.61s
912:	learn: 0.0008119	total: 27.1s	remaining: 2.58s
913:	learn: 0.0008100	total: 27.1s	remaining: 2.55s
914:	learn: 0.0008080	total: 27.2s	remaining: 2.52s
915:	learn: 0.0007999	total: 27.2s	remaining: 2.49s
916:	learn: 0.0007976	total: 27.2s	remaining: 2.46s
917:	learn: 0.0007906	total: 27.2s	remaining: 2.43s
918:	learn: 0.0007835	total: 27.3s	remaining: 2.4s
919:	learn: 0.0007775	total: 27.3s	remaining: 2.37s
920:	learn: 0.0007706	total: 27.3s	remaining: 2.34s
921:	learn: 0.0007640	total: 27.4s	remaining: 2.31s
922:	learn: 0.0007612	total: 27.4s	remaining: 2.28s
923:	learn: 0.0007595	total: 27.4s	remaining: 2.25s
924:	learn: 0.0007535	total: 27.4s	remaining: 2.23s
925:	learn: 0.0007459	total: 27.5s	remaining: 2.19s
926:	learn: 0.0007387	total: 27.5s	remaining: 2.17s
927:	learn: 0.0007352	total: 27.5s	remaining: 2.14s
928:	learn: 0.0007331	total: 27.6s	remaining: 2.11s
929:	learn: 0.0007261	total: 27.6s	remaining: 2.08s
930:	learn: 0.0007239	total: 27.6s	remaining: 2.05s
931:	learn: 0.0007199	total: 27.7s	remaining: 2.02s
932:	learn: 0.0007135	total: 27.7s	remaining: 1.99s
933:	learn: 0.0007109	total: 27.7s	remaining: 1.96s
934:	learn: 0.0007033	total: 27.8s	remaining: 1.93s
935:	learn: 0.0006992	total: 27.8s	remaining: 1.9s
936:	learn: 0.0006933	total: 27.8s	remaining: 1.87s
937:	learn: 0.0006866	total: 27.9s	remaining: 1.84s
938:	learn: 0.0006842	total: 27.9s	remaining: 1.81s
939:	learn: 0.0006786	total: 27.9s	remaining: 1.78s
940:	learn: 0.0006753	total: 27.9s	remaining: 1.75s
941:	learn: 0.0006713	total: 28s	remaining: 1.72s
942:	learn: 0.0006668	total: 28s	remaining: 1.69s
943:	learn: 0.0006611	total: 28.1s	remaining: 1.66s
944:	learn: 0.0006562	total: 28.1s	remaining: 1.63s
945:	learn: 0.0006483	total: 28.1s	remaining: 1.6s
946:	learn: 0.0006419	total: 28.1s	remaining: 1.57s
947:	learn: 0.0006356	total: 28.2s	remaining: 1.54s
948:	learn: 0.0006287	total: 28.2s	remaining: 1.52s
949:	learn: 0.0006249	total: 28.2s	remaining: 1.49s
950:	learn: 0.0006193	total: 28.3s	remaining: 1.46s
951:	learn: 0.0006138	total: 28.3s	remaining: 1.43s
952:	learn: 0.0006091	total: 28.3s	remaining: 1.4s
953:	learn: 0.0006047	total: 28.4s	remaining: 1.37s
954:	learn: 0.0005981	total: 28.4s	remaining: 1.34s
955:	learn: 0.0005965	total: 28.4s	remaining: 1.31s
956:	learn: 0.0005918	total: 28.4s	remaining: 1.28s
957:	learn: 0.0005877	total: 28.5s	remaining: 1.25s
958:	learn: 0.0005860	total: 28.5s	remaining: 1.22s
959:	learn: 0.0005838	total: 28.5s	remaining: 1.19s
960:	learn: 0.0005782	total: 28.5s	remaining: 1.16s
961:	learn: 0.0005730	total: 28.6s	remaining: 1.13s
962:	learn: 0.0005679	total: 28.6s	remaining: 1.1s
963:	learn: 0.0005635	total: 28.6s	remaining: 1.07s
964:	learn: 0.0005576	total: 28.7s	remaining: 1.04s
965:	learn: 0.0005525	total: 28.7s	remaining: 1.01s
966:	learn: 0.0005475	total: 28.7s	remaining: 980ms
967:	learn: 0.0005461	total: 28.7s	remaining: 950ms
968:	learn: 0.0005404	total: 28.8s	remaining: 920ms
969:	learn: 0.0005369	total: 28.8s	remaining: 890ms
970:	learn: 0.0005319	total: 28.8s	remaining: 861ms
971:	learn: 0.0005274	total: 28.8s	remaining: 831ms
972:	learn: 0.0005226	total: 28.9s	remaining: 801ms
973:	learn: 0.0005188	total: 28.9s	remaining: 771ms
974:	learn: 0.0005147	total: 28.9s	remaining: 741ms
975:	learn: 0.0005103	total: 28.9s	remaining: 712ms
976:	learn: 0.0005057	total: 29s	remaining: 682ms
977:	learn: 0.0005023	total: 29s	remaining: 652ms
978:	learn: 0.0004979	total: 29s	remaining: 623ms
979:	learn: 0.0004952	total: 29s	remaining: 593ms
980:	learn: 0.0004900	total: 29.1s	remaining: 563ms
981:	learn: 0.0004879	total: 29.1s	remaining: 533ms
982:	learn: 0.0004840	total: 29.1s	remaining: 504ms
983:	learn: 0.0004792	total: 29.1s	remaining: 474ms
984:	learn: 0.0004745	total: 29.2s	remaining: 444ms
985:	learn: 0.0004700	total: 29.2s	remaining: 415ms
986:	learn: 0.0004652	total: 29.2s	remaining: 385ms
987:	learn: 0.0004614	total: 29.2s	remaining: 355ms
988:	learn: 0.0004576	total: 29.3s	remaining: 326ms
989:	learn: 0.0004559	total: 29.3s	remaining: 296ms
990:	learn: 0.0004528	total: 29.3s	remaining: 266ms
991:	learn: 0.0004505	total: 29.3s	remaining: 237ms
992:	learn: 0.0004463	total: 29.4s	remaining: 207ms
993:	learn: 0.0004419	total: 29.4s	remaining: 177ms
994:	learn: 0.0004407	total: 29.4s	remaining: 148ms
995:	learn: 0.0004394	total: 29.5s	remaining: 118ms
996:	learn: 0.0004384	total: 29.5s	remaining: 88.7ms
997:	learn: 0.0004340	total: 29.5s	remaining: 59.1ms
998:	learn: 0.0004324	total: 29.5s	remaining: 29.6ms
999:	learn: 0.0004290	total: 29.6s	remaining: 0us
Learning rate set to 0.030858
0:	learn: 0.8714114	total: 43.6ms	remaining: 43.5s
1:	learn: 0.8670364	total: 66.4ms	remaining: 33.1s
2:	learn: 0.8645297	total: 87.7ms	remaining: 29.2s
3:	learn: 0.8608504	total: 116ms	remaining: 28.9s
4:	learn: 0.8549285	total: 158ms	remaining: 31.4s
5:	learn: 0.8521944	total: 180ms	remaining: 29.8s
6:	learn: 0.8504210	total: 203ms	remaining: 28.8s
7:	learn: 0.8479439	total: 230ms	remaining: 28.5s
8:	learn: 0.8444195	total: 276ms	remaining: 30.4s
9:	learn: 0.8403769	total: 298ms	remaining: 29.5s
10:	learn: 0.8379922	total: 323ms	remaining: 29.1s
11:	learn: 0.8369399	total: 347ms	remaining: 28.5s
12:	learn: 0.8341989	total: 371ms	remaining: 28.1s
13:	learn: 0.8312382	total: 397ms	remaining: 28s
14:	learn: 0.8297935	total: 421ms	remaining: 27.6s
15:	learn: 0.8271062	total: 457ms	remaining: 28.1s
16:	learn: 0.8248532	total: 489ms	remaining: 28.3s
17:	learn: 0.8218296	total: 514ms	remaining: 28s
18:	learn: 0.8195502	total: 543ms	remaining: 28s
19:	learn: 0.8151992	total: 569ms	remaining: 27.9s
20:	learn: 0.8142640	total: 587ms	remaining: 27.3s
21:	learn: 0.8131951	total: 614ms	remaining: 27.3s
22:	learn: 0.8114758	total: 643ms	remaining: 27.3s
23:	learn: 0.8098488	total: 673ms	remaining: 27.4s
24:	learn: 0.8063350	total: 707ms	remaining: 27.6s
25:	learn: 0.8035434	total: 737ms	remaining: 27.6s
26:	learn: 0.8014601	total: 767ms	remaining: 27.6s
27:	learn: 0.7981604	total: 794ms	remaining: 27.5s
28:	learn: 0.7949007	total: 821ms	remaining: 27.5s
29:	learn: 0.7915274	total: 850ms	remaining: 27.5s
30:	learn: 0.7883001	total: 888ms	remaining: 27.7s
31:	learn: 0.7836108	total: 921ms	remaining: 27.9s
32:	learn: 0.7796638	total: 949ms	remaining: 27.8s
33:	learn: 0.7758591	total: 980ms	remaining: 27.8s
34:	learn: 0.7734542	total: 1.01s	remaining: 27.8s
35:	learn: 0.7724726	total: 1.03s	remaining: 27.7s
36:	learn: 0.7705888	total: 1.06s	remaining: 27.6s
37:	learn: 0.7654622	total: 1.09s	remaining: 27.6s
38:	learn: 0.7624418	total: 1.12s	remaining: 27.6s
39:	learn: 0.7592289	total: 1.15s	remaining: 27.6s
40:	learn: 0.7576456	total: 1.18s	remaining: 27.5s
41:	learn: 0.7546749	total: 1.21s	remaining: 27.5s
42:	learn: 0.7518670	total: 1.23s	remaining: 27.4s
43:	learn: 0.7484988	total: 1.26s	remaining: 27.4s
44:	learn: 0.7445947	total: 1.28s	remaining: 27.3s
45:	learn: 0.7406953	total: 1.31s	remaining: 27.2s
46:	learn: 0.7373776	total: 1.34s	remaining: 27.3s
47:	learn: 0.7348014	total: 1.37s	remaining: 27.2s
48:	learn: 0.7308480	total: 1.41s	remaining: 27.4s
49:	learn: 0.7275926	total: 1.45s	remaining: 27.5s
50:	learn: 0.7245342	total: 1.48s	remaining: 27.5s
51:	learn: 0.7216839	total: 1.51s	remaining: 27.5s
52:	learn: 0.7172026	total: 1.54s	remaining: 27.5s
53:	learn: 0.7145592	total: 1.57s	remaining: 27.5s
54:	learn: 0.7113648	total: 1.6s	remaining: 27.5s
55:	learn: 0.7091506	total: 1.63s	remaining: 27.5s
56:	learn: 0.7073807	total: 1.66s	remaining: 27.4s
57:	learn: 0.7046347	total: 1.68s	remaining: 27.4s
58:	learn: 0.7029565	total: 1.71s	remaining: 27.3s
59:	learn: 0.7003554	total: 1.75s	remaining: 27.4s
60:	learn: 0.6973494	total: 1.78s	remaining: 27.3s
61:	learn: 0.6950611	total: 1.81s	remaining: 27.4s
62:	learn: 0.6929579	total: 1.84s	remaining: 27.4s
63:	learn: 0.6918418	total: 1.88s	remaining: 27.5s
64:	learn: 0.6879055	total: 1.91s	remaining: 27.5s
65:	learn: 0.6852173	total: 1.95s	remaining: 27.6s
66:	learn: 0.6830811	total: 1.98s	remaining: 27.6s
67:	learn: 0.6812028	total: 2.02s	remaining: 27.7s
68:	learn: 0.6801457	total: 2.06s	remaining: 27.7s
69:	learn: 0.6766182	total: 2.09s	remaining: 27.8s
70:	learn: 0.6757343	total: 2.12s	remaining: 27.8s
71:	learn: 0.6738297	total: 2.15s	remaining: 27.8s
72:	learn: 0.6695678	total: 2.19s	remaining: 27.9s
73:	learn: 0.6679546	total: 2.23s	remaining: 27.9s
74:	learn: 0.6641246	total: 2.27s	remaining: 28s
75:	learn: 0.6621586	total: 2.3s	remaining: 28s
76:	learn: 0.6576968	total: 2.33s	remaining: 28s
77:	learn: 0.6538065	total: 2.37s	remaining: 28s
78:	learn: 0.6517350	total: 2.4s	remaining: 28s
79:	learn: 0.6471297	total: 2.44s	remaining: 28s
80:	learn: 0.6443815	total: 2.47s	remaining: 28.1s
81:	learn: 0.6418635	total: 2.51s	remaining: 28.1s
82:	learn: 0.6374367	total: 2.54s	remaining: 28.1s
83:	learn: 0.6354177	total: 2.58s	remaining: 28.1s
84:	learn: 0.6321856	total: 2.61s	remaining: 28.1s
85:	learn: 0.6296893	total: 2.65s	remaining: 28.1s
86:	learn: 0.6261378	total: 2.68s	remaining: 28.1s
87:	learn: 0.6230692	total: 2.71s	remaining: 28.1s
88:	learn: 0.6218622	total: 2.75s	remaining: 28.1s
89:	learn: 0.6195797	total: 2.78s	remaining: 28.1s
90:	learn: 0.6158660	total: 2.82s	remaining: 28.2s
91:	learn: 0.6149003	total: 2.85s	remaining: 28.1s
92:	learn: 0.6113320	total: 2.89s	remaining: 28.2s
93:	learn: 0.6099617	total: 2.93s	remaining: 28.2s
94:	learn: 0.6053848	total: 2.97s	remaining: 28.3s
95:	learn: 0.6041318	total: 3s	remaining: 28.2s
96:	learn: 0.5998814	total: 3.03s	remaining: 28.2s
97:	learn: 0.5979437	total: 3.07s	remaining: 28.2s
98:	learn: 0.5948963	total: 3.1s	remaining: 28.2s
99:	learn: 0.5913936	total: 3.13s	remaining: 28.2s
100:	learn: 0.5892143	total: 3.17s	remaining: 28.2s
101:	learn: 0.5851459	total: 3.2s	remaining: 28.2s
102:	learn: 0.5814098	total: 3.24s	remaining: 28.2s
103:	learn: 0.5794016	total: 3.27s	remaining: 28.2s
104:	learn: 0.5786100	total: 3.3s	remaining: 28.2s
105:	learn: 0.5740118	total: 3.34s	remaining: 28.1s
106:	learn: 0.5705494	total: 3.37s	remaining: 28.1s
107:	learn: 0.5659706	total: 3.4s	remaining: 28.1s
108:	learn: 0.5622656	total: 3.44s	remaining: 28.1s
109:	learn: 0.5584300	total: 3.47s	remaining: 28.1s
110:	learn: 0.5542700	total: 3.5s	remaining: 28.1s
111:	learn: 0.5516312	total: 3.54s	remaining: 28s
112:	learn: 0.5484030	total: 3.57s	remaining: 28s
113:	learn: 0.5448663	total: 3.6s	remaining: 28s
114:	learn: 0.5426432	total: 3.64s	remaining: 28s
115:	learn: 0.5390481	total: 3.67s	remaining: 28s
116:	learn: 0.5353399	total: 3.7s	remaining: 27.9s
117:	learn: 0.5325920	total: 3.73s	remaining: 27.9s
118:	learn: 0.5296122	total: 3.77s	remaining: 27.9s
119:	learn: 0.5272495	total: 3.8s	remaining: 27.9s
120:	learn: 0.5246805	total: 3.83s	remaining: 27.8s
121:	learn: 0.5226248	total: 3.87s	remaining: 27.8s
122:	learn: 0.5203209	total: 3.9s	remaining: 27.8s
123:	learn: 0.5186574	total: 3.93s	remaining: 27.8s
124:	learn: 0.5159524	total: 3.97s	remaining: 27.8s
125:	learn: 0.5137200	total: 4s	remaining: 27.7s
126:	learn: 0.5118413	total: 4.03s	remaining: 27.7s
127:	learn: 0.5102272	total: 4.07s	remaining: 27.7s
128:	learn: 0.5071532	total: 4.1s	remaining: 27.7s
129:	learn: 0.5055315	total: 4.14s	remaining: 27.7s
130:	learn: 0.5021230	total: 4.18s	remaining: 27.7s
131:	learn: 0.4989840	total: 4.21s	remaining: 27.7s
132:	learn: 0.4965386	total: 4.25s	remaining: 27.7s
133:	learn: 0.4939817	total: 4.28s	remaining: 27.7s
134:	learn: 0.4920576	total: 4.31s	remaining: 27.6s
135:	learn: 0.4883103	total: 4.34s	remaining: 27.6s
136:	learn: 0.4879700	total: 4.36s	remaining: 27.5s
137:	learn: 0.4865358	total: 4.4s	remaining: 27.5s
138:	learn: 0.4825338	total: 4.43s	remaining: 27.4s
139:	learn: 0.4799216	total: 4.45s	remaining: 27.3s
140:	learn: 0.4789413	total: 4.48s	remaining: 27.3s
141:	learn: 0.4756981	total: 4.51s	remaining: 27.3s
142:	learn: 0.4729161	total: 4.54s	remaining: 27.2s
143:	learn: 0.4692659	total: 4.58s	remaining: 27.2s
144:	learn: 0.4661665	total: 4.61s	remaining: 27.2s
145:	learn: 0.4623115	total: 4.63s	remaining: 27.1s
146:	learn: 0.4599190	total: 4.67s	remaining: 27.1s
147:	learn: 0.4581873	total: 4.69s	remaining: 27s
148:	learn: 0.4555122	total: 4.72s	remaining: 27s
149:	learn: 0.4539440	total: 4.76s	remaining: 27s
150:	learn: 0.4502301	total: 4.78s	remaining: 26.9s
151:	learn: 0.4485769	total: 4.81s	remaining: 26.8s
152:	learn: 0.4470171	total: 4.83s	remaining: 26.8s
153:	learn: 0.4440567	total: 4.86s	remaining: 26.7s
154:	learn: 0.4411510	total: 4.9s	remaining: 26.7s
155:	learn: 0.4390313	total: 4.94s	remaining: 26.7s
156:	learn: 0.4357344	total: 4.96s	remaining: 26.6s
157:	learn: 0.4321915	total: 4.99s	remaining: 26.6s
158:	learn: 0.4283503	total: 5.01s	remaining: 26.5s
159:	learn: 0.4261866	total: 5.04s	remaining: 26.5s
160:	learn: 0.4226257	total: 5.08s	remaining: 26.5s
161:	learn: 0.4208977	total: 5.11s	remaining: 26.4s
162:	learn: 0.4182079	total: 5.14s	remaining: 26.4s
163:	learn: 0.4154692	total: 5.16s	remaining: 26.3s
164:	learn: 0.4127583	total: 5.19s	remaining: 26.3s
165:	learn: 0.4086458	total: 5.22s	remaining: 26.2s
166:	learn: 0.4066359	total: 5.25s	remaining: 26.2s
167:	learn: 0.4043998	total: 5.27s	remaining: 26.1s
168:	learn: 0.4007233	total: 5.31s	remaining: 26.1s
169:	learn: 0.3983562	total: 5.33s	remaining: 26s
170:	learn: 0.3951276	total: 5.36s	remaining: 26s
171:	learn: 0.3915552	total: 5.39s	remaining: 26s
172:	learn: 0.3891201	total: 5.43s	remaining: 25.9s
173:	learn: 0.3861103	total: 5.46s	remaining: 25.9s
174:	learn: 0.3846304	total: 5.49s	remaining: 25.9s
175:	learn: 0.3822930	total: 5.53s	remaining: 25.9s
176:	learn: 0.3799912	total: 5.56s	remaining: 25.9s
177:	learn: 0.3773550	total: 5.6s	remaining: 25.8s
178:	learn: 0.3757668	total: 5.63s	remaining: 25.8s
179:	learn: 0.3739229	total: 5.66s	remaining: 25.8s
180:	learn: 0.3717611	total: 5.7s	remaining: 25.8s
181:	learn: 0.3696486	total: 5.74s	remaining: 25.8s
182:	learn: 0.3666402	total: 5.77s	remaining: 25.8s
183:	learn: 0.3643123	total: 5.8s	remaining: 25.7s
184:	learn: 0.3627996	total: 5.84s	remaining: 25.7s
185:	learn: 0.3595438	total: 5.87s	remaining: 25.7s
186:	learn: 0.3577720	total: 5.9s	remaining: 25.7s
187:	learn: 0.3567260	total: 5.94s	remaining: 25.7s
188:	learn: 0.3544489	total: 5.97s	remaining: 25.6s
189:	learn: 0.3519729	total: 6.01s	remaining: 25.6s
190:	learn: 0.3488986	total: 6.04s	remaining: 25.6s
191:	learn: 0.3462823	total: 6.08s	remaining: 25.6s
192:	learn: 0.3433277	total: 6.11s	remaining: 25.6s
193:	learn: 0.3409999	total: 6.16s	remaining: 25.6s
194:	learn: 0.3380512	total: 6.2s	remaining: 25.6s
195:	learn: 0.3366555	total: 6.23s	remaining: 25.5s
196:	learn: 0.3343454	total: 6.26s	remaining: 25.5s
197:	learn: 0.3322994	total: 6.3s	remaining: 25.5s
198:	learn: 0.3293948	total: 6.34s	remaining: 25.5s
199:	learn: 0.3261335	total: 6.37s	remaining: 25.5s
200:	learn: 0.3240543	total: 6.4s	remaining: 25.4s
201:	learn: 0.3207945	total: 6.43s	remaining: 25.4s
202:	learn: 0.3186033	total: 6.47s	remaining: 25.4s
203:	learn: 0.3170521	total: 6.5s	remaining: 25.4s
204:	learn: 0.3145409	total: 6.53s	remaining: 25.3s
205:	learn: 0.3122076	total: 6.57s	remaining: 25.3s
206:	learn: 0.3097760	total: 6.6s	remaining: 25.3s
207:	learn: 0.3073862	total: 6.63s	remaining: 25.2s
208:	learn: 0.3048666	total: 6.66s	remaining: 25.2s
209:	learn: 0.3018579	total: 6.69s	remaining: 25.2s
210:	learn: 0.2988348	total: 6.71s	remaining: 25.1s
211:	learn: 0.2961872	total: 6.74s	remaining: 25.1s
212:	learn: 0.2941806	total: 6.77s	remaining: 25s
213:	learn: 0.2915386	total: 6.79s	remaining: 25s
214:	learn: 0.2895515	total: 6.82s	remaining: 24.9s
215:	learn: 0.2872945	total: 6.85s	remaining: 24.9s
216:	learn: 0.2850045	total: 6.89s	remaining: 24.9s
217:	learn: 0.2820487	total: 6.92s	remaining: 24.8s
218:	learn: 0.2795618	total: 6.95s	remaining: 24.8s
219:	learn: 0.2770582	total: 6.98s	remaining: 24.7s
220:	learn: 0.2740465	total: 7.01s	remaining: 24.7s
221:	learn: 0.2726103	total: 7.03s	remaining: 24.7s
222:	learn: 0.2697995	total: 7.06s	remaining: 24.6s
223:	learn: 0.2676370	total: 7.09s	remaining: 24.5s
224:	learn: 0.2652270	total: 7.11s	remaining: 24.5s
225:	learn: 0.2630053	total: 7.14s	remaining: 24.5s
226:	learn: 0.2612070	total: 7.17s	remaining: 24.4s
227:	learn: 0.2588111	total: 7.19s	remaining: 24.4s
228:	learn: 0.2567080	total: 7.22s	remaining: 24.3s
229:	learn: 0.2548331	total: 7.25s	remaining: 24.3s
230:	learn: 0.2522747	total: 7.28s	remaining: 24.2s
231:	learn: 0.2501303	total: 7.3s	remaining: 24.2s
232:	learn: 0.2481335	total: 7.33s	remaining: 24.1s
233:	learn: 0.2458372	total: 7.37s	remaining: 24.1s
234:	learn: 0.2433569	total: 7.39s	remaining: 24.1s
235:	learn: 0.2408155	total: 7.43s	remaining: 24.1s
236:	learn: 0.2387954	total: 7.46s	remaining: 24s
237:	learn: 0.2366492	total: 7.49s	remaining: 24s
238:	learn: 0.2347191	total: 7.52s	remaining: 24s
239:	learn: 0.2321625	total: 7.55s	remaining: 23.9s
240:	learn: 0.2303250	total: 7.59s	remaining: 23.9s
241:	learn: 0.2284321	total: 7.62s	remaining: 23.9s
242:	learn: 0.2262101	total: 7.64s	remaining: 23.8s
243:	learn: 0.2234519	total: 7.67s	remaining: 23.8s
244:	learn: 0.2214193	total: 7.69s	remaining: 23.7s
245:	learn: 0.2191392	total: 7.72s	remaining: 23.7s
246:	learn: 0.2173451	total: 7.75s	remaining: 23.6s
247:	learn: 0.2154421	total: 7.77s	remaining: 23.6s
248:	learn: 0.2134998	total: 7.81s	remaining: 23.5s
249:	learn: 0.2117322	total: 7.83s	remaining: 23.5s
250:	learn: 0.2099662	total: 7.86s	remaining: 23.4s
251:	learn: 0.2078987	total: 7.88s	remaining: 23.4s
252:	learn: 0.2060407	total: 7.92s	remaining: 23.4s
253:	learn: 0.2035928	total: 7.94s	remaining: 23.3s
254:	learn: 0.2015918	total: 7.96s	remaining: 23.3s
255:	learn: 0.1993914	total: 7.98s	remaining: 23.2s
256:	learn: 0.1972249	total: 8.01s	remaining: 23.2s
257:	learn: 0.1955657	total: 8.03s	remaining: 23.1s
258:	learn: 0.1936264	total: 8.06s	remaining: 23.1s
259:	learn: 0.1914551	total: 8.09s	remaining: 23s
260:	learn: 0.1901158	total: 8.11s	remaining: 23s
261:	learn: 0.1884684	total: 8.14s	remaining: 22.9s
262:	learn: 0.1868376	total: 8.16s	remaining: 22.9s
263:	learn: 0.1849677	total: 8.18s	remaining: 22.8s
264:	learn: 0.1830579	total: 8.2s	remaining: 22.8s
265:	learn: 0.1812295	total: 8.23s	remaining: 22.7s
266:	learn: 0.1799925	total: 8.25s	remaining: 22.6s
267:	learn: 0.1781326	total: 8.28s	remaining: 22.6s
268:	learn: 0.1761545	total: 8.3s	remaining: 22.6s
269:	learn: 0.1744257	total: 8.32s	remaining: 22.5s
270:	learn: 0.1725286	total: 8.35s	remaining: 22.5s
271:	learn: 0.1709992	total: 8.37s	remaining: 22.4s
272:	learn: 0.1693311	total: 8.39s	remaining: 22.4s
273:	learn: 0.1675519	total: 8.42s	remaining: 22.3s
274:	learn: 0.1659912	total: 8.44s	remaining: 22.3s
275:	learn: 0.1644473	total: 8.47s	remaining: 22.2s
276:	learn: 0.1627547	total: 8.49s	remaining: 22.2s
277:	learn: 0.1611844	total: 8.52s	remaining: 22.1s
278:	learn: 0.1596301	total: 8.54s	remaining: 22.1s
279:	learn: 0.1582434	total: 8.57s	remaining: 22s
280:	learn: 0.1567248	total: 8.59s	remaining: 22s
281:	learn: 0.1549493	total: 8.62s	remaining: 22s
282:	learn: 0.1534262	total: 8.64s	remaining: 21.9s
283:	learn: 0.1518935	total: 8.67s	remaining: 21.9s
284:	learn: 0.1505742	total: 8.69s	remaining: 21.8s
285:	learn: 0.1492976	total: 8.71s	remaining: 21.8s
286:	learn: 0.1478710	total: 8.74s	remaining: 21.7s
287:	learn: 0.1463323	total: 8.76s	remaining: 21.7s
288:	learn: 0.1447181	total: 8.79s	remaining: 21.6s
289:	learn: 0.1431876	total: 8.81s	remaining: 21.6s
290:	learn: 0.1418499	total: 8.83s	remaining: 21.5s
291:	learn: 0.1404011	total: 8.86s	remaining: 21.5s
292:	learn: 0.1392361	total: 8.88s	remaining: 21.4s
293:	learn: 0.1378780	total: 8.9s	remaining: 21.4s
294:	learn: 0.1367025	total: 8.93s	remaining: 21.3s
295:	learn: 0.1353306	total: 8.95s	remaining: 21.3s
296:	learn: 0.1340911	total: 8.98s	remaining: 21.2s
297:	learn: 0.1327823	total: 9s	remaining: 21.2s
298:	learn: 0.1315189	total: 9.03s	remaining: 21.2s
299:	learn: 0.1302096	total: 9.06s	remaining: 21.1s
300:	learn: 0.1289949	total: 9.09s	remaining: 21.1s
301:	learn: 0.1278089	total: 9.11s	remaining: 21.1s
302:	learn: 0.1264399	total: 9.14s	remaining: 21s
303:	learn: 0.1251026	total: 9.16s	remaining: 21s
304:	learn: 0.1238733	total: 9.18s	remaining: 20.9s
305:	learn: 0.1225712	total: 9.21s	remaining: 20.9s
306:	learn: 0.1212706	total: 9.24s	remaining: 20.8s
307:	learn: 0.1200813	total: 9.27s	remaining: 20.8s
308:	learn: 0.1188087	total: 9.3s	remaining: 20.8s
309:	learn: 0.1179328	total: 9.32s	remaining: 20.8s
310:	learn: 0.1169843	total: 9.35s	remaining: 20.7s
311:	learn: 0.1160896	total: 9.38s	remaining: 20.7s
312:	learn: 0.1150015	total: 9.4s	remaining: 20.6s
313:	learn: 0.1138192	total: 9.42s	remaining: 20.6s
314:	learn: 0.1130930	total: 9.45s	remaining: 20.5s
315:	learn: 0.1120127	total: 9.47s	remaining: 20.5s
316:	learn: 0.1109125	total: 9.5s	remaining: 20.5s
317:	learn: 0.1097676	total: 9.52s	remaining: 20.4s
318:	learn: 0.1084586	total: 9.54s	remaining: 20.4s
319:	learn: 0.1074592	total: 9.57s	remaining: 20.3s
320:	learn: 0.1063062	total: 9.59s	remaining: 20.3s
321:	learn: 0.1053850	total: 9.62s	remaining: 20.3s
322:	learn: 0.1045262	total: 9.64s	remaining: 20.2s
323:	learn: 0.1033246	total: 9.68s	remaining: 20.2s
324:	learn: 0.1023137	total: 9.71s	remaining: 20.2s
325:	learn: 0.1013269	total: 9.73s	remaining: 20.1s
326:	learn: 0.1002801	total: 9.75s	remaining: 20.1s
327:	learn: 0.0994319	total: 9.77s	remaining: 20s
328:	learn: 0.0983556	total: 9.79s	remaining: 20s
329:	learn: 0.0975180	total: 9.82s	remaining: 19.9s
330:	learn: 0.0965570	total: 9.84s	remaining: 19.9s
331:	learn: 0.0956769	total: 9.87s	remaining: 19.9s
332:	learn: 0.0949069	total: 9.89s	remaining: 19.8s
333:	learn: 0.0939404	total: 9.92s	remaining: 19.8s
334:	learn: 0.0929886	total: 9.95s	remaining: 19.7s
335:	learn: 0.0920485	total: 9.97s	remaining: 19.7s
336:	learn: 0.0912079	total: 9.99s	remaining: 19.7s
337:	learn: 0.0903404	total: 10s	remaining: 19.6s
338:	learn: 0.0896099	total: 10s	remaining: 19.6s
339:	learn: 0.0887647	total: 10.1s	remaining: 19.5s
340:	learn: 0.0878882	total: 10.1s	remaining: 19.5s
341:	learn: 0.0869981	total: 10.1s	remaining: 19.5s
342:	learn: 0.0859771	total: 10.1s	remaining: 19.4s
343:	learn: 0.0855027	total: 10.2s	remaining: 19.4s
344:	learn: 0.0847807	total: 10.2s	remaining: 19.3s
345:	learn: 0.0839566	total: 10.2s	remaining: 19.3s
346:	learn: 0.0832726	total: 10.2s	remaining: 19.3s
347:	learn: 0.0824607	total: 10.3s	remaining: 19.2s
348:	learn: 0.0816213	total: 10.3s	remaining: 19.2s
349:	learn: 0.0809092	total: 10.3s	remaining: 19.1s
350:	learn: 0.0799833	total: 10.3s	remaining: 19.1s
351:	learn: 0.0791065	total: 10.3s	remaining: 19.1s
352:	learn: 0.0783666	total: 10.4s	remaining: 19s
353:	learn: 0.0776928	total: 10.4s	remaining: 19s
354:	learn: 0.0769574	total: 10.4s	remaining: 19s
355:	learn: 0.0762160	total: 10.5s	remaining: 18.9s
356:	learn: 0.0755102	total: 10.5s	remaining: 18.9s
357:	learn: 0.0747448	total: 10.5s	remaining: 18.9s
358:	learn: 0.0741246	total: 10.6s	remaining: 18.8s
359:	learn: 0.0733946	total: 10.6s	remaining: 18.8s
360:	learn: 0.0724949	total: 10.6s	remaining: 18.8s
361:	learn: 0.0717174	total: 10.7s	remaining: 18.8s
362:	learn: 0.0710336	total: 10.7s	remaining: 18.8s
363:	learn: 0.0704690	total: 10.7s	remaining: 18.7s
364:	learn: 0.0701249	total: 10.8s	remaining: 18.7s
365:	learn: 0.0696067	total: 10.8s	remaining: 18.7s
366:	learn: 0.0689159	total: 10.8s	remaining: 18.7s
367:	learn: 0.0682374	total: 10.9s	remaining: 18.6s
368:	learn: 0.0676548	total: 10.9s	remaining: 18.6s
369:	learn: 0.0669973	total: 10.9s	remaining: 18.6s
370:	learn: 0.0663771	total: 10.9s	remaining: 18.6s
371:	learn: 0.0658640	total: 11s	remaining: 18.5s
372:	learn: 0.0653304	total: 11s	remaining: 18.5s
373:	learn: 0.0646237	total: 11.1s	remaining: 18.5s
374:	learn: 0.0639367	total: 11.1s	remaining: 18.5s
375:	learn: 0.0633009	total: 11.1s	remaining: 18.5s
376:	learn: 0.0626127	total: 11.2s	remaining: 18.4s
377:	learn: 0.0621748	total: 11.2s	remaining: 18.4s
378:	learn: 0.0614995	total: 11.2s	remaining: 18.4s
379:	learn: 0.0608722	total: 11.3s	remaining: 18.4s
380:	learn: 0.0603792	total: 11.3s	remaining: 18.3s
381:	learn: 0.0598900	total: 11.3s	remaining: 18.3s
382:	learn: 0.0593092	total: 11.4s	remaining: 18.3s
383:	learn: 0.0587882	total: 11.4s	remaining: 18.3s
384:	learn: 0.0582486	total: 11.4s	remaining: 18.2s
385:	learn: 0.0576687	total: 11.5s	remaining: 18.2s
386:	learn: 0.0569898	total: 11.5s	remaining: 18.2s
387:	learn: 0.0564511	total: 11.5s	remaining: 18.2s
388:	learn: 0.0561377	total: 11.6s	remaining: 18.1s
389:	learn: 0.0557695	total: 11.6s	remaining: 18.1s
390:	learn: 0.0551489	total: 11.6s	remaining: 18.1s
391:	learn: 0.0548916	total: 11.7s	remaining: 18.1s
392:	learn: 0.0543210	total: 11.7s	remaining: 18s
393:	learn: 0.0538787	total: 11.7s	remaining: 18s
394:	learn: 0.0533676	total: 11.7s	remaining: 18s
395:	learn: 0.0529050	total: 11.8s	remaining: 18s
396:	learn: 0.0524421	total: 11.8s	remaining: 17.9s
397:	learn: 0.0519410	total: 11.8s	remaining: 17.9s
398:	learn: 0.0514688	total: 11.9s	remaining: 17.9s
399:	learn: 0.0510928	total: 11.9s	remaining: 17.9s
400:	learn: 0.0506091	total: 11.9s	remaining: 17.8s
401:	learn: 0.0503853	total: 12s	remaining: 17.8s
402:	learn: 0.0498861	total: 12s	remaining: 17.8s
403:	learn: 0.0493367	total: 12s	remaining: 17.7s
404:	learn: 0.0489047	total: 12.1s	remaining: 17.7s
405:	learn: 0.0484749	total: 12.1s	remaining: 17.7s
406:	learn: 0.0480016	total: 12.1s	remaining: 17.7s
407:	learn: 0.0475348	total: 12.2s	remaining: 17.6s
408:	learn: 0.0470015	total: 12.2s	remaining: 17.6s
409:	learn: 0.0464966	total: 12.2s	remaining: 17.6s
410:	learn: 0.0461022	total: 12.3s	remaining: 17.6s
411:	learn: 0.0455941	total: 12.3s	remaining: 17.5s
412:	learn: 0.0451307	total: 12.3s	remaining: 17.5s
413:	learn: 0.0448100	total: 12.4s	remaining: 17.5s
414:	learn: 0.0443863	total: 12.4s	remaining: 17.5s
415:	learn: 0.0439357	total: 12.4s	remaining: 17.5s
416:	learn: 0.0435271	total: 12.5s	remaining: 17.4s
417:	learn: 0.0430870	total: 12.5s	remaining: 17.4s
418:	learn: 0.0426909	total: 12.5s	remaining: 17.4s
419:	learn: 0.0424721	total: 12.6s	remaining: 17.3s
420:	learn: 0.0421125	total: 12.6s	remaining: 17.3s
421:	learn: 0.0417187	total: 12.6s	remaining: 17.3s
422:	learn: 0.0415370	total: 12.7s	remaining: 17.3s
423:	learn: 0.0410456	total: 12.7s	remaining: 17.2s
424:	learn: 0.0406742	total: 12.7s	remaining: 17.2s
425:	learn: 0.0402943	total: 12.8s	remaining: 17.2s
426:	learn: 0.0401367	total: 12.8s	remaining: 17.2s
427:	learn: 0.0397107	total: 12.8s	remaining: 17.1s
428:	learn: 0.0393625	total: 12.9s	remaining: 17.1s
429:	learn: 0.0389634	total: 12.9s	remaining: 17.1s
430:	learn: 0.0385542	total: 12.9s	remaining: 17.1s
431:	learn: 0.0381381	total: 13s	remaining: 17s
432:	learn: 0.0377920	total: 13s	remaining: 17s
433:	learn: 0.0373697	total: 13s	remaining: 17s
434:	learn: 0.0369810	total: 13.1s	remaining: 17s
435:	learn: 0.0366902	total: 13.1s	remaining: 16.9s
436:	learn: 0.0363980	total: 13.1s	remaining: 16.9s
437:	learn: 0.0360205	total: 13.2s	remaining: 16.9s
438:	learn: 0.0357269	total: 13.2s	remaining: 16.9s
439:	learn: 0.0354368	total: 13.2s	remaining: 16.8s
440:	learn: 0.0350574	total: 13.3s	remaining: 16.8s
441:	learn: 0.0347708	total: 13.3s	remaining: 16.8s
442:	learn: 0.0344196	total: 13.3s	remaining: 16.8s
443:	learn: 0.0340742	total: 13.4s	remaining: 16.7s
444:	learn: 0.0337757	total: 13.4s	remaining: 16.7s
445:	learn: 0.0334375	total: 13.4s	remaining: 16.7s
446:	learn: 0.0331454	total: 13.5s	remaining: 16.7s
447:	learn: 0.0328313	total: 13.5s	remaining: 16.6s
448:	learn: 0.0325355	total: 13.5s	remaining: 16.6s
449:	learn: 0.0321605	total: 13.6s	remaining: 16.6s
450:	learn: 0.0318400	total: 13.6s	remaining: 16.6s
451:	learn: 0.0317233	total: 13.6s	remaining: 16.5s
452:	learn: 0.0314163	total: 13.7s	remaining: 16.5s
453:	learn: 0.0311102	total: 13.7s	remaining: 16.5s
454:	learn: 0.0308475	total: 13.7s	remaining: 16.5s
455:	learn: 0.0305336	total: 13.8s	remaining: 16.4s
456:	learn: 0.0302610	total: 13.8s	remaining: 16.4s
457:	learn: 0.0301320	total: 13.8s	remaining: 16.4s
458:	learn: 0.0299532	total: 13.9s	remaining: 16.4s
459:	learn: 0.0296811	total: 13.9s	remaining: 16.3s
460:	learn: 0.0293373	total: 13.9s	remaining: 16.3s
461:	learn: 0.0290798	total: 14s	remaining: 16.3s
462:	learn: 0.0287918	total: 14s	remaining: 16.3s
463:	learn: 0.0286129	total: 14.1s	remaining: 16.2s
464:	learn: 0.0283761	total: 14.1s	remaining: 16.2s
465:	learn: 0.0281030	total: 14.1s	remaining: 16.2s
466:	learn: 0.0278895	total: 14.2s	remaining: 16.2s
467:	learn: 0.0276632	total: 14.2s	remaining: 16.1s
468:	learn: 0.0273835	total: 14.2s	remaining: 16.1s
469:	learn: 0.0271186	total: 14.3s	remaining: 16.1s
470:	learn: 0.0269491	total: 14.3s	remaining: 16.1s
471:	learn: 0.0266750	total: 14.3s	remaining: 16s
472:	learn: 0.0264467	total: 14.4s	remaining: 16s
473:	learn: 0.0261464	total: 14.4s	remaining: 16s
474:	learn: 0.0258946	total: 14.4s	remaining: 15.9s
475:	learn: 0.0257811	total: 14.5s	remaining: 15.9s
476:	learn: 0.0255851	total: 14.5s	remaining: 15.9s
477:	learn: 0.0253084	total: 14.5s	remaining: 15.9s
478:	learn: 0.0250397	total: 14.6s	remaining: 15.8s
479:	learn: 0.0248240	total: 14.6s	remaining: 15.8s
480:	learn: 0.0247162	total: 14.6s	remaining: 15.8s
481:	learn: 0.0244699	total: 14.7s	remaining: 15.8s
482:	learn: 0.0242265	total: 14.7s	remaining: 15.7s
483:	learn: 0.0239919	total: 14.7s	remaining: 15.7s
484:	learn: 0.0238813	total: 14.8s	remaining: 15.7s
485:	learn: 0.0236432	total: 14.8s	remaining: 15.7s
486:	learn: 0.0234402	total: 14.8s	remaining: 15.6s
487:	learn: 0.0231865	total: 14.9s	remaining: 15.6s
488:	learn: 0.0229340	total: 14.9s	remaining: 15.6s
489:	learn: 0.0227259	total: 14.9s	remaining: 15.5s
490:	learn: 0.0224840	total: 15s	remaining: 15.5s
491:	learn: 0.0223563	total: 15s	remaining: 15.5s
492:	learn: 0.0221397	total: 15s	remaining: 15.5s
493:	learn: 0.0218798	total: 15.1s	remaining: 15.4s
494:	learn: 0.0216510	total: 15.1s	remaining: 15.4s
495:	learn: 0.0215414	total: 15.1s	remaining: 15.4s
496:	learn: 0.0214845	total: 15.2s	remaining: 15.3s
497:	learn: 0.0212990	total: 15.2s	remaining: 15.3s
498:	learn: 0.0211101	total: 15.2s	remaining: 15.3s
499:	learn: 0.0210159	total: 15.3s	remaining: 15.3s
500:	learn: 0.0208713	total: 15.3s	remaining: 15.2s
501:	learn: 0.0206891	total: 15.3s	remaining: 15.2s
502:	learn: 0.0204826	total: 15.4s	remaining: 15.2s
503:	learn: 0.0202869	total: 15.4s	remaining: 15.2s
504:	learn: 0.0201121	total: 15.4s	remaining: 15.1s
505:	learn: 0.0198858	total: 15.5s	remaining: 15.1s
506:	learn: 0.0196804	total: 15.5s	remaining: 15.1s
507:	learn: 0.0194951	total: 15.5s	remaining: 15s
508:	learn: 0.0192994	total: 15.6s	remaining: 15s
509:	learn: 0.0190886	total: 15.6s	remaining: 15s
510:	learn: 0.0188972	total: 15.6s	remaining: 15s
511:	learn: 0.0188111	total: 15.7s	remaining: 14.9s
512:	learn: 0.0186416	total: 15.7s	remaining: 14.9s
513:	learn: 0.0184610	total: 15.7s	remaining: 14.9s
514:	learn: 0.0182793	total: 15.8s	remaining: 14.9s
515:	learn: 0.0181669	total: 15.8s	remaining: 14.8s
516:	learn: 0.0181052	total: 15.8s	remaining: 14.8s
517:	learn: 0.0179984	total: 15.9s	remaining: 14.8s
518:	learn: 0.0179165	total: 15.9s	remaining: 14.7s
519:	learn: 0.0177382	total: 15.9s	remaining: 14.7s
520:	learn: 0.0175508	total: 16s	remaining: 14.7s
521:	learn: 0.0173734	total: 16s	remaining: 14.7s
522:	learn: 0.0172217	total: 16s	remaining: 14.6s
523:	learn: 0.0171379	total: 16.1s	remaining: 14.6s
524:	learn: 0.0169723	total: 16.1s	remaining: 14.6s
525:	learn: 0.0168211	total: 16.1s	remaining: 14.5s
526:	learn: 0.0166708	total: 16.2s	remaining: 14.5s
527:	learn: 0.0166129	total: 16.2s	remaining: 14.5s
528:	learn: 0.0164509	total: 16.2s	remaining: 14.5s
529:	learn: 0.0162811	total: 16.3s	remaining: 14.4s
530:	learn: 0.0161243	total: 16.3s	remaining: 14.4s
531:	learn: 0.0159785	total: 16.4s	remaining: 14.4s
532:	learn: 0.0159356	total: 16.4s	remaining: 14.4s
533:	learn: 0.0157590	total: 16.4s	remaining: 14.3s
534:	learn: 0.0155987	total: 16.4s	remaining: 14.3s
535:	learn: 0.0155473	total: 16.5s	remaining: 14.3s
536:	learn: 0.0154003	total: 16.5s	remaining: 14.2s
537:	learn: 0.0152541	total: 16.5s	remaining: 14.2s
538:	learn: 0.0150881	total: 16.6s	remaining: 14.2s
539:	learn: 0.0149467	total: 16.6s	remaining: 14.2s
540:	learn: 0.0148835	total: 16.6s	remaining: 14.1s
541:	learn: 0.0147302	total: 16.7s	remaining: 14.1s
542:	learn: 0.0145889	total: 16.7s	remaining: 14.1s
543:	learn: 0.0145063	total: 16.7s	remaining: 14s
544:	learn: 0.0144614	total: 16.8s	remaining: 14s
545:	learn: 0.0143140	total: 16.8s	remaining: 14s
546:	learn: 0.0142654	total: 16.8s	remaining: 13.9s
547:	learn: 0.0141182	total: 16.9s	remaining: 13.9s
548:	learn: 0.0140853	total: 16.9s	remaining: 13.9s
549:	learn: 0.0139504	total: 16.9s	remaining: 13.9s
550:	learn: 0.0138224	total: 17s	remaining: 13.8s
551:	learn: 0.0137056	total: 17s	remaining: 13.8s
552:	learn: 0.0135755	total: 17s	remaining: 13.8s
553:	learn: 0.0134346	total: 17.1s	remaining: 13.7s
554:	learn: 0.0132970	total: 17.1s	remaining: 13.7s
555:	learn: 0.0131930	total: 17.1s	remaining: 13.7s
556:	learn: 0.0130392	total: 17.2s	remaining: 13.7s
557:	learn: 0.0129011	total: 17.2s	remaining: 13.6s
558:	learn: 0.0128599	total: 17.2s	remaining: 13.6s
559:	learn: 0.0128009	total: 17.2s	remaining: 13.6s
560:	learn: 0.0127254	total: 17.3s	remaining: 13.5s
561:	learn: 0.0125951	total: 17.3s	remaining: 13.5s
562:	learn: 0.0125509	total: 17.3s	remaining: 13.4s
563:	learn: 0.0125103	total: 17.4s	remaining: 13.4s
564:	learn: 0.0123849	total: 17.4s	remaining: 13.4s
565:	learn: 0.0123508	total: 17.4s	remaining: 13.3s
566:	learn: 0.0122295	total: 17.4s	remaining: 13.3s
567:	learn: 0.0121239	total: 17.5s	remaining: 13.3s
568:	learn: 0.0119945	total: 17.5s	remaining: 13.3s
569:	learn: 0.0118701	total: 17.5s	remaining: 13.2s
570:	learn: 0.0117649	total: 17.6s	remaining: 13.2s
571:	learn: 0.0116906	total: 17.6s	remaining: 13.2s
572:	learn: 0.0115858	total: 17.6s	remaining: 13.1s
573:	learn: 0.0114713	total: 17.6s	remaining: 13.1s
574:	learn: 0.0113572	total: 17.7s	remaining: 13.1s
575:	learn: 0.0112329	total: 17.7s	remaining: 13s
576:	learn: 0.0111185	total: 17.7s	remaining: 13s
577:	learn: 0.0110062	total: 17.8s	remaining: 13s
578:	learn: 0.0109137	total: 17.8s	remaining: 12.9s
579:	learn: 0.0108243	total: 17.8s	remaining: 12.9s
580:	learn: 0.0107812	total: 17.9s	remaining: 12.9s
581:	learn: 0.0107445	total: 17.9s	remaining: 12.8s
582:	learn: 0.0106383	total: 17.9s	remaining: 12.8s
583:	learn: 0.0105534	total: 17.9s	remaining: 12.8s
584:	learn: 0.0104400	total: 18s	remaining: 12.7s
585:	learn: 0.0103796	total: 18s	remaining: 12.7s
586:	learn: 0.0103141	total: 18s	remaining: 12.7s
587:	learn: 0.0102744	total: 18.1s	remaining: 12.7s
588:	learn: 0.0101700	total: 18.1s	remaining: 12.6s
589:	learn: 0.0100564	total: 18.1s	remaining: 12.6s
590:	learn: 0.0099606	total: 18.1s	remaining: 12.6s
591:	learn: 0.0098676	total: 18.2s	remaining: 12.5s
592:	learn: 0.0098364	total: 18.2s	remaining: 12.5s
593:	learn: 0.0097456	total: 18.2s	remaining: 12.5s
594:	learn: 0.0096758	total: 18.3s	remaining: 12.4s
595:	learn: 0.0096014	total: 18.3s	remaining: 12.4s
596:	learn: 0.0095042	total: 18.3s	remaining: 12.4s
597:	learn: 0.0094251	total: 18.3s	remaining: 12.3s
598:	learn: 0.0093262	total: 18.4s	remaining: 12.3s
599:	learn: 0.0092288	total: 18.4s	remaining: 12.3s
600:	learn: 0.0091800	total: 18.4s	remaining: 12.2s
601:	learn: 0.0091030	total: 18.4s	remaining: 12.2s
602:	learn: 0.0090228	total: 18.5s	remaining: 12.2s
603:	learn: 0.0089205	total: 18.5s	remaining: 12.1s
604:	learn: 0.0088407	total: 18.5s	remaining: 12.1s
605:	learn: 0.0087696	total: 18.6s	remaining: 12.1s
606:	learn: 0.0086801	total: 18.6s	remaining: 12s
607:	learn: 0.0086242	total: 18.6s	remaining: 12s
608:	learn: 0.0085988	total: 18.6s	remaining: 12s
609:	learn: 0.0085615	total: 18.7s	remaining: 11.9s
610:	learn: 0.0084763	total: 18.7s	remaining: 11.9s
611:	learn: 0.0084453	total: 18.7s	remaining: 11.9s
612:	learn: 0.0084189	total: 18.8s	remaining: 11.9s
613:	learn: 0.0083612	total: 18.8s	remaining: 11.8s
614:	learn: 0.0082786	total: 18.8s	remaining: 11.8s
615:	learn: 0.0081889	total: 18.9s	remaining: 11.8s
616:	learn: 0.0081005	total: 18.9s	remaining: 11.7s
617:	learn: 0.0080235	total: 18.9s	remaining: 11.7s
618:	learn: 0.0079878	total: 19s	remaining: 11.7s
619:	learn: 0.0079108	total: 19s	remaining: 11.7s
620:	learn: 0.0078233	total: 19s	remaining: 11.6s
621:	learn: 0.0077863	total: 19.1s	remaining: 11.6s
622:	learn: 0.0077643	total: 19.1s	remaining: 11.6s
623:	learn: 0.0076936	total: 19.1s	remaining: 11.5s
624:	learn: 0.0076682	total: 19.2s	remaining: 11.5s
625:	learn: 0.0076033	total: 19.2s	remaining: 11.5s
626:	learn: 0.0075180	total: 19.2s	remaining: 11.4s
627:	learn: 0.0074399	total: 19.3s	remaining: 11.4s
628:	learn: 0.0073671	total: 19.3s	remaining: 11.4s
629:	learn: 0.0073236	total: 19.3s	remaining: 11.4s
630:	learn: 0.0072648	total: 19.4s	remaining: 11.3s
631:	learn: 0.0071973	total: 19.4s	remaining: 11.3s
632:	learn: 0.0071842	total: 19.4s	remaining: 11.3s
633:	learn: 0.0071220	total: 19.5s	remaining: 11.2s
634:	learn: 0.0070507	total: 19.5s	remaining: 11.2s
635:	learn: 0.0070290	total: 19.5s	remaining: 11.2s
636:	learn: 0.0069921	total: 19.6s	remaining: 11.1s
637:	learn: 0.0069385	total: 19.6s	remaining: 11.1s
638:	learn: 0.0069140	total: 19.6s	remaining: 11.1s
639:	learn: 0.0068461	total: 19.7s	remaining: 11.1s
640:	learn: 0.0067759	total: 19.7s	remaining: 11s
641:	learn: 0.0067513	total: 19.7s	remaining: 11s
642:	learn: 0.0066830	total: 19.8s	remaining: 11s
643:	learn: 0.0066140	total: 19.8s	remaining: 10.9s
644:	learn: 0.0065924	total: 19.8s	remaining: 10.9s
645:	learn: 0.0065374	total: 19.9s	remaining: 10.9s
646:	learn: 0.0065170	total: 19.9s	remaining: 10.9s
647:	learn: 0.0064848	total: 19.9s	remaining: 10.8s
648:	learn: 0.0064204	total: 20s	remaining: 10.8s
649:	learn: 0.0063673	total: 20s	remaining: 10.8s
650:	learn: 0.0063020	total: 20s	remaining: 10.7s
651:	learn: 0.0062367	total: 20.1s	remaining: 10.7s
652:	learn: 0.0061606	total: 20.1s	remaining: 10.7s
653:	learn: 0.0061344	total: 20.1s	remaining: 10.6s
654:	learn: 0.0060796	total: 20.1s	remaining: 10.6s
655:	learn: 0.0060276	total: 20.2s	remaining: 10.6s
656:	learn: 0.0059800	total: 20.2s	remaining: 10.5s
657:	learn: 0.0059198	total: 20.2s	remaining: 10.5s
658:	learn: 0.0058792	total: 20.3s	remaining: 10.5s
659:	learn: 0.0058603	total: 20.3s	remaining: 10.5s
660:	learn: 0.0058103	total: 20.3s	remaining: 10.4s
661:	learn: 0.0057638	total: 20.4s	remaining: 10.4s
662:	learn: 0.0057185	total: 20.4s	remaining: 10.4s
663:	learn: 0.0056586	total: 20.4s	remaining: 10.3s
664:	learn: 0.0056160	total: 20.5s	remaining: 10.3s
665:	learn: 0.0055538	total: 20.5s	remaining: 10.3s
666:	learn: 0.0055002	total: 20.5s	remaining: 10.2s
667:	learn: 0.0054628	total: 20.6s	remaining: 10.2s
668:	learn: 0.0054155	total: 20.6s	remaining: 10.2s
669:	learn: 0.0053977	total: 20.6s	remaining: 10.2s
670:	learn: 0.0053633	total: 20.6s	remaining: 10.1s
671:	learn: 0.0053053	total: 20.7s	remaining: 10.1s
672:	learn: 0.0052467	total: 20.7s	remaining: 10.1s
673:	learn: 0.0052123	total: 20.7s	remaining: 10s
674:	learn: 0.0051491	total: 20.8s	remaining: 10s
675:	learn: 0.0051120	total: 20.8s	remaining: 9.97s
676:	learn: 0.0050530	total: 20.8s	remaining: 9.94s
677:	learn: 0.0050026	total: 20.9s	remaining: 9.91s
678:	learn: 0.0049505	total: 20.9s	remaining: 9.88s
679:	learn: 0.0049220	total: 20.9s	remaining: 9.85s
680:	learn: 0.0049028	total: 21s	remaining: 9.82s
681:	learn: 0.0048888	total: 21s	remaining: 9.79s
682:	learn: 0.0048742	total: 21s	remaining: 9.76s
683:	learn: 0.0048318	total: 21.1s	remaining: 9.73s
684:	learn: 0.0048079	total: 21.1s	remaining: 9.7s
685:	learn: 0.0047587	total: 21.1s	remaining: 9.67s
686:	learn: 0.0047367	total: 21.2s	remaining: 9.64s
687:	learn: 0.0046993	total: 21.2s	remaining: 9.61s
688:	learn: 0.0046568	total: 21.2s	remaining: 9.58s
689:	learn: 0.0046002	total: 21.3s	remaining: 9.55s
690:	learn: 0.0045797	total: 21.3s	remaining: 9.52s
691:	learn: 0.0045639	total: 21.3s	remaining: 9.49s
692:	learn: 0.0045298	total: 21.4s	remaining: 9.46s
693:	learn: 0.0045025	total: 21.4s	remaining: 9.44s
694:	learn: 0.0044618	total: 21.4s	remaining: 9.41s
695:	learn: 0.0044188	total: 21.5s	remaining: 9.38s
696:	learn: 0.0043993	total: 21.5s	remaining: 9.35s
697:	learn: 0.0043469	total: 21.5s	remaining: 9.31s
698:	learn: 0.0043232	total: 21.6s	remaining: 9.28s
699:	learn: 0.0042777	total: 21.6s	remaining: 9.25s
700:	learn: 0.0042319	total: 21.6s	remaining: 9.22s
701:	learn: 0.0041965	total: 21.7s	remaining: 9.19s
702:	learn: 0.0041527	total: 21.7s	remaining: 9.16s
703:	learn: 0.0041221	total: 21.7s	remaining: 9.13s
704:	learn: 0.0040807	total: 21.8s	remaining: 9.1s
705:	learn: 0.0040451	total: 21.8s	remaining: 9.07s
706:	learn: 0.0040057	total: 21.8s	remaining: 9.04s
707:	learn: 0.0039635	total: 21.8s	remaining: 9.01s
708:	learn: 0.0039489	total: 21.9s	remaining: 8.98s
709:	learn: 0.0039076	total: 21.9s	remaining: 8.95s
710:	learn: 0.0038753	total: 21.9s	remaining: 8.92s
711:	learn: 0.0038359	total: 22s	remaining: 8.89s
712:	learn: 0.0038021	total: 22s	remaining: 8.86s
713:	learn: 0.0037846	total: 22s	remaining: 8.83s
714:	learn: 0.0037773	total: 22.1s	remaining: 8.8s
715:	learn: 0.0037428	total: 22.1s	remaining: 8.77s
716:	learn: 0.0037032	total: 22.1s	remaining: 8.73s
717:	learn: 0.0036583	total: 22.2s	remaining: 8.7s
718:	learn: 0.0036206	total: 22.2s	remaining: 8.67s
719:	learn: 0.0035860	total: 22.2s	remaining: 8.64s
720:	learn: 0.0035462	total: 22.3s	remaining: 8.61s
721:	learn: 0.0035105	total: 22.3s	remaining: 8.58s
722:	learn: 0.0034802	total: 22.3s	remaining: 8.55s
723:	learn: 0.0034604	total: 22.4s	remaining: 8.52s
724:	learn: 0.0034287	total: 22.4s	remaining: 8.49s
725:	learn: 0.0034048	total: 22.4s	remaining: 8.46s
726:	learn: 0.0033681	total: 22.5s	remaining: 8.43s
727:	learn: 0.0033293	total: 22.5s	remaining: 8.4s
728:	learn: 0.0033179	total: 22.5s	remaining: 8.37s
729:	learn: 0.0032921	total: 22.6s	remaining: 8.34s
730:	learn: 0.0032591	total: 22.6s	remaining: 8.31s
731:	learn: 0.0032335	total: 22.6s	remaining: 8.28s
732:	learn: 0.0032237	total: 22.6s	remaining: 8.25s
733:	learn: 0.0032043	total: 22.7s	remaining: 8.22s
734:	learn: 0.0031946	total: 22.7s	remaining: 8.19s
735:	learn: 0.0031692	total: 22.7s	remaining: 8.16s
736:	learn: 0.0031417	total: 22.8s	remaining: 8.13s
737:	learn: 0.0031115	total: 22.8s	remaining: 8.1s
738:	learn: 0.0030832	total: 22.8s	remaining: 8.06s
739:	learn: 0.0030499	total: 22.9s	remaining: 8.03s
740:	learn: 0.0030385	total: 22.9s	remaining: 8s
741:	learn: 0.0030056	total: 22.9s	remaining: 7.97s
742:	learn: 0.0029728	total: 23s	remaining: 7.94s
743:	learn: 0.0029441	total: 23s	remaining: 7.91s
744:	learn: 0.0029120	total: 23s	remaining: 7.88s
745:	learn: 0.0028812	total: 23s	remaining: 7.85s
746:	learn: 0.0028530	total: 23.1s	remaining: 7.82s
747:	learn: 0.0028420	total: 23.1s	remaining: 7.79s
748:	learn: 0.0028167	total: 23.1s	remaining: 7.75s
749:	learn: 0.0028018	total: 23.2s	remaining: 7.72s
750:	learn: 0.0027815	total: 23.2s	remaining: 7.69s
751:	learn: 0.0027623	total: 23.2s	remaining: 7.66s
752:	learn: 0.0027508	total: 23.3s	remaining: 7.63s
753:	learn: 0.0027245	total: 23.3s	remaining: 7.6s
754:	learn: 0.0026984	total: 23.3s	remaining: 7.57s
755:	learn: 0.0026750	total: 23.4s	remaining: 7.54s
756:	learn: 0.0026564	total: 23.4s	remaining: 7.51s
757:	learn: 0.0026481	total: 23.4s	remaining: 7.48s
758:	learn: 0.0026226	total: 23.4s	remaining: 7.45s
759:	learn: 0.0025941	total: 23.5s	remaining: 7.41s
760:	learn: 0.0025654	total: 23.5s	remaining: 7.38s
761:	learn: 0.0025437	total: 23.5s	remaining: 7.35s
762:	learn: 0.0025183	total: 23.6s	remaining: 7.32s
763:	learn: 0.0025067	total: 23.6s	remaining: 7.29s
764:	learn: 0.0024830	total: 23.6s	remaining: 7.26s
765:	learn: 0.0024733	total: 23.7s	remaining: 7.23s
766:	learn: 0.0024650	total: 23.7s	remaining: 7.2s
767:	learn: 0.0024484	total: 23.7s	remaining: 7.17s
768:	learn: 0.0024298	total: 23.8s	remaining: 7.13s
769:	learn: 0.0024192	total: 23.8s	remaining: 7.1s
770:	learn: 0.0024084	total: 23.8s	remaining: 7.07s
771:	learn: 0.0024005	total: 23.8s	remaining: 7.04s
772:	learn: 0.0023752	total: 23.9s	remaining: 7.01s
773:	learn: 0.0023617	total: 23.9s	remaining: 6.98s
774:	learn: 0.0023432	total: 23.9s	remaining: 6.95s
775:	learn: 0.0023186	total: 24s	remaining: 6.92s
776:	learn: 0.0022959	total: 24s	remaining: 6.89s
777:	learn: 0.0022764	total: 24s	remaining: 6.86s
778:	learn: 0.0022529	total: 24.1s	remaining: 6.82s
779:	learn: 0.0022299	total: 24.1s	remaining: 6.79s
780:	learn: 0.0022104	total: 24.1s	remaining: 6.76s
781:	learn: 0.0021862	total: 24.1s	remaining: 6.73s
782:	learn: 0.0021670	total: 24.2s	remaining: 6.7s
783:	learn: 0.0021616	total: 24.2s	remaining: 6.67s
784:	learn: 0.0021423	total: 24.2s	remaining: 6.64s
785:	learn: 0.0021299	total: 24.3s	remaining: 6.61s
786:	learn: 0.0021186	total: 24.3s	remaining: 6.57s
787:	learn: 0.0021134	total: 24.3s	remaining: 6.54s
788:	learn: 0.0020995	total: 24.4s	remaining: 6.51s
789:	learn: 0.0020745	total: 24.4s	remaining: 6.48s
790:	learn: 0.0020515	total: 24.4s	remaining: 6.45s
791:	learn: 0.0020333	total: 24.4s	remaining: 6.42s
792:	learn: 0.0020278	total: 24.5s	remaining: 6.38s
793:	learn: 0.0020075	total: 24.5s	remaining: 6.35s
794:	learn: 0.0019938	total: 24.5s	remaining: 6.32s
795:	learn: 0.0019800	total: 24.5s	remaining: 6.29s
796:	learn: 0.0019622	total: 24.6s	remaining: 6.25s
797:	learn: 0.0019445	total: 24.6s	remaining: 6.22s
798:	learn: 0.0019277	total: 24.6s	remaining: 6.19s
799:	learn: 0.0019171	total: 24.6s	remaining: 6.16s
800:	learn: 0.0019041	total: 24.7s	remaining: 6.13s
801:	learn: 0.0018886	total: 24.7s	remaining: 6.09s
802:	learn: 0.0018733	total: 24.7s	remaining: 6.06s
803:	learn: 0.0018674	total: 24.7s	remaining: 6.03s
804:	learn: 0.0018473	total: 24.8s	remaining: 6s
805:	learn: 0.0018312	total: 24.8s	remaining: 5.97s
806:	learn: 0.0018098	total: 24.8s	remaining: 5.93s
807:	learn: 0.0018007	total: 24.8s	remaining: 5.9s
808:	learn: 0.0017838	total: 24.9s	remaining: 5.87s
809:	learn: 0.0017654	total: 24.9s	remaining: 5.84s
810:	learn: 0.0017471	total: 24.9s	remaining: 5.81s
811:	learn: 0.0017333	total: 24.9s	remaining: 5.78s
812:	learn: 0.0017289	total: 25s	remaining: 5.74s
813:	learn: 0.0017124	total: 25s	remaining: 5.71s
814:	learn: 0.0016950	total: 25s	remaining: 5.68s
815:	learn: 0.0016897	total: 25.1s	remaining: 5.65s
816:	learn: 0.0016761	total: 25.1s	remaining: 5.62s
817:	learn: 0.0016606	total: 25.1s	remaining: 5.58s
818:	learn: 0.0016441	total: 25.1s	remaining: 5.55s
819:	learn: 0.0016378	total: 25.1s	remaining: 5.52s
820:	learn: 0.0016269	total: 25.2s	remaining: 5.49s
821:	learn: 0.0016212	total: 25.2s	remaining: 5.46s
822:	learn: 0.0016084	total: 25.2s	remaining: 5.42s
823:	learn: 0.0015986	total: 25.2s	remaining: 5.39s
824:	learn: 0.0015841	total: 25.3s	remaining: 5.36s
825:	learn: 0.0015689	total: 25.3s	remaining: 5.33s
826:	learn: 0.0015529	total: 25.3s	remaining: 5.3s
827:	learn: 0.0015399	total: 25.3s	remaining: 5.26s
828:	learn: 0.0015247	total: 25.4s	remaining: 5.23s
829:	learn: 0.0015125	total: 25.4s	remaining: 5.2s
830:	learn: 0.0014970	total: 25.4s	remaining: 5.17s
831:	learn: 0.0014803	total: 25.5s	remaining: 5.14s
832:	learn: 0.0014637	total: 25.5s	remaining: 5.11s
833:	learn: 0.0014570	total: 25.5s	remaining: 5.08s
834:	learn: 0.0014500	total: 25.5s	remaining: 5.04s
835:	learn: 0.0014409	total: 25.6s	remaining: 5.01s
836:	learn: 0.0014284	total: 25.6s	remaining: 4.98s
837:	learn: 0.0014246	total: 25.6s	remaining: 4.95s
838:	learn: 0.0014184	total: 25.6s	remaining: 4.92s
839:	learn: 0.0014058	total: 25.7s	remaining: 4.89s
840:	learn: 0.0013945	total: 25.7s	remaining: 4.86s
841:	learn: 0.0013828	total: 25.7s	remaining: 4.83s
842:	learn: 0.0013709	total: 25.8s	remaining: 4.8s
843:	learn: 0.0013617	total: 25.8s	remaining: 4.76s
844:	learn: 0.0013509	total: 25.8s	remaining: 4.73s
845:	learn: 0.0013439	total: 25.8s	remaining: 4.7s
846:	learn: 0.0013316	total: 25.9s	remaining: 4.67s
847:	learn: 0.0013207	total: 25.9s	remaining: 4.64s
848:	learn: 0.0013147	total: 25.9s	remaining: 4.61s
849:	learn: 0.0013028	total: 25.9s	remaining: 4.58s
850:	learn: 0.0012898	total: 26s	remaining: 4.54s
851:	learn: 0.0012850	total: 26s	remaining: 4.51s
852:	learn: 0.0012729	total: 26s	remaining: 4.49s
853:	learn: 0.0012680	total: 26.1s	remaining: 4.46s
854:	learn: 0.0012549	total: 26.1s	remaining: 4.42s
855:	learn: 0.0012497	total: 26.1s	remaining: 4.39s
856:	learn: 0.0012370	total: 26.2s	remaining: 4.37s
857:	learn: 0.0012314	total: 26.2s	remaining: 4.33s
858:	learn: 0.0012206	total: 26.2s	remaining: 4.31s
859:	learn: 0.0012093	total: 26.3s	remaining: 4.28s
860:	learn: 0.0011955	total: 26.3s	remaining: 4.25s
861:	learn: 0.0011837	total: 26.3s	remaining: 4.22s
862:	learn: 0.0011778	total: 26.4s	remaining: 4.18s
863:	learn: 0.0011743	total: 26.4s	remaining: 4.15s
864:	learn: 0.0011708	total: 26.4s	remaining: 4.12s
865:	learn: 0.0011591	total: 26.4s	remaining: 4.09s
866:	learn: 0.0011467	total: 26.5s	remaining: 4.06s
867:	learn: 0.0011343	total: 26.5s	remaining: 4.03s
868:	learn: 0.0011241	total: 26.5s	remaining: 4s
869:	learn: 0.0011123	total: 26.6s	remaining: 3.97s
870:	learn: 0.0011035	total: 26.6s	remaining: 3.94s
871:	learn: 0.0010954	total: 26.6s	remaining: 3.91s
872:	learn: 0.0010845	total: 26.7s	remaining: 3.88s
873:	learn: 0.0010726	total: 26.7s	remaining: 3.85s
874:	learn: 0.0010616	total: 26.8s	remaining: 3.82s
875:	learn: 0.0010584	total: 26.8s	remaining: 3.79s
876:	learn: 0.0010508	total: 26.8s	remaining: 3.76s
877:	learn: 0.0010490	total: 26.9s	remaining: 3.73s
878:	learn: 0.0010383	total: 26.9s	remaining: 3.7s
879:	learn: 0.0010357	total: 26.9s	remaining: 3.67s
880:	learn: 0.0010292	total: 26.9s	remaining: 3.64s
881:	learn: 0.0010213	total: 27s	remaining: 3.61s
882:	learn: 0.0010188	total: 27s	remaining: 3.58s
883:	learn: 0.0010089	total: 27s	remaining: 3.55s
884:	learn: 0.0009989	total: 27.1s	remaining: 3.52s
885:	learn: 0.0009925	total: 27.1s	remaining: 3.49s
886:	learn: 0.0009835	total: 27.1s	remaining: 3.46s
887:	learn: 0.0009742	total: 27.2s	remaining: 3.43s
888:	learn: 0.0009667	total: 27.2s	remaining: 3.4s
889:	learn: 0.0009616	total: 27.2s	remaining: 3.37s
890:	learn: 0.0009541	total: 27.3s	remaining: 3.33s
891:	learn: 0.0009507	total: 27.3s	remaining: 3.31s
892:	learn: 0.0009401	total: 27.3s	remaining: 3.27s
893:	learn: 0.0009309	total: 27.4s	remaining: 3.25s
894:	learn: 0.0009205	total: 27.4s	remaining: 3.21s
895:	learn: 0.0009111	total: 27.4s	remaining: 3.18s
896:	learn: 0.0009047	total: 27.5s	remaining: 3.15s
897:	learn: 0.0009003	total: 27.5s	remaining: 3.12s
898:	learn: 0.0008975	total: 27.5s	remaining: 3.09s
899:	learn: 0.0008871	total: 27.6s	remaining: 3.06s
900:	learn: 0.0008844	total: 27.6s	remaining: 3.03s
901:	learn: 0.0008761	total: 27.6s	remaining: 3s
902:	learn: 0.0008741	total: 27.7s	remaining: 2.97s
903:	learn: 0.0008647	total: 27.7s	remaining: 2.94s
904:	learn: 0.0008584	total: 27.7s	remaining: 2.91s
905:	learn: 0.0008505	total: 27.7s	remaining: 2.88s
906:	learn: 0.0008444	total: 27.8s	remaining: 2.85s
907:	learn: 0.0008379	total: 27.8s	remaining: 2.82s
908:	learn: 0.0008321	total: 27.8s	remaining: 2.79s
909:	learn: 0.0008244	total: 27.9s	remaining: 2.75s
910:	learn: 0.0008150	total: 27.9s	remaining: 2.73s
911:	learn: 0.0008085	total: 27.9s	remaining: 2.69s
912:	learn: 0.0008057	total: 28s	remaining: 2.66s
913:	learn: 0.0007981	total: 28s	remaining: 2.63s
914:	learn: 0.0007942	total: 28s	remaining: 2.6s
915:	learn: 0.0007898	total: 28.1s	remaining: 2.57s
916:	learn: 0.0007819	total: 28.1s	remaining: 2.54s
917:	learn: 0.0007733	total: 28.1s	remaining: 2.51s
918:	learn: 0.0007714	total: 28.1s	remaining: 2.48s
919:	learn: 0.0007657	total: 28.2s	remaining: 2.45s
920:	learn: 0.0007592	total: 28.2s	remaining: 2.42s
921:	learn: 0.0007502	total: 28.2s	remaining: 2.39s
922:	learn: 0.0007481	total: 28.3s	remaining: 2.36s
923:	learn: 0.0007413	total: 28.3s	remaining: 2.33s
924:	learn: 0.0007347	total: 28.3s	remaining: 2.3s
925:	learn: 0.0007296	total: 28.4s	remaining: 2.27s
926:	learn: 0.0007216	total: 28.4s	remaining: 2.24s
927:	learn: 0.0007134	total: 28.4s	remaining: 2.21s
928:	learn: 0.0007105	total: 28.5s	remaining: 2.17s
929:	learn: 0.0007036	total: 28.5s	remaining: 2.15s
930:	learn: 0.0006956	total: 28.5s	remaining: 2.11s
931:	learn: 0.0006878	total: 28.6s	remaining: 2.08s
932:	learn: 0.0006820	total: 28.6s	remaining: 2.05s
933:	learn: 0.0006753	total: 28.6s	remaining: 2.02s
934:	learn: 0.0006700	total: 28.7s	remaining: 1.99s
935:	learn: 0.0006637	total: 28.7s	remaining: 1.96s
936:	learn: 0.0006614	total: 28.7s	remaining: 1.93s
937:	learn: 0.0006574	total: 28.8s	remaining: 1.9s
938:	learn: 0.0006496	total: 28.8s	remaining: 1.87s
939:	learn: 0.0006439	total: 28.8s	remaining: 1.84s
940:	learn: 0.0006423	total: 28.8s	remaining: 1.81s
941:	learn: 0.0006354	total: 28.9s	remaining: 1.78s
942:	learn: 0.0006312	total: 28.9s	remaining: 1.75s
943:	learn: 0.0006254	total: 28.9s	remaining: 1.72s
944:	learn: 0.0006202	total: 29s	remaining: 1.69s
945:	learn: 0.0006141	total: 29s	remaining: 1.66s
946:	learn: 0.0006077	total: 29s	remaining: 1.63s
947:	learn: 0.0006028	total: 29.1s	remaining: 1.59s
948:	learn: 0.0005962	total: 29.1s	remaining: 1.56s
949:	learn: 0.0005945	total: 29.2s	remaining: 1.53s
950:	learn: 0.0005913	total: 29.2s	remaining: 1.5s
951:	learn: 0.0005887	total: 29.2s	remaining: 1.47s
952:	learn: 0.0005837	total: 29.2s	remaining: 1.44s
953:	learn: 0.0005783	total: 29.3s	remaining: 1.41s
954:	learn: 0.0005769	total: 29.3s	remaining: 1.38s
955:	learn: 0.0005728	total: 29.3s	remaining: 1.35s
956:	learn: 0.0005714	total: 29.4s	remaining: 1.32s
957:	learn: 0.0005663	total: 29.4s	remaining: 1.29s
958:	learn: 0.0005607	total: 29.4s	remaining: 1.26s
959:	learn: 0.0005594	total: 29.5s	remaining: 1.23s
960:	learn: 0.0005555	total: 29.5s	remaining: 1.2s
961:	learn: 0.0005501	total: 29.5s	remaining: 1.17s
962:	learn: 0.0005443	total: 29.6s	remaining: 1.14s
963:	learn: 0.0005395	total: 29.6s	remaining: 1.1s
964:	learn: 0.0005342	total: 29.6s	remaining: 1.07s
965:	learn: 0.0005287	total: 29.7s	remaining: 1.04s
966:	learn: 0.0005251	total: 29.7s	remaining: 1.01s
967:	learn: 0.0005196	total: 29.7s	remaining: 983ms
968:	learn: 0.0005167	total: 29.8s	remaining: 953ms
969:	learn: 0.0005111	total: 29.8s	remaining: 922ms
970:	learn: 0.0005056	total: 29.8s	remaining: 891ms
971:	learn: 0.0005024	total: 29.9s	remaining: 860ms
972:	learn: 0.0005010	total: 29.9s	remaining: 830ms
973:	learn: 0.0004975	total: 29.9s	remaining: 799ms
974:	learn: 0.0004926	total: 30s	remaining: 768ms
975:	learn: 0.0004898	total: 30s	remaining: 737ms
976:	learn: 0.0004849	total: 30s	remaining: 707ms
977:	learn: 0.0004817	total: 30s	remaining: 676ms
978:	learn: 0.0004780	total: 30.1s	remaining: 645ms
979:	learn: 0.0004765	total: 30.1s	remaining: 614ms
980:	learn: 0.0004752	total: 30.1s	remaining: 584ms
981:	learn: 0.0004702	total: 30.2s	remaining: 553ms
982:	learn: 0.0004660	total: 30.2s	remaining: 522ms
983:	learn: 0.0004611	total: 30.2s	remaining: 491ms
984:	learn: 0.0004561	total: 30.3s	remaining: 461ms
985:	learn: 0.0004516	total: 30.3s	remaining: 430ms
986:	learn: 0.0004471	total: 30.3s	remaining: 399ms
987:	learn: 0.0004434	total: 30.3s	remaining: 369ms
988:	learn: 0.0004404	total: 30.4s	remaining: 338ms
989:	learn: 0.0004369	total: 30.4s	remaining: 307ms
990:	learn: 0.0004331	total: 30.4s	remaining: 276ms
991:	learn: 0.0004289	total: 30.5s	remaining: 246ms
992:	learn: 0.0004263	total: 30.5s	remaining: 215ms
993:	learn: 0.0004241	total: 30.5s	remaining: 184ms
994:	learn: 0.0004221	total: 30.6s	remaining: 154ms
995:	learn: 0.0004190	total: 30.6s	remaining: 123ms
996:	learn: 0.0004172	total: 30.6s	remaining: 92.1ms
997:	learn: 0.0004130	total: 30.6s	remaining: 61.4ms
998:	learn: 0.0004111	total: 30.7s	remaining: 30.7ms
999:	learn: 0.0004074	total: 30.7s	remaining: 0us
Learning rate set to 0.030858
0:	learn: 0.8490524	total: 33.9ms	remaining: 33.9s
1:	learn: 0.8437034	total: 64.1ms	remaining: 32s
2:	learn: 0.8399944	total: 94ms	remaining: 31.2s
3:	learn: 0.8353541	total: 123ms	remaining: 30.6s
4:	learn: 0.8342041	total: 151ms	remaining: 30.1s
5:	learn: 0.8322557	total: 179ms	remaining: 29.7s
6:	learn: 0.8302988	total: 207ms	remaining: 29.4s
7:	learn: 0.8266955	total: 233ms	remaining: 28.9s
8:	learn: 0.8224080	total: 261ms	remaining: 28.7s
9:	learn: 0.8192242	total: 292ms	remaining: 28.9s
10:	learn: 0.8169458	total: 321ms	remaining: 28.9s
11:	learn: 0.8133632	total: 348ms	remaining: 28.7s
12:	learn: 0.8101134	total: 377ms	remaining: 28.6s
13:	learn: 0.8082560	total: 405ms	remaining: 28.5s
14:	learn: 0.8060812	total: 432ms	remaining: 28.4s
15:	learn: 0.8025357	total: 460ms	remaining: 28.3s
16:	learn: 0.8006861	total: 489ms	remaining: 28.3s
17:	learn: 0.7985064	total: 517ms	remaining: 28.2s
18:	learn: 0.7950592	total: 547ms	remaining: 28.3s
19:	learn: 0.7932597	total: 573ms	remaining: 28.1s
20:	learn: 0.7890200	total: 602ms	remaining: 28s
21:	learn: 0.7879938	total: 635ms	remaining: 28.2s
22:	learn: 0.7848956	total: 662ms	remaining: 28.1s
23:	learn: 0.7829439	total: 686ms	remaining: 27.9s
24:	learn: 0.7812956	total: 711ms	remaining: 27.7s
25:	learn: 0.7790922	total: 735ms	remaining: 27.6s
26:	learn: 0.7757546	total: 763ms	remaining: 27.5s
27:	learn: 0.7730460	total: 784ms	remaining: 27.2s
28:	learn: 0.7693661	total: 809ms	remaining: 27.1s
29:	learn: 0.7664273	total: 841ms	remaining: 27.2s
30:	learn: 0.7631215	total: 871ms	remaining: 27.2s
31:	learn: 0.7610279	total: 897ms	remaining: 27.1s
32:	learn: 0.7573360	total: 920ms	remaining: 27s
33:	learn: 0.7560589	total: 955ms	remaining: 27.1s
34:	learn: 0.7544135	total: 983ms	remaining: 27.1s
35:	learn: 0.7489600	total: 1.01s	remaining: 26.9s
36:	learn: 0.7467835	total: 1.03s	remaining: 26.8s
37:	learn: 0.7437821	total: 1.05s	remaining: 26.7s
38:	learn: 0.7403193	total: 1.09s	remaining: 26.8s
39:	learn: 0.7380090	total: 1.11s	remaining: 26.7s
40:	learn: 0.7355817	total: 1.14s	remaining: 26.7s
41:	learn: 0.7343705	total: 1.17s	remaining: 26.6s
42:	learn: 0.7322452	total: 1.2s	remaining: 26.7s
43:	learn: 0.7311525	total: 1.22s	remaining: 26.5s
44:	learn: 0.7299844	total: 1.24s	remaining: 26.4s
45:	learn: 0.7282392	total: 1.27s	remaining: 26.3s
46:	learn: 0.7267989	total: 1.29s	remaining: 26.1s
47:	learn: 0.7248907	total: 1.31s	remaining: 26.1s
48:	learn: 0.7227919	total: 1.34s	remaining: 26s
49:	learn: 0.7197833	total: 1.36s	remaining: 25.9s
50:	learn: 0.7175952	total: 1.39s	remaining: 25.8s
51:	learn: 0.7147321	total: 1.41s	remaining: 25.7s
52:	learn: 0.7100850	total: 1.44s	remaining: 25.7s
53:	learn: 0.7083117	total: 1.47s	remaining: 25.8s
54:	learn: 0.7058990	total: 1.5s	remaining: 25.7s
55:	learn: 0.7028415	total: 1.52s	remaining: 25.7s
56:	learn: 0.6990396	total: 1.55s	remaining: 25.6s
57:	learn: 0.6967175	total: 1.57s	remaining: 25.5s
58:	learn: 0.6945101	total: 1.6s	remaining: 25.5s
59:	learn: 0.6896913	total: 1.62s	remaining: 25.4s
60:	learn: 0.6869852	total: 1.64s	remaining: 25.3s
61:	learn: 0.6846732	total: 1.68s	remaining: 25.4s
62:	learn: 0.6820025	total: 1.71s	remaining: 25.4s
63:	learn: 0.6802621	total: 1.73s	remaining: 25.3s
64:	learn: 0.6774320	total: 1.76s	remaining: 25.3s
65:	learn: 0.6765466	total: 1.78s	remaining: 25.2s
66:	learn: 0.6718317	total: 1.81s	remaining: 25.2s
67:	learn: 0.6680047	total: 1.83s	remaining: 25.1s
68:	learn: 0.6655074	total: 1.86s	remaining: 25s
69:	learn: 0.6637092	total: 1.89s	remaining: 25.1s
70:	learn: 0.6606005	total: 1.91s	remaining: 25s
71:	learn: 0.6563359	total: 1.93s	remaining: 24.9s
72:	learn: 0.6530946	total: 1.96s	remaining: 24.9s
73:	learn: 0.6507850	total: 1.98s	remaining: 24.8s
74:	learn: 0.6468567	total: 2.01s	remaining: 24.8s
75:	learn: 0.6445316	total: 2.04s	remaining: 24.8s
76:	learn: 0.6394149	total: 2.07s	remaining: 24.8s
77:	learn: 0.6361223	total: 2.09s	remaining: 24.7s
78:	learn: 0.6323602	total: 2.12s	remaining: 24.8s
79:	learn: 0.6296006	total: 2.15s	remaining: 24.7s
80:	learn: 0.6263579	total: 2.18s	remaining: 24.8s
81:	learn: 0.6243972	total: 2.21s	remaining: 24.7s
82:	learn: 0.6210648	total: 2.24s	remaining: 24.7s
83:	learn: 0.6188872	total: 2.26s	remaining: 24.7s
84:	learn: 0.6164058	total: 2.29s	remaining: 24.7s
85:	learn: 0.6139995	total: 2.32s	remaining: 24.7s
86:	learn: 0.6096766	total: 2.35s	remaining: 24.6s
87:	learn: 0.6061734	total: 2.38s	remaining: 24.6s
88:	learn: 0.6014951	total: 2.4s	remaining: 24.6s
89:	learn: 0.5975071	total: 2.43s	remaining: 24.6s
90:	learn: 0.5950243	total: 2.47s	remaining: 24.7s
91:	learn: 0.5917513	total: 2.5s	remaining: 24.6s
92:	learn: 0.5893212	total: 2.52s	remaining: 24.6s
93:	learn: 0.5867788	total: 2.55s	remaining: 24.6s
94:	learn: 0.5825257	total: 2.58s	remaining: 24.6s
95:	learn: 0.5796241	total: 2.61s	remaining: 24.5s
96:	learn: 0.5758525	total: 2.64s	remaining: 24.5s
97:	learn: 0.5736543	total: 2.67s	remaining: 24.5s
98:	learn: 0.5703362	total: 2.69s	remaining: 24.5s
99:	learn: 0.5667363	total: 2.72s	remaining: 24.5s
100:	learn: 0.5652212	total: 2.75s	remaining: 24.5s
101:	learn: 0.5625043	total: 2.78s	remaining: 24.5s
102:	learn: 0.5600471	total: 2.81s	remaining: 24.5s
103:	learn: 0.5573626	total: 2.84s	remaining: 24.5s
104:	learn: 0.5536129	total: 2.87s	remaining: 24.5s
105:	learn: 0.5489959	total: 2.9s	remaining: 24.5s
106:	learn: 0.5467340	total: 2.93s	remaining: 24.4s
107:	learn: 0.5453502	total: 2.96s	remaining: 24.4s
108:	learn: 0.5437388	total: 2.98s	remaining: 24.4s
109:	learn: 0.5412622	total: 3.01s	remaining: 24.4s
110:	learn: 0.5385024	total: 3.04s	remaining: 24.4s
111:	learn: 0.5361477	total: 3.07s	remaining: 24.3s
112:	learn: 0.5334622	total: 3.1s	remaining: 24.3s
113:	learn: 0.5295208	total: 3.14s	remaining: 24.4s
114:	learn: 0.5262708	total: 3.16s	remaining: 24.4s
115:	learn: 0.5238776	total: 3.19s	remaining: 24.3s
116:	learn: 0.5212442	total: 3.22s	remaining: 24.3s
117:	learn: 0.5174776	total: 3.25s	remaining: 24.3s
118:	learn: 0.5157907	total: 3.28s	remaining: 24.3s
119:	learn: 0.5133822	total: 3.31s	remaining: 24.3s
120:	learn: 0.5096378	total: 3.33s	remaining: 24.2s
121:	learn: 0.5056772	total: 3.36s	remaining: 24.2s
122:	learn: 0.5028899	total: 3.39s	remaining: 24.2s
123:	learn: 0.5008271	total: 3.42s	remaining: 24.2s
124:	learn: 0.4986071	total: 3.46s	remaining: 24.2s
125:	learn: 0.4960193	total: 3.48s	remaining: 24.2s
126:	learn: 0.4928788	total: 3.51s	remaining: 24.1s
127:	learn: 0.4893660	total: 3.54s	remaining: 24.1s
128:	learn: 0.4876930	total: 3.57s	remaining: 24.1s
129:	learn: 0.4869450	total: 3.6s	remaining: 24.1s
130:	learn: 0.4845932	total: 3.62s	remaining: 24s
131:	learn: 0.4827469	total: 3.65s	remaining: 24s
132:	learn: 0.4814338	total: 3.68s	remaining: 24s
133:	learn: 0.4796223	total: 3.71s	remaining: 24s
134:	learn: 0.4779269	total: 3.74s	remaining: 24s
135:	learn: 0.4751513	total: 3.77s	remaining: 24s
136:	learn: 0.4729568	total: 3.8s	remaining: 23.9s
137:	learn: 0.4710310	total: 3.83s	remaining: 23.9s
138:	learn: 0.4676896	total: 3.86s	remaining: 23.9s
139:	learn: 0.4656228	total: 3.89s	remaining: 23.9s
140:	learn: 0.4628911	total: 3.91s	remaining: 23.8s
141:	learn: 0.4593945	total: 3.94s	remaining: 23.8s
142:	learn: 0.4567069	total: 3.97s	remaining: 23.8s
143:	learn: 0.4553521	total: 4s	remaining: 23.8s
144:	learn: 0.4529188	total: 4.03s	remaining: 23.7s
145:	learn: 0.4504950	total: 4.05s	remaining: 23.7s
146:	learn: 0.4481183	total: 4.09s	remaining: 23.7s
147:	learn: 0.4456195	total: 4.12s	remaining: 23.7s
148:	learn: 0.4426089	total: 4.15s	remaining: 23.7s
149:	learn: 0.4390966	total: 4.18s	remaining: 23.7s
150:	learn: 0.4359428	total: 4.2s	remaining: 23.6s
151:	learn: 0.4336748	total: 4.23s	remaining: 23.6s
152:	learn: 0.4312198	total: 4.26s	remaining: 23.6s
153:	learn: 0.4279663	total: 4.29s	remaining: 23.5s
154:	learn: 0.4257181	total: 4.32s	remaining: 23.5s
155:	learn: 0.4242483	total: 4.34s	remaining: 23.5s
156:	learn: 0.4215978	total: 4.37s	remaining: 23.5s
157:	learn: 0.4177356	total: 4.4s	remaining: 23.5s
158:	learn: 0.4160485	total: 4.43s	remaining: 23.4s
159:	learn: 0.4141864	total: 4.46s	remaining: 23.4s
160:	learn: 0.4121422	total: 4.5s	remaining: 23.5s
161:	learn: 0.4112268	total: 4.53s	remaining: 23.4s
162:	learn: 0.4086295	total: 4.56s	remaining: 23.4s
163:	learn: 0.4053926	total: 4.59s	remaining: 23.4s
164:	learn: 0.4043268	total: 4.62s	remaining: 23.4s
165:	learn: 0.4021907	total: 4.65s	remaining: 23.3s
166:	learn: 0.3994000	total: 4.67s	remaining: 23.3s
167:	learn: 0.3973786	total: 4.7s	remaining: 23.3s
168:	learn: 0.3953757	total: 4.73s	remaining: 23.3s
169:	learn: 0.3914959	total: 4.76s	remaining: 23.3s
170:	learn: 0.3887614	total: 4.79s	remaining: 23.2s
171:	learn: 0.3859688	total: 4.83s	remaining: 23.2s
172:	learn: 0.3844504	total: 4.86s	remaining: 23.2s
173:	learn: 0.3824612	total: 4.88s	remaining: 23.2s
174:	learn: 0.3793360	total: 4.91s	remaining: 23.2s
175:	learn: 0.3773220	total: 4.94s	remaining: 23.1s
176:	learn: 0.3746628	total: 4.97s	remaining: 23.1s
177:	learn: 0.3736681	total: 5s	remaining: 23.1s
178:	learn: 0.3724676	total: 5.03s	remaining: 23.1s
179:	learn: 0.3698002	total: 5.05s	remaining: 23s
180:	learn: 0.3673907	total: 5.09s	remaining: 23s
181:	learn: 0.3653890	total: 5.12s	remaining: 23s
182:	learn: 0.3621443	total: 5.15s	remaining: 23s
183:	learn: 0.3598429	total: 5.18s	remaining: 23s
184:	learn: 0.3581888	total: 5.21s	remaining: 23s
185:	learn: 0.3553283	total: 5.24s	remaining: 22.9s
186:	learn: 0.3533626	total: 5.27s	remaining: 22.9s
187:	learn: 0.3521683	total: 5.3s	remaining: 22.9s
188:	learn: 0.3491252	total: 5.33s	remaining: 22.9s
189:	learn: 0.3459684	total: 5.35s	remaining: 22.8s
190:	learn: 0.3435310	total: 5.38s	remaining: 22.8s
191:	learn: 0.3411016	total: 5.42s	remaining: 22.8s
192:	learn: 0.3392615	total: 5.45s	remaining: 22.8s
193:	learn: 0.3376245	total: 5.47s	remaining: 22.7s
194:	learn: 0.3345394	total: 5.5s	remaining: 22.7s
195:	learn: 0.3332867	total: 5.53s	remaining: 22.7s
196:	learn: 0.3321907	total: 5.56s	remaining: 22.7s
197:	learn: 0.3297508	total: 5.58s	remaining: 22.6s
198:	learn: 0.3266115	total: 5.63s	remaining: 22.7s
199:	learn: 0.3244734	total: 5.66s	remaining: 22.7s
200:	learn: 0.3221060	total: 5.69s	remaining: 22.6s
201:	learn: 0.3193951	total: 5.72s	remaining: 22.6s
202:	learn: 0.3174703	total: 5.75s	remaining: 22.6s
203:	learn: 0.3146019	total: 5.78s	remaining: 22.6s
204:	learn: 0.3116620	total: 5.81s	remaining: 22.5s
205:	learn: 0.3093749	total: 5.83s	remaining: 22.5s
206:	learn: 0.3087420	total: 5.86s	remaining: 22.5s
207:	learn: 0.3061211	total: 5.89s	remaining: 22.4s
208:	learn: 0.3037353	total: 5.92s	remaining: 22.4s
209:	learn: 0.3012549	total: 5.95s	remaining: 22.4s
210:	learn: 0.2996472	total: 5.98s	remaining: 22.4s
211:	learn: 0.2980506	total: 6.01s	remaining: 22.3s
212:	learn: 0.2952183	total: 6.03s	remaining: 22.3s
213:	learn: 0.2931668	total: 6.06s	remaining: 22.3s
214:	learn: 0.2904189	total: 6.09s	remaining: 22.2s
215:	learn: 0.2889353	total: 6.12s	remaining: 22.2s
216:	learn: 0.2873576	total: 6.15s	remaining: 22.2s
217:	learn: 0.2852348	total: 6.18s	remaining: 22.2s
218:	learn: 0.2832371	total: 6.21s	remaining: 22.1s
219:	learn: 0.2808515	total: 6.23s	remaining: 22.1s
220:	learn: 0.2788857	total: 6.26s	remaining: 22.1s
221:	learn: 0.2769890	total: 6.29s	remaining: 22.1s
222:	learn: 0.2744908	total: 6.32s	remaining: 22s
223:	learn: 0.2722708	total: 6.35s	remaining: 22s
224:	learn: 0.2696692	total: 6.38s	remaining: 22s
225:	learn: 0.2675663	total: 6.41s	remaining: 21.9s
226:	learn: 0.2654453	total: 6.43s	remaining: 21.9s
227:	learn: 0.2631234	total: 6.46s	remaining: 21.9s
228:	learn: 0.2608953	total: 6.49s	remaining: 21.9s
229:	learn: 0.2584432	total: 6.52s	remaining: 21.8s
230:	learn: 0.2561575	total: 6.55s	remaining: 21.8s
231:	learn: 0.2534712	total: 6.57s	remaining: 21.8s
232:	learn: 0.2511508	total: 6.61s	remaining: 21.8s
233:	learn: 0.2487342	total: 6.64s	remaining: 21.7s
234:	learn: 0.2463317	total: 6.66s	remaining: 21.7s
235:	learn: 0.2438645	total: 6.69s	remaining: 21.7s
236:	learn: 0.2414421	total: 6.72s	remaining: 21.6s
237:	learn: 0.2389275	total: 6.75s	remaining: 21.6s
238:	learn: 0.2373994	total: 6.78s	remaining: 21.6s
239:	learn: 0.2359274	total: 6.8s	remaining: 21.5s
240:	learn: 0.2344464	total: 6.83s	remaining: 21.5s
241:	learn: 0.2329410	total: 6.86s	remaining: 21.5s
242:	learn: 0.2306883	total: 6.89s	remaining: 21.5s
243:	learn: 0.2286086	total: 6.92s	remaining: 21.4s
244:	learn: 0.2262313	total: 6.95s	remaining: 21.4s
245:	learn: 0.2241392	total: 6.98s	remaining: 21.4s
246:	learn: 0.2217422	total: 7.01s	remaining: 21.4s
247:	learn: 0.2197285	total: 7.03s	remaining: 21.3s
248:	learn: 0.2175635	total: 7.06s	remaining: 21.3s
249:	learn: 0.2152558	total: 7.09s	remaining: 21.3s
250:	learn: 0.2134118	total: 7.12s	remaining: 21.2s
251:	learn: 0.2119224	total: 7.15s	remaining: 21.2s
252:	learn: 0.2105971	total: 7.18s	remaining: 21.2s
253:	learn: 0.2089801	total: 7.2s	remaining: 21.2s
254:	learn: 0.2067815	total: 7.23s	remaining: 21.1s
255:	learn: 0.2046619	total: 7.27s	remaining: 21.1s
256:	learn: 0.2029846	total: 7.3s	remaining: 21.1s
257:	learn: 0.2015576	total: 7.33s	remaining: 21.1s
258:	learn: 0.1995299	total: 7.36s	remaining: 21s
259:	learn: 0.1974943	total: 7.38s	remaining: 21s
260:	learn: 0.1962298	total: 7.41s	remaining: 21s
261:	learn: 0.1949391	total: 7.44s	remaining: 21s
262:	learn: 0.1927942	total: 7.46s	remaining: 20.9s
263:	learn: 0.1911806	total: 7.49s	remaining: 20.9s
264:	learn: 0.1893273	total: 7.53s	remaining: 20.9s
265:	learn: 0.1874284	total: 7.56s	remaining: 20.9s
266:	learn: 0.1856501	total: 7.59s	remaining: 20.8s
267:	learn: 0.1836488	total: 7.62s	remaining: 20.8s
268:	learn: 0.1816512	total: 7.64s	remaining: 20.8s
269:	learn: 0.1802361	total: 7.67s	remaining: 20.7s
270:	learn: 0.1792172	total: 7.7s	remaining: 20.7s
271:	learn: 0.1775603	total: 7.73s	remaining: 20.7s
272:	learn: 0.1766270	total: 7.76s	remaining: 20.7s
273:	learn: 0.1755266	total: 7.79s	remaining: 20.6s
274:	learn: 0.1738636	total: 7.81s	remaining: 20.6s
275:	learn: 0.1722438	total: 7.84s	remaining: 20.6s
276:	learn: 0.1706313	total: 7.87s	remaining: 20.6s
277:	learn: 0.1691183	total: 7.9s	remaining: 20.5s
278:	learn: 0.1674522	total: 7.93s	remaining: 20.5s
279:	learn: 0.1663077	total: 7.96s	remaining: 20.5s
280:	learn: 0.1648055	total: 7.98s	remaining: 20.4s
281:	learn: 0.1627656	total: 8.01s	remaining: 20.4s
282:	learn: 0.1616341	total: 8.04s	remaining: 20.4s
283:	learn: 0.1598426	total: 8.06s	remaining: 20.3s
284:	learn: 0.1581647	total: 8.1s	remaining: 20.3s
285:	learn: 0.1563430	total: 8.13s	remaining: 20.3s
286:	learn: 0.1546840	total: 8.16s	remaining: 20.3s
287:	learn: 0.1535329	total: 8.18s	remaining: 20.2s
288:	learn: 0.1519353	total: 8.21s	remaining: 20.2s
289:	learn: 0.1501238	total: 8.24s	remaining: 20.2s
290:	learn: 0.1485541	total: 8.28s	remaining: 20.2s
291:	learn: 0.1469788	total: 8.3s	remaining: 20.1s
292:	learn: 0.1460263	total: 8.33s	remaining: 20.1s
293:	learn: 0.1447646	total: 8.35s	remaining: 20.1s
294:	learn: 0.1433849	total: 8.39s	remaining: 20.1s
295:	learn: 0.1416669	total: 8.42s	remaining: 20s
296:	learn: 0.1405669	total: 8.46s	remaining: 20s
297:	learn: 0.1391223	total: 8.48s	remaining: 20s
298:	learn: 0.1376822	total: 8.5s	remaining: 19.9s
299:	learn: 0.1364907	total: 8.53s	remaining: 19.9s
300:	learn: 0.1352660	total: 8.55s	remaining: 19.9s
301:	learn: 0.1343860	total: 8.58s	remaining: 19.8s
302:	learn: 0.1336642	total: 8.61s	remaining: 19.8s
303:	learn: 0.1327897	total: 8.63s	remaining: 19.8s
304:	learn: 0.1314595	total: 8.66s	remaining: 19.7s
305:	learn: 0.1304059	total: 8.68s	remaining: 19.7s
306:	learn: 0.1291861	total: 8.72s	remaining: 19.7s
307:	learn: 0.1279054	total: 8.75s	remaining: 19.7s
308:	learn: 0.1265918	total: 8.78s	remaining: 19.6s
309:	learn: 0.1252619	total: 8.81s	remaining: 19.6s
310:	learn: 0.1240002	total: 8.83s	remaining: 19.6s
311:	learn: 0.1226362	total: 8.86s	remaining: 19.5s
312:	learn: 0.1214823	total: 8.88s	remaining: 19.5s
313:	learn: 0.1202259	total: 8.91s	remaining: 19.5s
314:	learn: 0.1194715	total: 8.95s	remaining: 19.5s
315:	learn: 0.1184933	total: 8.98s	remaining: 19.4s
316:	learn: 0.1171925	total: 9s	remaining: 19.4s
317:	learn: 0.1162475	total: 9.03s	remaining: 19.4s
318:	learn: 0.1153410	total: 9.08s	remaining: 19.4s
319:	learn: 0.1140568	total: 9.12s	remaining: 19.4s
320:	learn: 0.1131567	total: 9.15s	remaining: 19.4s
321:	learn: 0.1121817	total: 9.18s	remaining: 19.3s
322:	learn: 0.1111163	total: 9.2s	remaining: 19.3s
323:	learn: 0.1102955	total: 9.22s	remaining: 19.2s
324:	learn: 0.1093612	total: 9.25s	remaining: 19.2s
325:	learn: 0.1083356	total: 9.28s	remaining: 19.2s
326:	learn: 0.1074788	total: 9.3s	remaining: 19.1s
327:	learn: 0.1065708	total: 9.33s	remaining: 19.1s
328:	learn: 0.1055053	total: 9.36s	remaining: 19.1s
329:	learn: 0.1045015	total: 9.38s	remaining: 19s
330:	learn: 0.1036171	total: 9.41s	remaining: 19s
331:	learn: 0.1026142	total: 9.45s	remaining: 19s
332:	learn: 0.1016139	total: 9.47s	remaining: 19s
333:	learn: 0.1012338	total: 9.5s	remaining: 18.9s
334:	learn: 0.1003777	total: 9.53s	remaining: 18.9s
335:	learn: 0.0996906	total: 9.55s	remaining: 18.9s
336:	learn: 0.0988948	total: 9.58s	remaining: 18.8s
337:	learn: 0.0981389	total: 9.6s	remaining: 18.8s
338:	learn: 0.0971178	total: 9.64s	remaining: 18.8s
339:	learn: 0.0964710	total: 9.68s	remaining: 18.8s
340:	learn: 0.0954687	total: 9.71s	remaining: 18.8s
341:	learn: 0.0945264	total: 9.73s	remaining: 18.7s
342:	learn: 0.0939373	total: 9.76s	remaining: 18.7s
343:	learn: 0.0930823	total: 9.79s	remaining: 18.7s
344:	learn: 0.0921724	total: 9.83s	remaining: 18.7s
345:	learn: 0.0912994	total: 9.86s	remaining: 18.6s
346:	learn: 0.0907648	total: 9.89s	remaining: 18.6s
347:	learn: 0.0900202	total: 9.91s	remaining: 18.6s
348:	learn: 0.0891371	total: 9.94s	remaining: 18.5s
349:	learn: 0.0882608	total: 9.97s	remaining: 18.5s
350:	learn: 0.0875344	total: 10s	remaining: 18.5s
351:	learn: 0.0866413	total: 10s	remaining: 18.5s
352:	learn: 0.0857971	total: 10.1s	remaining: 18.4s
353:	learn: 0.0852938	total: 10.1s	remaining: 18.4s
354:	learn: 0.0844510	total: 10.1s	remaining: 18.4s
355:	learn: 0.0836252	total: 10.2s	remaining: 18.4s
356:	learn: 0.0828549	total: 10.2s	remaining: 18.4s
357:	learn: 0.0820660	total: 10.2s	remaining: 18.3s
358:	learn: 0.0812224	total: 10.2s	remaining: 18.3s
359:	learn: 0.0803944	total: 10.3s	remaining: 18.3s
360:	learn: 0.0797316	total: 10.3s	remaining: 18.2s
361:	learn: 0.0790266	total: 10.3s	remaining: 18.2s
362:	learn: 0.0785280	total: 10.4s	remaining: 18.2s
363:	learn: 0.0777695	total: 10.4s	remaining: 18.1s
364:	learn: 0.0773087	total: 10.4s	remaining: 18.1s
365:	learn: 0.0766771	total: 10.4s	remaining: 18.1s
366:	learn: 0.0759679	total: 10.5s	remaining: 18.1s
367:	learn: 0.0752682	total: 10.5s	remaining: 18.1s
368:	learn: 0.0749543	total: 10.5s	remaining: 18s
369:	learn: 0.0742405	total: 10.6s	remaining: 18s
370:	learn: 0.0737692	total: 10.6s	remaining: 18s
371:	learn: 0.0729868	total: 10.6s	remaining: 17.9s
372:	learn: 0.0723163	total: 10.7s	remaining: 17.9s
373:	learn: 0.0716907	total: 10.7s	remaining: 17.9s
374:	learn: 0.0709920	total: 10.7s	remaining: 17.8s
375:	learn: 0.0702483	total: 10.7s	remaining: 17.8s
376:	learn: 0.0696304	total: 10.8s	remaining: 17.8s
377:	learn: 0.0688666	total: 10.8s	remaining: 17.8s
378:	learn: 0.0681985	total: 10.8s	remaining: 17.8s
379:	learn: 0.0675923	total: 10.9s	remaining: 17.7s
380:	learn: 0.0671005	total: 10.9s	remaining: 17.7s
381:	learn: 0.0667008	total: 10.9s	remaining: 17.7s
382:	learn: 0.0661521	total: 10.9s	remaining: 17.6s
383:	learn: 0.0653868	total: 11s	remaining: 17.6s
384:	learn: 0.0647614	total: 11s	remaining: 17.6s
385:	learn: 0.0641790	total: 11s	remaining: 17.5s
386:	learn: 0.0634312	total: 11.1s	remaining: 17.5s
387:	learn: 0.0628864	total: 11.1s	remaining: 17.5s
388:	learn: 0.0625875	total: 11.1s	remaining: 17.5s
389:	learn: 0.0619784	total: 11.2s	remaining: 17.4s
390:	learn: 0.0613512	total: 11.2s	remaining: 17.4s
391:	learn: 0.0610538	total: 11.2s	remaining: 17.4s
392:	learn: 0.0606437	total: 11.2s	remaining: 17.4s
393:	learn: 0.0600735	total: 11.3s	remaining: 17.3s
394:	learn: 0.0593549	total: 11.3s	remaining: 17.3s
395:	learn: 0.0587471	total: 11.3s	remaining: 17.3s
396:	learn: 0.0581491	total: 11.4s	remaining: 17.2s
397:	learn: 0.0577808	total: 11.4s	remaining: 17.2s
398:	learn: 0.0573238	total: 11.4s	remaining: 17.2s
399:	learn: 0.0570558	total: 11.4s	remaining: 17.2s
400:	learn: 0.0566143	total: 11.5s	remaining: 17.1s
401:	learn: 0.0560747	total: 11.5s	remaining: 17.1s
402:	learn: 0.0555160	total: 11.5s	remaining: 17.1s
403:	learn: 0.0548549	total: 11.6s	remaining: 17.1s
404:	learn: 0.0543432	total: 11.6s	remaining: 17s
405:	learn: 0.0538702	total: 11.6s	remaining: 17s
406:	learn: 0.0534637	total: 11.6s	remaining: 17s
407:	learn: 0.0529666	total: 11.7s	remaining: 16.9s
408:	learn: 0.0524679	total: 11.7s	remaining: 16.9s
409:	learn: 0.0519683	total: 11.7s	remaining: 16.9s
410:	learn: 0.0514977	total: 11.8s	remaining: 16.9s
411:	learn: 0.0510658	total: 11.8s	remaining: 16.8s
412:	learn: 0.0507195	total: 11.8s	remaining: 16.8s
413:	learn: 0.0501449	total: 11.9s	remaining: 16.8s
414:	learn: 0.0497758	total: 11.9s	remaining: 16.8s
415:	learn: 0.0493901	total: 11.9s	remaining: 16.7s
416:	learn: 0.0488966	total: 11.9s	remaining: 16.7s
417:	learn: 0.0486185	total: 12s	remaining: 16.7s
418:	learn: 0.0480942	total: 12s	remaining: 16.7s
419:	learn: 0.0475869	total: 12s	remaining: 16.6s
420:	learn: 0.0472223	total: 12.1s	remaining: 16.6s
421:	learn: 0.0468202	total: 12.1s	remaining: 16.6s
422:	learn: 0.0463255	total: 12.1s	remaining: 16.5s
423:	learn: 0.0459467	total: 12.1s	remaining: 16.5s
424:	learn: 0.0455888	total: 12.2s	remaining: 16.5s
425:	learn: 0.0453417	total: 12.2s	remaining: 16.4s
426:	learn: 0.0450062	total: 12.2s	remaining: 16.4s
427:	learn: 0.0447524	total: 12.3s	remaining: 16.4s
428:	learn: 0.0443414	total: 12.3s	remaining: 16.4s
429:	learn: 0.0440915	total: 12.3s	remaining: 16.4s
430:	learn: 0.0438426	total: 12.4s	remaining: 16.3s
431:	learn: 0.0433527	total: 12.4s	remaining: 16.3s
432:	learn: 0.0429184	total: 12.4s	remaining: 16.3s
433:	learn: 0.0424431	total: 12.5s	remaining: 16.3s
434:	learn: 0.0422214	total: 12.5s	remaining: 16.2s
435:	learn: 0.0418205	total: 12.5s	remaining: 16.2s
436:	learn: 0.0414291	total: 12.6s	remaining: 16.2s
437:	learn: 0.0410766	total: 12.6s	remaining: 16.1s
438:	learn: 0.0406562	total: 12.6s	remaining: 16.1s
439:	learn: 0.0402102	total: 12.6s	remaining: 16.1s
440:	learn: 0.0397308	total: 12.7s	remaining: 16.1s
441:	learn: 0.0394539	total: 12.7s	remaining: 16s
442:	learn: 0.0391754	total: 12.7s	remaining: 16s
443:	learn: 0.0388703	total: 12.8s	remaining: 16s
444:	learn: 0.0384753	total: 12.8s	remaining: 15.9s
445:	learn: 0.0380320	total: 12.8s	remaining: 15.9s
446:	learn: 0.0377146	total: 12.8s	remaining: 15.9s
447:	learn: 0.0373482	total: 12.9s	remaining: 15.9s
448:	learn: 0.0369382	total: 12.9s	remaining: 15.8s
449:	learn: 0.0365800	total: 12.9s	remaining: 15.8s
450:	learn: 0.0361287	total: 13s	remaining: 15.8s
451:	learn: 0.0357133	total: 13s	remaining: 15.8s
452:	learn: 0.0353519	total: 13s	remaining: 15.7s
453:	learn: 0.0349681	total: 13.1s	remaining: 15.7s
454:	learn: 0.0346054	total: 13.1s	remaining: 15.7s
455:	learn: 0.0342962	total: 13.1s	remaining: 15.6s
456:	learn: 0.0339354	total: 13.1s	remaining: 15.6s
457:	learn: 0.0335879	total: 13.2s	remaining: 15.6s
458:	learn: 0.0334258	total: 13.2s	remaining: 15.5s
459:	learn: 0.0330998	total: 13.2s	remaining: 15.5s
460:	learn: 0.0328162	total: 13.3s	remaining: 15.5s
461:	learn: 0.0326341	total: 13.3s	remaining: 15.5s
462:	learn: 0.0322875	total: 13.3s	remaining: 15.4s
463:	learn: 0.0321099	total: 13.3s	remaining: 15.4s
464:	learn: 0.0318028	total: 13.4s	remaining: 15.4s
465:	learn: 0.0315999	total: 13.4s	remaining: 15.3s
466:	learn: 0.0313432	total: 13.4s	remaining: 15.3s
467:	learn: 0.0311279	total: 13.4s	remaining: 15.3s
468:	learn: 0.0308481	total: 13.5s	remaining: 15.3s
469:	learn: 0.0305705	total: 13.5s	remaining: 15.2s
470:	learn: 0.0302858	total: 13.5s	remaining: 15.2s
471:	learn: 0.0301035	total: 13.6s	remaining: 15.2s
472:	learn: 0.0298000	total: 13.6s	remaining: 15.2s
473:	learn: 0.0295289	total: 13.6s	remaining: 15.1s
474:	learn: 0.0292410	total: 13.7s	remaining: 15.1s
475:	learn: 0.0290460	total: 13.7s	remaining: 15.1s
476:	learn: 0.0287740	total: 13.7s	remaining: 15s
477:	learn: 0.0285176	total: 13.7s	remaining: 15s
478:	learn: 0.0282559	total: 13.8s	remaining: 15s
479:	learn: 0.0279618	total: 13.8s	remaining: 14.9s
480:	learn: 0.0277529	total: 13.8s	remaining: 14.9s
481:	learn: 0.0275164	total: 13.9s	remaining: 14.9s
482:	learn: 0.0272304	total: 13.9s	remaining: 14.9s
483:	learn: 0.0269757	total: 13.9s	remaining: 14.8s
484:	learn: 0.0266833	total: 13.9s	remaining: 14.8s
485:	learn: 0.0265401	total: 14s	remaining: 14.8s
486:	learn: 0.0262898	total: 14s	remaining: 14.7s
487:	learn: 0.0260597	total: 14s	remaining: 14.7s
488:	learn: 0.0257969	total: 14.1s	remaining: 14.7s
489:	learn: 0.0255549	total: 14.1s	remaining: 14.7s
490:	learn: 0.0252713	total: 14.1s	remaining: 14.6s
491:	learn: 0.0250535	total: 14.1s	remaining: 14.6s
492:	learn: 0.0247705	total: 14.2s	remaining: 14.6s
493:	learn: 0.0245718	total: 14.2s	remaining: 14.5s
494:	learn: 0.0243221	total: 14.2s	remaining: 14.5s
495:	learn: 0.0240610	total: 14.3s	remaining: 14.5s
496:	learn: 0.0238262	total: 14.3s	remaining: 14.5s
497:	learn: 0.0236748	total: 14.3s	remaining: 14.4s
498:	learn: 0.0234374	total: 14.3s	remaining: 14.4s
499:	learn: 0.0231813	total: 14.4s	remaining: 14.4s
500:	learn: 0.0229286	total: 14.4s	remaining: 14.3s
501:	learn: 0.0226888	total: 14.4s	remaining: 14.3s
502:	learn: 0.0224730	total: 14.5s	remaining: 14.3s
503:	learn: 0.0222474	total: 14.5s	remaining: 14.3s
504:	learn: 0.0220008	total: 14.5s	remaining: 14.2s
505:	learn: 0.0218097	total: 14.6s	remaining: 14.2s
506:	learn: 0.0215837	total: 14.6s	remaining: 14.2s
507:	learn: 0.0213730	total: 14.6s	remaining: 14.2s
508:	learn: 0.0212413	total: 14.6s	remaining: 14.1s
509:	learn: 0.0209897	total: 14.7s	remaining: 14.1s
510:	learn: 0.0208357	total: 14.7s	remaining: 14.1s
511:	learn: 0.0206523	total: 14.7s	remaining: 14s
512:	learn: 0.0204694	total: 14.8s	remaining: 14s
513:	learn: 0.0202898	total: 14.8s	remaining: 14s
514:	learn: 0.0200741	total: 14.8s	remaining: 14s
515:	learn: 0.0198638	total: 14.8s	remaining: 13.9s
516:	learn: 0.0196607	total: 14.9s	remaining: 13.9s
517:	learn: 0.0195025	total: 14.9s	remaining: 13.9s
518:	learn: 0.0193119	total: 14.9s	remaining: 13.8s
519:	learn: 0.0191256	total: 15s	remaining: 13.8s
520:	learn: 0.0189624	total: 15s	remaining: 13.8s
521:	learn: 0.0188047	total: 15s	remaining: 13.8s
522:	learn: 0.0186051	total: 15.1s	remaining: 13.7s
523:	learn: 0.0184051	total: 15.1s	remaining: 13.7s
524:	learn: 0.0182724	total: 15.1s	remaining: 13.7s
525:	learn: 0.0181100	total: 15.1s	remaining: 13.6s
526:	learn: 0.0179445	total: 15.2s	remaining: 13.6s
527:	learn: 0.0177684	total: 15.2s	remaining: 13.6s
528:	learn: 0.0176095	total: 15.2s	remaining: 13.6s
529:	learn: 0.0174296	total: 15.3s	remaining: 13.5s
530:	learn: 0.0172406	total: 15.3s	remaining: 13.5s
531:	learn: 0.0170720	total: 15.3s	remaining: 13.5s
532:	learn: 0.0168998	total: 15.4s	remaining: 13.5s
533:	learn: 0.0167163	total: 15.4s	remaining: 13.4s
534:	learn: 0.0165685	total: 15.4s	remaining: 13.4s
535:	learn: 0.0164935	total: 15.4s	remaining: 13.4s
536:	learn: 0.0164356	total: 15.5s	remaining: 13.3s
537:	learn: 0.0162796	total: 15.5s	remaining: 13.3s
538:	learn: 0.0161244	total: 15.5s	remaining: 13.3s
539:	learn: 0.0159603	total: 15.6s	remaining: 13.3s
540:	learn: 0.0158016	total: 15.6s	remaining: 13.2s
541:	learn: 0.0156361	total: 15.6s	remaining: 13.2s
542:	learn: 0.0154704	total: 15.6s	remaining: 13.2s
543:	learn: 0.0153001	total: 15.7s	remaining: 13.1s
544:	learn: 0.0151403	total: 15.7s	remaining: 13.1s
545:	learn: 0.0150788	total: 15.7s	remaining: 13.1s
546:	learn: 0.0149447	total: 15.8s	remaining: 13.1s
547:	learn: 0.0148338	total: 15.8s	remaining: 13s
548:	learn: 0.0147082	total: 15.8s	remaining: 13s
549:	learn: 0.0145680	total: 15.8s	remaining: 13s
550:	learn: 0.0144274	total: 15.9s	remaining: 12.9s
551:	learn: 0.0143283	total: 15.9s	remaining: 12.9s
552:	learn: 0.0141856	total: 15.9s	remaining: 12.9s
553:	learn: 0.0140412	total: 16s	remaining: 12.9s
554:	learn: 0.0139010	total: 16s	remaining: 12.8s
555:	learn: 0.0137542	total: 16s	remaining: 12.8s
556:	learn: 0.0136469	total: 16.1s	remaining: 12.8s
557:	learn: 0.0135700	total: 16.1s	remaining: 12.7s
558:	learn: 0.0135024	total: 16.1s	remaining: 12.7s
559:	learn: 0.0133575	total: 16.1s	remaining: 12.7s
560:	learn: 0.0132664	total: 16.2s	remaining: 12.7s
561:	learn: 0.0131713	total: 16.2s	remaining: 12.6s
562:	learn: 0.0130175	total: 16.2s	remaining: 12.6s
563:	learn: 0.0128859	total: 16.3s	remaining: 12.6s
564:	learn: 0.0127715	total: 16.3s	remaining: 12.6s
565:	learn: 0.0126754	total: 16.3s	remaining: 12.5s
566:	learn: 0.0125544	total: 16.4s	remaining: 12.5s
567:	learn: 0.0124351	total: 16.4s	remaining: 12.5s
568:	learn: 0.0123182	total: 16.4s	remaining: 12.4s
569:	learn: 0.0122136	total: 16.5s	remaining: 12.4s
570:	learn: 0.0121141	total: 16.5s	remaining: 12.4s
571:	learn: 0.0120347	total: 16.5s	remaining: 12.4s
572:	learn: 0.0119183	total: 16.6s	remaining: 12.3s
573:	learn: 0.0118197	total: 16.6s	remaining: 12.3s
574:	learn: 0.0116897	total: 16.6s	remaining: 12.3s
575:	learn: 0.0116212	total: 16.6s	remaining: 12.3s
576:	learn: 0.0115183	total: 16.7s	remaining: 12.2s
577:	learn: 0.0114187	total: 16.7s	remaining: 12.2s
578:	learn: 0.0112879	total: 16.7s	remaining: 12.2s
579:	learn: 0.0112111	total: 16.8s	remaining: 12.1s
580:	learn: 0.0110949	total: 16.8s	remaining: 12.1s
581:	learn: 0.0109944	total: 16.8s	remaining: 12.1s
582:	learn: 0.0109144	total: 16.8s	remaining: 12.1s
583:	learn: 0.0108019	total: 16.9s	remaining: 12s
584:	learn: 0.0107100	total: 16.9s	remaining: 12s
585:	learn: 0.0106064	total: 16.9s	remaining: 12s
586:	learn: 0.0105151	total: 17s	remaining: 11.9s
587:	learn: 0.0104723	total: 17s	remaining: 11.9s
588:	learn: 0.0104039	total: 17s	remaining: 11.9s
589:	learn: 0.0102970	total: 17.1s	remaining: 11.9s
590:	learn: 0.0101941	total: 17.1s	remaining: 11.8s
591:	learn: 0.0100940	total: 17.1s	remaining: 11.8s
592:	learn: 0.0099781	total: 17.1s	remaining: 11.8s
593:	learn: 0.0098737	total: 17.2s	remaining: 11.7s
594:	learn: 0.0097959	total: 17.2s	remaining: 11.7s
595:	learn: 0.0097514	total: 17.2s	remaining: 11.7s
596:	learn: 0.0096614	total: 17.3s	remaining: 11.7s
597:	learn: 0.0095611	total: 17.3s	remaining: 11.6s
598:	learn: 0.0094572	total: 17.3s	remaining: 11.6s
599:	learn: 0.0093706	total: 17.4s	remaining: 11.6s
600:	learn: 0.0092712	total: 17.4s	remaining: 11.6s
601:	learn: 0.0091918	total: 17.4s	remaining: 11.5s
602:	learn: 0.0091150	total: 17.5s	remaining: 11.5s
603:	learn: 0.0090173	total: 17.5s	remaining: 11.5s
604:	learn: 0.0089412	total: 17.5s	remaining: 11.4s
605:	learn: 0.0088712	total: 17.6s	remaining: 11.4s
606:	learn: 0.0087789	total: 17.6s	remaining: 11.4s
607:	learn: 0.0087094	total: 17.6s	remaining: 11.4s
608:	learn: 0.0086264	total: 17.6s	remaining: 11.3s
609:	learn: 0.0085349	total: 17.7s	remaining: 11.3s
610:	learn: 0.0084613	total: 17.7s	remaining: 11.3s
611:	learn: 0.0083612	total: 17.7s	remaining: 11.3s
612:	learn: 0.0082673	total: 17.8s	remaining: 11.2s
613:	learn: 0.0081902	total: 17.8s	remaining: 11.2s
614:	learn: 0.0081157	total: 17.8s	remaining: 11.2s
615:	learn: 0.0080843	total: 17.9s	remaining: 11.1s
616:	learn: 0.0079984	total: 17.9s	remaining: 11.1s
617:	learn: 0.0079089	total: 17.9s	remaining: 11.1s
618:	learn: 0.0078690	total: 17.9s	remaining: 11s
619:	learn: 0.0077982	total: 18s	remaining: 11s
620:	learn: 0.0077673	total: 18s	remaining: 11s
621:	learn: 0.0076940	total: 18s	remaining: 11s
622:	learn: 0.0076206	total: 18.1s	remaining: 10.9s
623:	learn: 0.0075694	total: 18.1s	remaining: 10.9s
624:	learn: 0.0074913	total: 18.1s	remaining: 10.9s
625:	learn: 0.0074219	total: 18.2s	remaining: 10.8s
626:	learn: 0.0073739	total: 18.2s	remaining: 10.8s
627:	learn: 0.0073032	total: 18.2s	remaining: 10.8s
628:	learn: 0.0072249	total: 18.2s	remaining: 10.8s
629:	learn: 0.0071685	total: 18.3s	remaining: 10.7s
630:	learn: 0.0071125	total: 18.3s	remaining: 10.7s
631:	learn: 0.0070474	total: 18.3s	remaining: 10.7s
632:	learn: 0.0070189	total: 18.4s	remaining: 10.6s
633:	learn: 0.0069519	total: 18.4s	remaining: 10.6s
634:	learn: 0.0068942	total: 18.4s	remaining: 10.6s
635:	learn: 0.0068200	total: 18.4s	remaining: 10.6s
636:	learn: 0.0067566	total: 18.5s	remaining: 10.5s
637:	learn: 0.0066812	total: 18.5s	remaining: 10.5s
638:	learn: 0.0066230	total: 18.5s	remaining: 10.5s
639:	learn: 0.0065843	total: 18.6s	remaining: 10.4s
640:	learn: 0.0065180	total: 18.6s	remaining: 10.4s
641:	learn: 0.0064628	total: 18.6s	remaining: 10.4s
642:	learn: 0.0064209	total: 18.6s	remaining: 10.4s
643:	learn: 0.0063644	total: 18.7s	remaining: 10.3s
644:	learn: 0.0062947	total: 18.7s	remaining: 10.3s
645:	learn: 0.0062247	total: 18.7s	remaining: 10.3s
646:	learn: 0.0061757	total: 18.8s	remaining: 10.2s
647:	learn: 0.0061531	total: 18.8s	remaining: 10.2s
648:	learn: 0.0060986	total: 18.8s	remaining: 10.2s
649:	learn: 0.0060520	total: 18.9s	remaining: 10.2s
650:	learn: 0.0059884	total: 18.9s	remaining: 10.1s
651:	learn: 0.0059509	total: 18.9s	remaining: 10.1s
652:	learn: 0.0058889	total: 18.9s	remaining: 10.1s
653:	learn: 0.0058259	total: 19s	remaining: 10s
654:	learn: 0.0057694	total: 19s	remaining: 10s
655:	learn: 0.0057178	total: 19s	remaining: 9.98s
656:	learn: 0.0056999	total: 19.1s	remaining: 9.95s
657:	learn: 0.0056459	total: 19.1s	remaining: 9.93s
658:	learn: 0.0055984	total: 19.1s	remaining: 9.9s
659:	learn: 0.0055507	total: 19.2s	remaining: 9.87s
660:	learn: 0.0054938	total: 19.2s	remaining: 9.84s
661:	learn: 0.0054394	total: 19.2s	remaining: 9.81s
662:	learn: 0.0054198	total: 19.2s	remaining: 9.78s
663:	learn: 0.0053753	total: 19.3s	remaining: 9.75s
664:	learn: 0.0053159	total: 19.3s	remaining: 9.72s
665:	learn: 0.0052655	total: 19.3s	remaining: 9.69s
666:	learn: 0.0052328	total: 19.4s	remaining: 9.66s
667:	learn: 0.0051836	total: 19.4s	remaining: 9.64s
668:	learn: 0.0051204	total: 19.4s	remaining: 9.61s
669:	learn: 0.0050697	total: 19.5s	remaining: 9.58s
670:	learn: 0.0050183	total: 19.5s	remaining: 9.55s
671:	learn: 0.0049971	total: 19.5s	remaining: 9.53s
672:	learn: 0.0049527	total: 19.6s	remaining: 9.5s
673:	learn: 0.0049026	total: 19.6s	remaining: 9.47s
674:	learn: 0.0048628	total: 19.6s	remaining: 9.44s
675:	learn: 0.0048096	total: 19.6s	remaining: 9.41s
676:	learn: 0.0047837	total: 19.7s	remaining: 9.38s
677:	learn: 0.0047322	total: 19.7s	remaining: 9.35s
678:	learn: 0.0047010	total: 19.7s	remaining: 9.33s
679:	learn: 0.0046811	total: 19.8s	remaining: 9.3s
680:	learn: 0.0046362	total: 19.8s	remaining: 9.27s
681:	learn: 0.0046191	total: 19.8s	remaining: 9.24s
682:	learn: 0.0046011	total: 19.8s	remaining: 9.21s
683:	learn: 0.0045560	total: 19.9s	remaining: 9.18s
684:	learn: 0.0045173	total: 19.9s	remaining: 9.15s
685:	learn: 0.0044783	total: 19.9s	remaining: 9.12s
686:	learn: 0.0044388	total: 20s	remaining: 9.1s
687:	learn: 0.0043932	total: 20s	remaining: 9.06s
688:	learn: 0.0043716	total: 20s	remaining: 9.03s
689:	learn: 0.0043262	total: 20s	remaining: 9s
690:	learn: 0.0042759	total: 20.1s	remaining: 8.97s
691:	learn: 0.0042420	total: 20.1s	remaining: 8.95s
692:	learn: 0.0042027	total: 20.1s	remaining: 8.92s
693:	learn: 0.0041554	total: 20.2s	remaining: 8.89s
694:	learn: 0.0041273	total: 20.2s	remaining: 8.86s
695:	learn: 0.0040968	total: 20.2s	remaining: 8.83s
696:	learn: 0.0040599	total: 20.2s	remaining: 8.8s
697:	learn: 0.0040224	total: 20.3s	remaining: 8.77s
698:	learn: 0.0039805	total: 20.3s	remaining: 8.74s
699:	learn: 0.0039375	total: 20.3s	remaining: 8.71s
700:	learn: 0.0039100	total: 20.4s	remaining: 8.69s
701:	learn: 0.0038767	total: 20.4s	remaining: 8.66s
702:	learn: 0.0038449	total: 20.4s	remaining: 8.63s
703:	learn: 0.0038333	total: 20.5s	remaining: 8.61s
704:	learn: 0.0037963	total: 20.5s	remaining: 8.57s
705:	learn: 0.0037694	total: 20.5s	remaining: 8.55s
706:	learn: 0.0037343	total: 20.6s	remaining: 8.52s
707:	learn: 0.0037028	total: 20.6s	remaining: 8.49s
708:	learn: 0.0036627	total: 20.6s	remaining: 8.46s
709:	learn: 0.0036239	total: 20.6s	remaining: 8.43s
710:	learn: 0.0035940	total: 20.7s	remaining: 8.4s
711:	learn: 0.0035599	total: 20.7s	remaining: 8.37s
712:	learn: 0.0035491	total: 20.7s	remaining: 8.34s
713:	learn: 0.0035272	total: 20.8s	remaining: 8.32s
714:	learn: 0.0034906	total: 20.8s	remaining: 8.29s
715:	learn: 0.0034537	total: 20.8s	remaining: 8.26s
716:	learn: 0.0034169	total: 20.9s	remaining: 8.23s
717:	learn: 0.0034070	total: 20.9s	remaining: 8.2s
718:	learn: 0.0033700	total: 20.9s	remaining: 8.17s
719:	learn: 0.0033575	total: 20.9s	remaining: 8.14s
720:	learn: 0.0033309	total: 21s	remaining: 8.11s
721:	learn: 0.0032962	total: 21s	remaining: 8.08s
722:	learn: 0.0032703	total: 21s	remaining: 8.05s
723:	learn: 0.0032365	total: 21.1s	remaining: 8.03s
724:	learn: 0.0032015	total: 21.1s	remaining: 8s
725:	learn: 0.0031797	total: 21.1s	remaining: 7.97s
726:	learn: 0.0031462	total: 21.1s	remaining: 7.94s
727:	learn: 0.0031197	total: 21.2s	remaining: 7.91s
728:	learn: 0.0030919	total: 21.2s	remaining: 7.88s
729:	learn: 0.0030570	total: 21.2s	remaining: 7.86s
730:	learn: 0.0030476	total: 21.3s	remaining: 7.83s
731:	learn: 0.0030125	total: 21.3s	remaining: 7.8s
732:	learn: 0.0029825	total: 21.3s	remaining: 7.77s
733:	learn: 0.0029714	total: 21.4s	remaining: 7.74s
734:	learn: 0.0029470	total: 21.4s	remaining: 7.71s
735:	learn: 0.0029135	total: 21.4s	remaining: 7.68s
736:	learn: 0.0028804	total: 21.4s	remaining: 7.65s
737:	learn: 0.0028733	total: 21.5s	remaining: 7.62s
738:	learn: 0.0028478	total: 21.5s	remaining: 7.59s
739:	learn: 0.0028265	total: 21.5s	remaining: 7.57s
740:	learn: 0.0028018	total: 21.6s	remaining: 7.54s
741:	learn: 0.0027953	total: 21.6s	remaining: 7.51s
742:	learn: 0.0027897	total: 21.6s	remaining: 7.48s
743:	learn: 0.0027693	total: 21.6s	remaining: 7.45s
744:	learn: 0.0027430	total: 21.7s	remaining: 7.42s
745:	learn: 0.0027204	total: 21.7s	remaining: 7.39s
746:	learn: 0.0026984	total: 21.7s	remaining: 7.36s
747:	learn: 0.0026721	total: 21.8s	remaining: 7.33s
748:	learn: 0.0026458	total: 21.8s	remaining: 7.3s
749:	learn: 0.0026244	total: 21.8s	remaining: 7.27s
750:	learn: 0.0026047	total: 21.9s	remaining: 7.25s
751:	learn: 0.0025972	total: 21.9s	remaining: 7.22s
752:	learn: 0.0025802	total: 21.9s	remaining: 7.19s
753:	learn: 0.0025570	total: 22s	remaining: 7.17s
754:	learn: 0.0025393	total: 22s	remaining: 7.14s
755:	learn: 0.0025148	total: 22s	remaining: 7.11s
756:	learn: 0.0024991	total: 22s	remaining: 7.08s
757:	learn: 0.0024764	total: 22.1s	remaining: 7.05s
758:	learn: 0.0024662	total: 22.1s	remaining: 7.02s
759:	learn: 0.0024424	total: 22.1s	remaining: 6.99s
760:	learn: 0.0024183	total: 22.2s	remaining: 6.96s
761:	learn: 0.0023932	total: 22.2s	remaining: 6.93s
762:	learn: 0.0023740	total: 22.2s	remaining: 6.9s
763:	learn: 0.0023502	total: 22.3s	remaining: 6.87s
764:	learn: 0.0023293	total: 22.3s	remaining: 6.84s
765:	learn: 0.0023022	total: 22.3s	remaining: 6.82s
766:	learn: 0.0022845	total: 22.3s	remaining: 6.79s
767:	learn: 0.0022793	total: 22.4s	remaining: 6.76s
768:	learn: 0.0022547	total: 22.4s	remaining: 6.73s
769:	learn: 0.0022332	total: 22.4s	remaining: 6.7s
770:	learn: 0.0022107	total: 22.5s	remaining: 6.67s
771:	learn: 0.0021999	total: 22.5s	remaining: 6.64s
772:	learn: 0.0021848	total: 22.5s	remaining: 6.61s
773:	learn: 0.0021665	total: 22.6s	remaining: 6.59s
774:	learn: 0.0021500	total: 22.6s	remaining: 6.56s
775:	learn: 0.0021258	total: 22.6s	remaining: 6.53s
776:	learn: 0.0021037	total: 22.6s	remaining: 6.5s
777:	learn: 0.0020854	total: 22.7s	remaining: 6.47s
778:	learn: 0.0020791	total: 22.7s	remaining: 6.44s
779:	learn: 0.0020556	total: 22.7s	remaining: 6.41s
780:	learn: 0.0020441	total: 22.8s	remaining: 6.38s
781:	learn: 0.0020382	total: 22.8s	remaining: 6.35s
782:	learn: 0.0020237	total: 22.8s	remaining: 6.33s
783:	learn: 0.0020059	total: 22.9s	remaining: 6.3s
784:	learn: 0.0020000	total: 22.9s	remaining: 6.27s
785:	learn: 0.0019798	total: 22.9s	remaining: 6.24s
786:	learn: 0.0019618	total: 23s	remaining: 6.21s
787:	learn: 0.0019416	total: 23s	remaining: 6.18s
788:	learn: 0.0019278	total: 23s	remaining: 6.15s
789:	learn: 0.0019103	total: 23s	remaining: 6.12s
790:	learn: 0.0018894	total: 23.1s	remaining: 6.09s
791:	learn: 0.0018666	total: 23.1s	remaining: 6.06s
792:	learn: 0.0018461	total: 23.1s	remaining: 6.04s
793:	learn: 0.0018320	total: 23.2s	remaining: 6.01s
794:	learn: 0.0018166	total: 23.2s	remaining: 5.98s
795:	learn: 0.0017968	total: 23.2s	remaining: 5.95s
796:	learn: 0.0017761	total: 23.3s	remaining: 5.92s
797:	learn: 0.0017603	total: 23.3s	remaining: 5.89s
798:	learn: 0.0017553	total: 23.3s	remaining: 5.87s
799:	learn: 0.0017377	total: 23.3s	remaining: 5.83s
800:	learn: 0.0017209	total: 23.4s	remaining: 5.8s
801:	learn: 0.0017046	total: 23.4s	remaining: 5.78s
802:	learn: 0.0016876	total: 23.4s	remaining: 5.75s
803:	learn: 0.0016728	total: 23.4s	remaining: 5.72s
804:	learn: 0.0016579	total: 23.5s	remaining: 5.69s
805:	learn: 0.0016404	total: 23.5s	remaining: 5.66s
806:	learn: 0.0016250	total: 23.5s	remaining: 5.63s
807:	learn: 0.0016097	total: 23.6s	remaining: 5.6s
808:	learn: 0.0015922	total: 23.6s	remaining: 5.57s
809:	learn: 0.0015747	total: 23.6s	remaining: 5.54s
810:	learn: 0.0015584	total: 23.6s	remaining: 5.51s
811:	learn: 0.0015449	total: 23.7s	remaining: 5.48s
812:	learn: 0.0015322	total: 23.7s	remaining: 5.45s
813:	learn: 0.0015219	total: 23.7s	remaining: 5.42s
814:	learn: 0.0015062	total: 23.8s	remaining: 5.39s
815:	learn: 0.0015001	total: 23.8s	remaining: 5.36s
816:	learn: 0.0014958	total: 23.8s	remaining: 5.33s
817:	learn: 0.0014809	total: 23.8s	remaining: 5.31s
818:	learn: 0.0014718	total: 23.9s	remaining: 5.28s
819:	learn: 0.0014681	total: 23.9s	remaining: 5.25s
820:	learn: 0.0014644	total: 23.9s	remaining: 5.22s
821:	learn: 0.0014608	total: 24s	remaining: 5.19s
822:	learn: 0.0014476	total: 24s	remaining: 5.16s
823:	learn: 0.0014322	total: 24s	remaining: 5.13s
824:	learn: 0.0014181	total: 24.1s	remaining: 5.1s
825:	learn: 0.0014092	total: 24.1s	remaining: 5.07s
826:	learn: 0.0013967	total: 24.1s	remaining: 5.04s
827:	learn: 0.0013869	total: 24.1s	remaining: 5.01s
828:	learn: 0.0013740	total: 24.2s	remaining: 4.98s
829:	learn: 0.0013713	total: 24.2s	remaining: 4.95s
830:	learn: 0.0013580	total: 24.2s	remaining: 4.92s
831:	learn: 0.0013439	total: 24.2s	remaining: 4.89s
832:	learn: 0.0013333	total: 24.3s	remaining: 4.87s
833:	learn: 0.0013217	total: 24.3s	remaining: 4.84s
834:	learn: 0.0013122	total: 24.3s	remaining: 4.81s
835:	learn: 0.0013085	total: 24.4s	remaining: 4.78s
836:	learn: 0.0012988	total: 24.4s	remaining: 4.75s
837:	learn: 0.0012911	total: 24.4s	remaining: 4.72s
838:	learn: 0.0012765	total: 24.4s	remaining: 4.69s
839:	learn: 0.0012658	total: 24.5s	remaining: 4.66s
840:	learn: 0.0012521	total: 24.5s	remaining: 4.63s
841:	learn: 0.0012422	total: 24.5s	remaining: 4.6s
842:	learn: 0.0012316	total: 24.5s	remaining: 4.57s
843:	learn: 0.0012289	total: 24.6s	remaining: 4.54s
844:	learn: 0.0012177	total: 24.6s	remaining: 4.51s
845:	learn: 0.0012064	total: 24.6s	remaining: 4.48s
846:	learn: 0.0011959	total: 24.7s	remaining: 4.45s
847:	learn: 0.0011903	total: 24.7s	remaining: 4.42s
848:	learn: 0.0011821	total: 24.7s	remaining: 4.39s
849:	learn: 0.0011728	total: 24.7s	remaining: 4.37s
850:	learn: 0.0011622	total: 24.8s	remaining: 4.33s
851:	learn: 0.0011597	total: 24.8s	remaining: 4.31s
852:	learn: 0.0011519	total: 24.8s	remaining: 4.28s
853:	learn: 0.0011382	total: 24.9s	remaining: 4.25s
854:	learn: 0.0011260	total: 24.9s	remaining: 4.22s
855:	learn: 0.0011148	total: 24.9s	remaining: 4.19s
856:	learn: 0.0011034	total: 24.9s	remaining: 4.16s
857:	learn: 0.0010927	total: 25s	remaining: 4.13s
858:	learn: 0.0010818	total: 25s	remaining: 4.1s
859:	learn: 0.0010698	total: 25s	remaining: 4.07s
860:	learn: 0.0010600	total: 25s	remaining: 4.04s
861:	learn: 0.0010535	total: 25.1s	remaining: 4.01s
862:	learn: 0.0010445	total: 25.1s	remaining: 3.98s
863:	learn: 0.0010343	total: 25.1s	remaining: 3.95s
864:	learn: 0.0010319	total: 25.1s	remaining: 3.92s
865:	learn: 0.0010213	total: 25.2s	remaining: 3.89s
866:	learn: 0.0010143	total: 25.2s	remaining: 3.86s
867:	learn: 0.0010093	total: 25.2s	remaining: 3.84s
868:	learn: 0.0009995	total: 25.2s	remaining: 3.81s
869:	learn: 0.0009910	total: 25.3s	remaining: 3.78s
870:	learn: 0.0009825	total: 25.3s	remaining: 3.75s
871:	learn: 0.0009740	total: 25.3s	remaining: 3.72s
872:	learn: 0.0009668	total: 25.4s	remaining: 3.69s
873:	learn: 0.0009579	total: 25.4s	remaining: 3.66s
874:	learn: 0.0009503	total: 25.4s	remaining: 3.63s
875:	learn: 0.0009412	total: 25.5s	remaining: 3.6s
876:	learn: 0.0009388	total: 25.5s	remaining: 3.58s
877:	learn: 0.0009316	total: 25.5s	remaining: 3.55s
878:	learn: 0.0009227	total: 25.5s	remaining: 3.52s
879:	learn: 0.0009150	total: 25.6s	remaining: 3.49s
880:	learn: 0.0009059	total: 25.6s	remaining: 3.46s
881:	learn: 0.0009036	total: 25.6s	remaining: 3.43s
882:	learn: 0.0008962	total: 25.7s	remaining: 3.4s
883:	learn: 0.0008882	total: 25.7s	remaining: 3.37s
884:	learn: 0.0008816	total: 25.7s	remaining: 3.34s
885:	learn: 0.0008724	total: 25.7s	remaining: 3.31s
886:	learn: 0.0008671	total: 25.8s	remaining: 3.28s
887:	learn: 0.0008579	total: 25.8s	remaining: 3.25s
888:	learn: 0.0008486	total: 25.8s	remaining: 3.22s
889:	learn: 0.0008391	total: 25.9s	remaining: 3.19s
890:	learn: 0.0008317	total: 25.9s	remaining: 3.17s
891:	learn: 0.0008297	total: 25.9s	remaining: 3.14s
892:	learn: 0.0008208	total: 25.9s	remaining: 3.11s
893:	learn: 0.0008153	total: 26s	remaining: 3.08s
894:	learn: 0.0008059	total: 26s	remaining: 3.05s
895:	learn: 0.0008000	total: 26s	remaining: 3.02s
896:	learn: 0.0007904	total: 26.1s	remaining: 2.99s
897:	learn: 0.0007823	total: 26.1s	remaining: 2.96s
898:	learn: 0.0007807	total: 26.1s	remaining: 2.93s
899:	learn: 0.0007747	total: 26.1s	remaining: 2.9s
900:	learn: 0.0007731	total: 26.2s	remaining: 2.88s
901:	learn: 0.0007664	total: 26.2s	remaining: 2.85s
902:	learn: 0.0007649	total: 26.2s	remaining: 2.82s
903:	learn: 0.0007632	total: 26.2s	remaining: 2.79s
904:	learn: 0.0007554	total: 26.3s	remaining: 2.76s
905:	learn: 0.0007476	total: 26.3s	remaining: 2.73s
906:	learn: 0.0007406	total: 26.3s	remaining: 2.7s
907:	learn: 0.0007392	total: 26.4s	remaining: 2.67s
908:	learn: 0.0007366	total: 26.4s	remaining: 2.64s
909:	learn: 0.0007341	total: 26.4s	remaining: 2.61s
910:	learn: 0.0007277	total: 26.4s	remaining: 2.58s
911:	learn: 0.0007213	total: 26.5s	remaining: 2.55s
912:	learn: 0.0007147	total: 26.5s	remaining: 2.52s
913:	learn: 0.0007089	total: 26.5s	remaining: 2.5s
914:	learn: 0.0007018	total: 26.6s	remaining: 2.47s
915:	learn: 0.0006956	total: 26.6s	remaining: 2.44s
916:	learn: 0.0006880	total: 26.6s	remaining: 2.41s
917:	learn: 0.0006836	total: 26.6s	remaining: 2.38s
918:	learn: 0.0006820	total: 26.7s	remaining: 2.35s
919:	learn: 0.0006779	total: 26.7s	remaining: 2.32s
920:	learn: 0.0006733	total: 26.7s	remaining: 2.29s
921:	learn: 0.0006665	total: 26.8s	remaining: 2.26s
922:	learn: 0.0006607	total: 26.8s	remaining: 2.23s
923:	learn: 0.0006548	total: 26.8s	remaining: 2.21s
924:	learn: 0.0006515	total: 26.8s	remaining: 2.18s
925:	learn: 0.0006450	total: 26.9s	remaining: 2.15s
926:	learn: 0.0006391	total: 26.9s	remaining: 2.12s
927:	learn: 0.0006326	total: 26.9s	remaining: 2.09s
928:	learn: 0.0006257	total: 27s	remaining: 2.06s
929:	learn: 0.0006204	total: 27s	remaining: 2.03s
930:	learn: 0.0006190	total: 27s	remaining: 2s
931:	learn: 0.0006178	total: 27s	remaining: 1.97s
932:	learn: 0.0006126	total: 27.1s	remaining: 1.94s
933:	learn: 0.0006069	total: 27.1s	remaining: 1.91s
934:	learn: 0.0006009	total: 27.1s	remaining: 1.89s
935:	learn: 0.0005973	total: 27.2s	remaining: 1.86s
936:	learn: 0.0005912	total: 27.2s	remaining: 1.83s
937:	learn: 0.0005856	total: 27.2s	remaining: 1.8s
938:	learn: 0.0005836	total: 27.2s	remaining: 1.77s
939:	learn: 0.0005785	total: 27.3s	remaining: 1.74s
940:	learn: 0.0005740	total: 27.3s	remaining: 1.71s
941:	learn: 0.0005727	total: 27.3s	remaining: 1.68s
942:	learn: 0.0005681	total: 27.3s	remaining: 1.65s
943:	learn: 0.0005628	total: 27.4s	remaining: 1.62s
944:	learn: 0.0005569	total: 27.4s	remaining: 1.59s
945:	learn: 0.0005558	total: 27.4s	remaining: 1.56s
946:	learn: 0.0005514	total: 27.5s	remaining: 1.54s
947:	learn: 0.0005452	total: 27.5s	remaining: 1.51s
948:	learn: 0.0005392	total: 27.5s	remaining: 1.48s
949:	learn: 0.0005366	total: 27.5s	remaining: 1.45s
950:	learn: 0.0005354	total: 27.6s	remaining: 1.42s
951:	learn: 0.0005297	total: 27.6s	remaining: 1.39s
952:	learn: 0.0005253	total: 27.6s	remaining: 1.36s
953:	learn: 0.0005213	total: 27.7s	remaining: 1.33s
954:	learn: 0.0005166	total: 27.7s	remaining: 1.3s
955:	learn: 0.0005111	total: 27.7s	remaining: 1.27s
956:	learn: 0.0005100	total: 27.7s	remaining: 1.25s
957:	learn: 0.0005061	total: 27.8s	remaining: 1.22s
958:	learn: 0.0005012	total: 27.8s	remaining: 1.19s
959:	learn: 0.0004963	total: 27.8s	remaining: 1.16s
960:	learn: 0.0004941	total: 27.9s	remaining: 1.13s
961:	learn: 0.0004906	total: 27.9s	remaining: 1.1s
962:	learn: 0.0004866	total: 27.9s	remaining: 1.07s
963:	learn: 0.0004819	total: 27.9s	remaining: 1.04s
964:	learn: 0.0004798	total: 28s	remaining: 1.01s
965:	learn: 0.0004759	total: 28s	remaining: 985ms
966:	learn: 0.0004710	total: 28s	remaining: 956ms
967:	learn: 0.0004669	total: 28s	remaining: 927ms
968:	learn: 0.0004627	total: 28.1s	remaining: 898ms
969:	learn: 0.0004581	total: 28.1s	remaining: 869ms
970:	learn: 0.0004537	total: 28.1s	remaining: 840ms
971:	learn: 0.0004496	total: 28.2s	remaining: 811ms
972:	learn: 0.0004488	total: 28.2s	remaining: 782ms
973:	learn: 0.0004443	total: 28.2s	remaining: 753ms
974:	learn: 0.0004410	total: 28.2s	remaining: 724ms
975:	learn: 0.0004365	total: 28.3s	remaining: 695ms
976:	learn: 0.0004344	total: 28.3s	remaining: 666ms
977:	learn: 0.0004334	total: 28.3s	remaining: 638ms
978:	learn: 0.0004293	total: 28.4s	remaining: 608ms
979:	learn: 0.0004253	total: 28.4s	remaining: 579ms
980:	learn: 0.0004213	total: 28.4s	remaining: 550ms
981:	learn: 0.0004169	total: 28.5s	remaining: 522ms
982:	learn: 0.0004145	total: 28.5s	remaining: 493ms
983:	learn: 0.0004109	total: 28.5s	remaining: 464ms
984:	learn: 0.0004064	total: 28.5s	remaining: 435ms
985:	learn: 0.0004024	total: 28.6s	remaining: 406ms
986:	learn: 0.0004016	total: 28.6s	remaining: 377ms
987:	learn: 0.0004007	total: 28.6s	remaining: 348ms
988:	learn: 0.0003976	total: 28.6s	remaining: 319ms
989:	learn: 0.0003943	total: 28.7s	remaining: 290ms
990:	learn: 0.0003899	total: 28.7s	remaining: 261ms
991:	learn: 0.0003863	total: 28.7s	remaining: 232ms
992:	learn: 0.0003834	total: 28.8s	remaining: 203ms
993:	learn: 0.0003795	total: 28.8s	remaining: 174ms
994:	learn: 0.0003763	total: 28.8s	remaining: 145ms
995:	learn: 0.0003723	total: 28.8s	remaining: 116ms
996:	learn: 0.0003682	total: 28.9s	remaining: 86.9ms
997:	learn: 0.0003645	total: 28.9s	remaining: 57.9ms
998:	learn: 0.0003617	total: 28.9s	remaining: 29ms
999:	learn: 0.0003586	total: 28.9s	remaining: 0us
The computed objective value is -9.931619770560502
[INFO][abstract_intensifier.py:590] Added config 449cf4 and rejected config 22d081 as incumbent because it is not better than the incumbents on 1 instances:
Iteration 1 timed out.
Starting Optimization Incumbent ITR 1
[INFO][abstract_intensifier.py:590] Added config 07faaa and rejected config 22d081 as incumbent because it is not better than the incumbents on 1 instances:
Iteration 2 timed out.
Starting Optimization Incumbent ITR 2
[INFO][abstract_intensifier.py:590] Added config 9fc890 and rejected config 22d081 as incumbent because it is not better than the incumbents on 1 instances:
Iteration 3 timed out.
Starting Optimization Incumbent ITR 3
[INFO][abstract_intensifier.py:590] Added config b51348 and rejected config 22d081 as incumbent because it is not better than the incumbents on 1 instances:
Iteration 4 timed out.
Starting Optimization Incumbent ITR 4
[INFO][abstract_intensifier.py:590] Added config 90ead9 and rejected config 22d081 as incumbent because it is not better than the incumbents on 1 instances:
Iteration 5 timed out.
Starting Optimization Incumbent ITR 5
[INFO][abstract_intensifier.py:590] Added config 3d5e2f and rejected config 22d081 as incumbent because it is not better than the incumbents on 1 instances:
Iteration 6 timed out.
Starting Optimization Incumbent ITR 6
[INFO][abstract_intensifier.py:590] Added config abadce and rejected config 22d081 as incumbent because it is not better than the incumbents on 1 instances:
Iteration 7 timed out.
Starting Optimization Incumbent ITR 7
[INFO][abstract_intensifier.py:590] Added config b723b0 and rejected config 22d081 as incumbent because it is not better than the incumbents on 1 instances:
Iteration 8 timed out.
Starting Optimization Incumbent ITR 8
[INFO][abstract_intensifier.py:590] Added config d819a5 and rejected config 22d081 as incumbent because it is not better than the incumbents on 1 instances:
Iteration 9 timed out.
Starting Optimization Incumbent ITR 9
[INFO][abstract_intensifier.py:590] Added config 793bef and rejected config 22d081 as incumbent because it is not better than the incumbents on 1 instances:
Iteration 10 timed out.
Final Best Incumbent:
None
Objective Value:
/home/TUE/20210962/miniconda3/envs/anton/lib/python3.8/site-packages/sklearn/ensemble/_stacking.py:957: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
-inf
/var/spool/slurm/d/job121042/slurm_script: line 6: deactivate: No such file or directory
